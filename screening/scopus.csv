Authors;Title;Abstract;Author Keywords
"Song F., Touili T.";"Model-checking software library API usage rules";"Modern software increasingly relies on using third-party libraries which are accessed via application programming interfaces (APIs). Libraries usually impose constraints on how API functions can be used (API usage rules) and programmers have to obey these API usage rules. However, API usage rules often are not well documented or documented informally. In this work, we show how to use the SCTPL and SLTPL logics to precisely and formally specify API usage rules in libraries, where SCTPL/SLTPL can be seen as an extension of the branching/linear temporal logic CTL/LTL with variables, quantifiers and predicates over the stack. This allows library providers to formally describe API usage rules without knowing how their libraries will be used by programmers. We propose an automated approach to check whether programs using libraries violate API usage rules or not. Our approach consists in modeling programs as pushdown systems (PDSs) and checking API usage rules by SCTPL/SLTPL model-checking for PDSs. To make the model-checking procedure more efficient and precise, we propose an abstraction that reduces drastically the size of the program model and integrate may-alias analysis into our approach to reduce false alarms. Moreover, we characterize two sublogics rSCTPL and rSLTPL of SCTPL and SLTPL that are preserved by the abstraction. We implement our techniques in a tool and apply the tool to check several open-source programs. Our tool finds several previously unknown bugs in several programs. The may-alias analysis avoids most of the false alarms that occur using SCTPL or SLTPL model-checking techniques without may-alias analysis. © 2015, Springer-Verlag Berlin Heidelberg.";"Model-checking, Pushdown systems, Software API usage rules"
"Campos E.C., de Souza L.B.L., Maia M.D.A.";"Searching crowd knowledge to recommend solutions for API usage tasks";"Stack Overflow (SO) is a question and answer service directed to issues related to software development. In SO, developers post questions related to a programming topic and other members of the site can provide answers to help them. The information available on this type of service is also known as ‘crowd knowledge’ and currently is one important trend in supporting activities related to software development. We present an approach that makes use of ‘crowd knowledge’ in SO to recommend information that can assist developer activities. This strategy recommends a ranked list of question-answer pairs from SO based on a query. The criteria for ranking are based on three main aspects: the textual similarity of the pairs with respect to the query related to the developer's problem, the quality of the pairs, and a filtering mechanism that considers only ‘how-to’ posts. We conducted an experiment considering programming problems on three different topics (Swing, Boost and LINQ) widely used by the software development community to evaluate the proposed recommendation strategy. The results have shown that for Lucene + Score + How-to approach, 77.14% of the assessed activities have at least one recommended pair proved to be useful concerning the target programming problem. Copyright © 2016 John Wiley & Sons, Ltd. Copyright © 2016 John Wiley & Sons, Ltd.";"crowd knowledge, Q&A services, recommendation systems"
"Varley R.";"ExoData: A Python package to handle large exoplanet catalogue data";"Exoplanet science often involves using the system parameters of real exoplanets for tasks such as simulations, fitting routines, and target selection for proposals. Several exoplanet catalogues are already well established but often lack a version history and code friendly interfaces. Software that bridges the barrier between the catalogues and code enables users to improve the specific repeatability of results by facilitating the retrieval of exact system parameters used in articles results along with unifying the equations and software used. As exoplanet science moves towards large data, gone are the days where researchers can recall the current population from memory. An interface able to query the population now becomes invaluable for target selection and population analysis. ExoData is a Python interface and exploratory analysis tool for the Open Exoplanet Catalogue. It allows the loading of exoplanet systems into Python as objects (Planet, Star, Binary, etc.) from which common orbital and system equations can be calculated and measured parameters retrieved. This allows researchers to use tested code of the common equations they require (with units) and provides a large science input catalogue of planets for easy plotting and use in research. Advanced querying of targets is possible using the database and Python programming language. ExoData is also able to parse spectral types and fill in missing parameters according to programmable specifications and equations. Examples of use cases are integration of equations into data reduction pipelines, selecting planets for observing proposals and as an input catalogue to large scale simulation and analysis of planets. ExoData is a Python package available freely on GitHub.1 It's open source and community contributions are encouraged. The package can be easily installed using pip install exodata, detailed setup information is provided within. Program summary Program title: ExoData Catalogue identifier: AFAL_v1_0 Program summary URL:http://cpc.cs.qub.ac.uk/summaries/AFAL_v1_0.html Program obtainable from: CPC Program Library, Queen's University, Belfast, N. Ireland Licensing provisions: GNU General Public License, version 3 No. of lines in distributed program, including test data, etc.: 21884 No. of bytes in distributed program, including test data, etc.: 608434 Distribution format: tar.gz Programming language: Python 2.7, 3.4, 3.5. Computer: Any. Operating system: Any. RAM: Less than 200MB Classification: 1.7. External routines: numpy, quantities, matplotlib, requests, astropy, seaborn, pandas, six Nature of problem: Being able to use exoplanet catalogue values in code including where there may be incomplete and incorrectly formatted values. Also being able to use the whole catalogue data at once, both for user querying, visualisation and in large simulation programs. Solution method: An interface to access the catalogue including filling in missing values and parsing of the catalogue data. Creating an API useable by both humans and other code, implementation of commonly used exoplanet equations, a plotting library. Running time: A few seconds depending on task © 2016 The Author(s)";"Catalogues, Exoplanets, Interface"
"Suro F., Ono Y.";"Japanese EFL learners' uses of text-to-speech technology and their learning behaviors: A pilot study";"The purpose of this study is to show how EFL learners work on Text-to-speech (TTS) technology to improve their speaking accuracy. We constructed the system for improving speaking proficiency based on Web-Speech API. Usually, text-to-speech is available on the net or by using TTS applications in education. However, these sounds produced are not generally customized to the diversity of learners' learning strategies. The system constructed in the study makes it possible for learners to choose the words, phrases sentences or the passage they like to listen to for their speaking practice. Major findings that came out from this study are: (i) As to the easier materials, accuracy improvement was observed regardless of their proficiency, (ii) On the contrary, as to the difficult materials, such an improvement was not observed in the experiment, and (iii) there is diversity of how they worked on the system, and there are some patterns in their learning behaviors, Bottom-uppers and Top-downers. These findings suggest the usefulness of the current system for various types of learners in terms of learning strategies and a future possibility from a learning analytic point of view to modify the system. © 2016 IEEE.";"EFL learners, Learning Behavior, Speaking Proficiency, Text-to-Speech (TTS)"
"Acar Y., Backes M., Fahl S., Kim D., Mazurek M.L., Stransky C.";"You Get Where You're Looking for: The Impact of Information Sources on Code Security";"Vulnerabilities in Android code - including but not limited to insecure data storage, unprotected inter-component communication, broken TLS implementations, and violations of least privilege - have enabled real-world privacy leaks and motivated research cataloguing their prevalence and impact. Researchers have speculated that appification promotes security problems, as it increasingly allows inexperienced laymen to develop complex and sensitive apps. Anecdotally, Internet resources such as Stack Overflow are blamed for promoting insecure solutions that are naively copy-pasted by inexperienced developers. In this paper, we for the first time systematically analyzed how the use of information resources impacts code security. We first surveyed 295 app developers who have published in the Google Play market concerning how they use resources to solve security-related problems. Based on the survey results, we conducted a lab study with 54 Android developers (students and professionals), in which participants wrote security-and privacy-relevant code under time constraints. The participants were assigned to one of four conditions: free choice of resources, Stack Overflow only, official Android documentation only, or books only. Those participants who were allowed to use only Stack Overflow produced significantly less secure code than those using, the official Android documentation or books, while participants using the official Android documentation produced significantly less functional code than those using Stack Overflow. To assess the quality of Stack Overflow as a resource, we surveyed the 139 threads our participants accessed during the study, finding that only 25% of them were helpful in solving the assigned tasks and only 17% of them contained secure code snippets. In order to obtain ground truth concerning the prevalence of the secure and insecure code our participants wrote in the lab study, we statically analyzed a random sample of 200,000 apps from Google Play, finding that 93.6% of the apps used at least one of the API calls our participants used during our study. We also found that many of the security errors made by our participants also appear in the wild, possibly also originating in the use of Stack Overflow to solve programming problems. Taken together, our results confirm that API documentation is secure but hard to use, while informal documentation such as Stack Overflow is more accessible but often leads to insecurity. Given time constraints and economic pressures, we can expect that Android developers will continue to choose those resources that are easiest to use, therefore, our results firmly establish the need for secure-but-usable documentation. © 2016 IEEE.";"Android, developer resources, developer study, security, usability"
"López-Fernández L., García B., Gallego M., Gortázar F.";"Designing and evaluating the usability of an API for real-time multimedia services in the Internet";"In the last few years, multimedia technologies in general, and Real-Time multimedia Communications (RTC) in particular, are becoming mainstream among WWW and smartphone developers, who have an increasing interest in richer media capabilities for creating their applications. The engineering literature proposing novel algorithms, protocols and architectures for managing and processing multimedia information is currently overwhelming. However, most of these results do not arrive to applications due to the lack of simple and usable APIs. Interestingly, in this context in which APIs are the critical ingredient for reaching wide developer audiences, the scientific literature about multimedia APIs and their usability is scarce. In this paper we try to contribute to fill this gap by proposing the RTC Media API: a novel type of API designed with the aim of making simple for developers the use of latest trends in RTC multimedia including WebRTC, Video Content Analysis or Augmented Reality. We provide a specification of such API and discuss how it satisfies a set of design requirements including programming-language agnosticism, adaptation to cloud environments, support to multisensory multimedia, etc. After that, we describe an implementation of such an API that has been created in the context of the Kurento open source software project, and present a study evaluating the API usability performed in a group of more than 40 professional developers distributed worldwide. In the light of the obtained results, we conclude that the usability of the API is adequate across the main development activities (i.e. API learning, code creation and code maintenance), with an average usability score of 3.39 over 5 in a Likert scale, and that this result is robust with respect to developers’ profiles, cultures, professional experiences and preferred programming languages. © 2016 Springer Science+Business Media New York,Application Programming Interfaces, Cognitive dimensions of notations, Media server, Multimedia processing, Multimedia tools and applications, Real-time multimedia communications, WebRTC"
"Sawant A.A., Bacchelli A.";"fine-GRAPE: fine-grained APi usage extractor – an approach and dataset to investigate API usage";"An Application Programming Interface (API) provides a set of functionalities to a developer with the aim of enabling reuse. APIs have been investigated from different angles such as popularity usage and evolution to get a better understanding of their various characteristics. For such studies, software repositories are mined for API usage examples. However, many of the mining algorithms used for such purposes do not take type information into account. Thus making the results unreliable. In this paper, we aim to rectify this by introducing fine-GRAPE, an approach that produces fine-grained API usage information by taking advantage of type information while mining API method invocations and annotation. By means of fine-GRAPE, we investigate API usages from Java projects hosted on GitHub. We select five of the most popular APIs across GitHub Java projects and collect historical API usage information by mining both the release history of these APIs and the code history of every project that uses them. We perform two case studies on the resulting dataset. The first measures the lag time of each client. The second investigates the percentage of used API features. In the first case we find that for APIs that release more frequently clients are far less likely to upgrade to a more recent version of the API as opposed to clients of APIs that release infrequently. The second case study shows us that for most APIs there is a small number of features that is actually used and most of these features relate to those that have been introduced early in the APIs lifecycle. © 2016 The Author(s)";"API popularity, API usage, Application programming interface, Dataset"
"Landhäußer M., Weigelt S., Tichy W.F.";"NLCI: a natural language command interpreter";"Natural language interfaces are becoming more and more common, because they are powerful and easy to use. Examples of such interfaces are voice controlled navigation devices, Apple’s personal assistant Siri, Google Voice Search, and translation services. However, such interfaces are extremely difficult to build, to maintain, and to port to new domains. We present an approach for building and porting such interfaces quickly. NLCI is a natural language command interpreter that accepts action commands in English and translates them into executable code. The core component is an ontology that models an API. Once the API is “ontologized”, NLCI translates input sentences into sequences of API calls that implement the intended actions. Two radically different APIs were ontologized: openHAB for home automation and Alice for building 3D animations. Construction of the ontology can be automated if the API uses descriptive names for its components. In that case, the language interface can be generated completely automatically. Recall and precision of NLCI on a benchmark of 50 input scripts are 67 and 78 %, resp. Though not yet acceptable for practical use, the results indicate that the approach is feasible. NLCI accepts typed input only. Future work will use a speech front-end to test spoken input. © 2016 Springer Science+Business Media New York,End-user programming, Knowledge-based software engineering, Natural language processing for software engineering, Program synthesis, Programming in natural language"
"Pathirage M., Hyde J., Pan Y., Plale B.";"SamzaSQL: Scalable fast data management with streaming SQL";"As the data-driven economy evolves, enterprises have come to realize a competitive advantage in being able to act on high volume, high velocity streams of data. Technologies such as distributed message queues and streaming processing platforms that can scale to thousands of data stream partitions on commodity hardware are a response. However, the programming API provided by these systems is often low-level, requiring substantial custom code that adds to the programmer learning curve and maintenance overhead. Additionally, these systems often lack SQL querying capabilities that have proven popular on Big Data systems like Hive, Impala or Presto. We define a minimal set of extensions to standard SQL for data stream querying and manipulation. These extensions are prototyped in SamzaSQL, a new tool for streaming SQL that compiles streaming SQL into physical plans that are executed on Samza, an open-source distributed stream processing framework. We compare the performance of streaming SQL queries against native Samza applications and discuss usability improvements. SamzaSQL is a part of the open source Apache Samza project and will be available for general use. © 2016 IEEE."
"Walker S., McFadden M.";"Best practices for scalable power measurement and control";"There are thousands of specialized registers onmodern processors which provide useful features such as powerbudgeting, thermal monitoring, and performance counting. These registers fall into two categories, model specific registers(MSRs) and configuration space registers (CSRs). Many ofthese registers, such as those supported by PAPI, help thehigh-performance computing (HPC) community analyze theirprogram in order to maximize performance and use resourcesmore efficiently. However, there are many MSRs and CSRswhich are not supported by existing performance tools. TheMSR kernel module provides access to all MSRs, but requiresthe user to be root. Users will typically want to access a handfulof MSRs sequentially, but we found that the existing MSRmodule has far too much overhead. Just like MSRs, usersneed elevated privileges to access CSRs with utilities suchas lspci. Simply allowing users to access all of the registersis out of the question because of the security risks involved. Furthermore, using these registers requires detailed knowledgeof the architectural changes in addition to the manufacturer'sproprietary ways of encoding the data. In this paper, we will describe a group of utilities developedat Lawrence Livermore National Laboratory to address theseproblems. Our Libmsr API solves the usability issues byproviding a simplified interface to common tasks. The companionkernel module, MSR-SAFE, allows whitelisting MSRsfor userspace access, plus provides an optimized way to accessMSRs in batches. Our CSR-SAFE kernel module is a first of itskind utility to whitelist sections of the PCI configuration space, where CSRs reside, for userspace access. We demonstrate theabilities of Libmsr and MSR-SAFE by using the utilities toset various power limits on the NAS parallel benchmark MG. Experiments analyzing our optimizations show a maximumspeedup of 26X, and approximately 2-8X on average for typicalbatches versus the stock MSR kernel module. Our utilitiescurrently support most modern Intel processors. © 2016 IEEE.";"Model Specific Registers, PCI Configuration Registers, Performance, Power, RAPL, Scalability"
"Khan S., Nauman M., Othman A.T., Musa S., Syed T.A.";"TSSDroid: realization of an efficient and usable TSS API for the Android software stack";"The advancement in smartphones capabilities has attracted malware writers to build more sophisticated attacks on these devices. Traditional software-based security mechanisms have failed to provide strong security against these attacks. Similar threats on the PC have been countered using the concepts of Trusted Computing—a highly flexible trust mechanism with strong security properties. However, smartphone platforms have yet to see any Trusted Computing applications—primarily because of the difficulty in adopting this relatively new paradigm of security. In this paper, we present the design of a high-level application programming interface (API) that allows Android-based smartphone application developers to adopt Trusted Computing and use it in their applications without having to learn the intricate details of how Trusted Computing works. The API abstracts away the complexity in using Trusted Computing constructs by offering easy-to-use interfaces for complex tasks. The API has enhanced the usability of Trusted Computing development by significantly reducing the number of lines and complexity of code required to perform these diverse tasks. This paper provides a reference implementation for the proposed API in order to show that the API is efficient in terms of performance overhead. Copyright Â© 2016 John Wiley & Sons, Ltd. Copyright Â© 2016 John Wiley & Sons, Ltd.";"android, API design, mobile platforms, trusted computing"
"Saied M.A., Sahraoui H.";"A cooperative approach for combining client-based and library-based API usage pattern mining";"Software developers need to cope with the complexity of Application Programming Interfaces (APIs) of external libraries or frameworks. Typical APIs provide thousands of methods to their client programs, and these methods are not used independently of each other. Much existing work has provided different techniques to mine API usage patterns based on client programs in order to help developers understanding and using existing libraries. Other techniques propose to overcome the strong constraint of clients' dependency and infer API usage patterns only using the library source code. In this paper, we propose a cooperative usage pattern mining technique (COUPminer) that combines client-based and library-based usage pattern mining. We evaluated our technique through four APIs and the obtained results show that the cooperative approach allows taking advantage at the same time from the precision of client-based technique and from the generalizability of library-based techniques. © 2016 IEEE.";"API Documentation, API Usage, Software Clustering, Usage Pattern"
"Fleureau J., Galvane Q., Tariolle F.-L., Guillotel P.";"Generic drone control platform for autonomous capture of cinema scenes";"The movie industry has been using Unmanned Aerial Vehicles as a new tool to produce more and more complex and aesthetic camera shots. However, the shooting process currently rely on manual control of the drones which makes it difficult and sometimes inconvenient to work with. In this paper we address the lack of autonomous system to operate generic rotary-wing drones for shooting purposes. We propose a global control architecture based on a high-level generic API used by many UAV. Our solution integrates a compound and coupled model of a generic rotary-wing drone and a Full State Feedback strategy. To address the specific task of capturing cinema scenes, we combine the control architecture with an automatic camera path planning approach that encompass cinematographic techniques. The possibilities offered by our system are demonstrated through a series of experiments. © 2016 Copyright held by the owner/author(s).";"ACM proceedings, Rotary-wing"
"Otegui J., Guralnick R.P.";"The geospatial data quality REST API for primary biodiversity data";"Summary: We present a REST web service to assess the geospatial quality of primary biodiversity data. It enables access to basic and advanced functions to detect completeness and consistency issues as well as general errors in the provided record or set of records. The API uses JSON for data interchange and efficient parallelization techniques for fast assessments of large datasets. Availability and implementation: The Geospatial Data Quality API is part of the VertNet set of APIs. It can be accessed at http://api-geospatial.vertnet-portal.appspot.com/geospatial and is already implemented in the VertNet data portal for quality reporting. Source code is freely available under GPL license from http://www.github.com/vertnet/api-geospatial. Supplementary information: Supplementary data are available at Bioinformatics online. © 2016 The Author 2016. Published by Oxford University Press."
"Myers B.A., Stylos J.";"Improving API usability";"APPLICATION PROGRAMMING INTERFACES (APIs), including libraries, frameworks, toolkits, and software development kits, are used by virtually all code. If one includes both internal APIs (interfaces internal to software projects) and public APIs (such as the Java Platform SDK, the Windows .NET Framework, jQuery for JavaScript, and Web services like Google Maps), nearly every line of code most programmers write will use API calls. APIs provide a mechanism for code reuse so programmers can build on top of what others (or they themselves) have already done, rather than start from scratch with every program. Moreover, using APIs is often required because low-level access to system resources (such as graphics, networking, and the file system) is available only through protected APIs. Organizations increasingly provide their internal data on the Web through public APIs, for example, http://www.programmableweb.com lists almost 15,000 APIs for Web services and https://www.digitalgov. gov/2013/04/30/apis-in-government/promotes use of government data through Web APIs. © 2016 ACM."
"Weidner O., Atkinson M., Barker A., Vicente R.F.";"Rethinking high performance computing platforms: Challenges, opportunities and recommendations";"A growing number of ""second generation"" high-performance computing applications with heterogeneous, dynamic and data-intensive properties have an extended set of requirements, which cover application deployment, resource allocation, -control, and I/O scheduling. These requirements are not met by the current production HPC platform models and policies. This results in a loss of opportunity, productivity and innovation for new computational methods and tools. It also decreases effective system utilization for platform providers due to unsupervised workarounds and ""rogue"" resource management strategies implemented in application space. In this paper we critically discuss the dominant HPC platform model and describe the challenges it creates for second generation applications because of its asymmetric resource view, interfaces and software deployment policies. We present an extended, more symmetric and application-centric platform model that adds decentralized deployment, introspection, bidirectional control and information flow and more comprehensive resource scheduling. We describe cHPC: an early prototype of a non-disruptive implementation based on Linux Containers (LXC). It can operate alongside existing batch queuing systems and exposes a symmetric platform API without interfering with existing applications and usage modes. We see our approach as a viable, incremental next step in HPC platform evolution that benefits applications and platform providers alike. To demonstrate this further, we layout out a roadmap for future research and experimental evaluation. © 2016 ACM.";"HPC platform APIs, HPC platform models, Linux containers, OS-level virtualization, Resource management, Usability"
"Gurram B., Giri N.";"Improving localization accuracy of android's Fused Location Provider API using Kalman Filter";"This paper intends to improve the location accuracy of Google's Fused Location Provider API, for android handheld device using Kalman Filter. Since the Fused Location Provider was built for managing the battery and accuracy tradeoff between GPS provider and Network Provider, the estimate is likely to be noisy and the track obtained contains jumps. So by using Kalman filter, the jumps can be devoid, and a smooth track can be obtained. A real time experiment is carried out to check the improvements. The results show that the proposed location path is smoother than the path travelled using the conventional Fused Location Provider API. © 2016 IEEE.";"Android, Fused Location Provider API, Kalman Filter, Location, Real time tracking"
"Nguyen T.T., Pham H.V., Vu P.M., Nguyen T.T.";"Learning API usages from bytecode: A statistical approach";"Mobile app developers rely heavily on standard API frameworks and libraries. However, learning API usages is often challenging due to the fast-changing nature of API frameworks for mobile systems and the insufficiency of API documentation and source code examples. In this paper, we propose a novel approach to learn API usages from bytecode of Android mobile apps. Our core contributions include HAPI, a statistical model of API usages and three algorithms to extract method call sequences from apps' bytecode, to train HAPI based on those sequences, and to recommend method calls in code completion using the trained HAPIs. Our empirical evaluation shows that our prototype tool can effectively learn API usages from 200 thousand apps containing 350 million method sequences. It recommends next method calls with top-3 accuracy of 90% and outperforms baseline approaches on average 10-20%. © 2016 ACM.";"API usage, Mobile apps, Statistical model"
"Raghothaman M., Wei Y., Hamadi Y.";"SWIM: Synthesizing what i mean code search and idiomatic snippet synthesis";"Modern programming frameworks come with large libraries, with diverse applications such as for matching regular expres-sions, parsing XML files and sending email. Programmers often use search engines such as Google and Bing to learn about existing APIs. In this paper, we describe swim, a tool which suggests code snippets given API-related natural language queries such as\generate md5 hash code"". The query does not need to contain framework-specific trivia such as the type names or methods of interest. We translate user queries into the APIs of interest using clickthrough data from the Bing search engine. Then, based on patterns learned from open-source code repositories, we synthesize idiomatic code describing the use of these APIs. We introduce structured call sequences to capture API-usage patterns. Structured call sequences are a generalized form of method call sequences, with if-branches and while-loops to represent conditional and repeated API usage patterns, and are simple to extract and amenable to synthesis. We evaluated swim with 30 common C# API-related queries received by Bing. For 70% of the queries, the first suggested snippet was a relevant solution, and a relevant solution was present in the top 10 results for all benchmarked queries. The online portion of the workow is also very responsive, at an average of 1:5 seconds per snippet. © 2016 ACM."
"Mindermann K.";"Are easily usable security libraries possible and how should experts work together to create them?";"Due to non-experts also developing security relevant applications it is necessary to support them too. Some improvements in the current research may not reach or impact these developers. Nonetheless these developers use security libraries. There are findings that even their usage is not easily possible and applications are left vulnerable to supposedly treated threats. So it is important to improve the usability of the security libraries. This is itself is not straightforward because of a required maturing process for example. By get- ting together experts of different involved areas, especially cryptographic and API-usability experts, both of the problems can be tackled. © 2016 ACM.";"Abstraction, API, Developer knowledge"
"Wu N., Hou D., Liu Q.";"Linking usage tutorials into API client code";"Traceability links between software artifacts have important applications in the development process. This paper concerns a special case of traceability recovery, i.e., the automated integration of API usage tutorials with the API client code. Our solution involves partitioning the client code into multiple semantic groups/snippets and linking each snippet to the best matching tutorials. Evaluation using benchmarks created for two popular APIs reveals that our solution can find the expected tutorial links at the average rank of 1.6 and 1.4 in the top ranked results, for the two API's, respectively, and with good average precision and recall. We also evaluate the impact of both method partitioning and JavaDoc query expansion on tutorial linking performance. Lastly, we conduct a formative user study to pinpoint the scenarios where our solution actually helps a software developer. We conclude that it is a promising approach to speeding up the maintenance of API client code. © 2016 ACM.";"Abstract syntax tree, API, Documentation, Information retrieval, Java, Traceability, Vector space model"
"Nguyen A.T., Nguyen H.A., Nguyen T.N.";"A large-scale study on repetitiveness, containment, and composability of routines in open-source projects";"Source code in software systems has been shown to have a good degree of repetitiveness at the lexical, syntactical, and API usage levels. This paper presents a large-scale study on the repetitiveness, containment, and composability of source code at the semantic level. We collected a large dataset consisting of 9,224 Java projects with 2.79M class files, 17.54M methods with 187M SLOCs. For each method in a project, we build the program dependency graph (PDG) to represent a routine, and compare PDGs with one another as well as the subgraphs within them. We found that within a project, 12.1% of the routines are repeated, and most of them repeat from 2-7 times. As entirety, the routines are quite project-specific with only 3.3% of them exactly repeating in 1-4 other projects with at most 8 times. We also found that 26.1% and 7.27% of the routines are contained in other routine(s), i.e., implemented as part of other routine(s) elsewhere within a project and in other projects, respectively. Except for trivial routines, their repetitiveness and containment is independent of their complexity. Defining a subroutine via a per-variable slicing subgraph in a PDG, we found that 14.3% of all routines have all of their subroutines repeated. A high percentage of subroutines in a routine can be found/reused elsewhere. We collected 8,764,971 unique subroutines (with 323,564 unique JDK subroutines) as basic units for code searching/synthesis. We also provide practical implications of our findings to automated tools. © 2016 ACM.";"Code reuse, Composability, Containment, Repetitiveness"
"Qiu D., Li B., Leung H.";"Understanding the API usage in Java";"Context Application Programming Interfaces (APIs) facilitate the use of programming languages. They define sets of rules and specifications for software programs to interact with. The design of language API is usually artistic, driven by aesthetic concerns and the intuitions of language architects. Despite recent studies on limited scope of API usage, there is a lack of comprehensive, quantitative analyses that explore and seek to understand how real-world source code uses language APIs. Objective This study aims to understand how APIs are employed in practical development and explore their potential applications based on the results of API usage analysis. Method We conduct a large-scale, comprehensive, empirical analysis of the actual usage of APIs on Java, a modern, mature, and widely-used programming language. Our corpus contains over 5000 open-source Java projects, totaling 150 million source lines of code (SLoC). We study the usage of both core (official) API library and third-party (unofficial) API libraries. We resolve project dependencies automatically, generate accurate resolved abstract syntax trees (ASTs), capture used API entities from over 1.5 million ASTs, and measure the usage based on our defined metrics: frequency, popularity and coverage. Results Our study provides detailed quantitative information and yield insight, particularly, (1) confirms the conventional wisdom that the usage of APIs obeys Zipf distribution, (2) demonstrates that core API is not fully used (many classes, methods and fields have never been used), (3) discovers that deprecated API entities (in which some were deprecated long ago) are still widely used, (4) evaluates that the use of current compact profiles is under-utilized, (5) identifies API library coldspots and hotspots. Conclusions Our findings are suggestive of potential applications across language API design, optimization and restriction, API education, library recommendation and compact profile construction. © 2016 Elsevier B.V. All rights reserved.";"API usage, Empirical study, Java"
"Fysarakis K., Mylonakis D., Manifavas C., Papaefstathiou I.";"Node.DPWS: Efficient Web Services for the Internet of Things";"Interconnected computing systems in various forms will soon permeate our lives, realizing the Internet of Things (IoT) and letting us enjoy novel, enhanced services that promise to improve our everyday life. Nevertheless, this new reality introduces significant challenges in terms of performance, scaling, usability, and interoperability. Leveraging the benefits of service-oriented architectures (SOAs) can help alleviate many of the issues that developers, implementers, and users alike must face in the context of the IoT. Node.DPWS is a novel implementation of the Devices Profile for Web Services (DPWS) based on the Node.js platform. It comprises the first set of DPWS libraries available to Node.js developers and can be used to deploy lightweight, efficient, and scalable Web services over heterogeneous nodes, including devices with limited resources. A performance evaluation on typical embedded devices validated the benefits of Node.DPWS compared to alternative DPWS libraries. © 2016 IEEE.";"development tools, Devices Profile for Web Services, DPWS, Node.DPWS, Node.js, software development, software engineering, software libraries, standards, ubiquitous computing, Web services"
"Tsai C.-C., Jain B., Abdul N.A., Porter D.E.";"A study of modern Linux API usage and compatibility: What to support when you're supporting";"This paper presents a study of Linux API usage across all applications and libraries in the Ubuntu Linux 15.04 distribution. We propose metrics for reasoning about the importance of various system APIs, including system calls, pseudo-files, and libc functions. Our metrics are designed for evaluating the relative maturity of a prototype system or compatibility layer, and this paper focuses on compatibility with Linux applications. This study uses a combination of static analysis to understand API usage and survey data to weight the relative importance of applications to end users. This paper yields several insights for developers and researchers, which are useful for assessing the complexity and security of Linux APIs. For example, every Ubuntu installation requires 224 system calls, 208 ioctl, fcntl, and prctl codes and hundreds of pseudo files. For each API type, a significant number of APIs are rarely used, if ever. Moreover, several security-relevant API changes, such as replacing access with faccessat, have met with slow adoption. Finally, hundreds of libc interfaces are effectively unused, yielding opportunities to improve security and efficiency by restructuring libc. Copyright © 2016 held by owner/author(s)."
"Corraya A.D., Sumi M.A., Shachi S.I., Rahman Z.";"Guiding software developers by social networking application plug-in using the multiple bridge source repository through a data mining integrated approach";"In today's world social networking is an important (powerful) medium of mass communication. People of almost all classes have been interacting each other and sharing their views, moments and ideas by using enormous user friendly applications in different social networking sites. It is really unbelievable to find a person who has never heard about the social networking system. The available social networking sites usually opportune their users to develop various customized applications through particular templates and embedded sources of codes. The users with average knowledge of development often encounter difficulties to reuse those resources and eventually lack guidelines and necessary API recommendations. In our work, we have proposed a framework and model to help those apps developer through a user assistance plug-in tool that is able to provide identical API usage patterns and sequences in response to a particular user query. We have titled our system as Social Networking Application Plug-in (SNAP). It searches social networking apps repository where multiple storage are bridged and apply respective mining algorithm to find the relevant sequences to fulfill the user needs. It provides similar, most relevant and functional API usage scenarios as well as gives an option to choose, reuse and modify the recommended sources. From the investigations we have ever made, the SNAP approach is capable to recommend error-free, understandable and minimal API patterns. © 2015 IEEE.";"API Recommendations, Bridged Source Repository, Customized Application, Sequence Mining, Usage Scenario"
"Haydel N., Gesing S., Taylor I., Madey G., Dakkak A., De Gonzalo S.G., Hwu W.-M.W.";"Enhancing the Usability and Utilization of Accelerated Architectures via Docker";"Accelerated architectures such as GPUs (Graphics Processing Units) and MICs (Many Integrated Cores) have been proven to increase the performance of many algorithms compared to their CPU counterparts and are widely available in local, campus-wide and national infrastructures, however, their utilization is not following the same pace as their deployment. Reasons for the underutilization lay partly on the software side with proprietary and complex interfaces for development and usage. A common API providing an extra layer to abstract the differences and specific characteristics of those architectures would deliver a far more portable interface for application developers. This cloud challenge proposal presents such an API that addresses these issues using a container-based approach. The resulting environment provides Docker-based containers for deploying accelerator libraries, such as CUDA Toolkit, OpenCL and OpenACC, onto a wide variety of different platforms and operating systems. By leveraging the container approach, we can overlay accelerator libraries onto the host without needing to be concerned about the intricacies of underlying operating system of the host. Docker therefore provides the advantage of being easily applicable on diverse architectures, virtualizing the necessary environment and including libraries as well as applications in a standardized way. The novelty of our approach is the extra layer for utilization and device discovery in this layer improving the usability and uniform development of accelerated methods with direct access to resources. © 2015 IEEE.";"accelerated architectures, cloud computing, Docker, virtual machine, Virtualization"
"Ali-Gombe A., Ahmed I., Richard G.G., III, Roussev V.";"AspectDroid: Android app analysis system";"The growing threat to user privacy related to Android applications (apps) has tremendously increased the need for more reliable and accessible app analysis systems. This paper presents AspectDroid, an application-level system designed to investigate Android applications for possible unwanted activities. AspectDroid is comprised of app instrumentation, automated testing and containment systems. By using static bytecode instrumentation, AspectDroid weaves monitoring code into an existing application and provides data flow and sensitive API usage as well as dynamic instrumentation capabilities. The newly repackaged app is then executed either manually or via an automated testing module. Finally, the flexible containment provided by AspectDroid adds a layer of protection so that malicious activities can be prevented from affecting other devices. The accuracy score of Aspect Droid when tested on 105 DroidBench corpus shows it can detect tagged data with 95.29%. We further tested our system on 100 real malware families from the Drebin dataset [1]. The result of our analysis showed AspectDroid incurs approximately 1MB average total memory size overhead and 5.9% average increase in CPU-usage.";"Android, AspectJ, Dynamic analysis, Instrumentation"
"Mani S., Padhye R., Sinha V.S.";"Mining API expertise profiles with Partial Program Analysis";"A developer's API usage expertise can be estimated by analyzing source code that they have checked-in to a software repository. In prior work we proposed a system for creating a social network of developers centered around the APIs they use in order to recommend people and projects they might be interested in. The implementation of such a system requires analyzing code from repositories of large numbers of projects that use different build systems. Hence, one challenge is to determine the APIs referenced in code in these repositories without relying on the ability to resolve every project's external dependencies. In this paper, we consider a technique called Partial Program Analysis for resolving type bindings in Java source code in the absence of third-party library binaries. Another important design decision concerns the approach of associating such API references with the developers who authored them such as walking entire change history or use blame information. We evaluate these different design options on 4 open-source Java projects and found that both Partial Program Analysis and blame-based approach provide precision greater than 80%. However, use of blame as opposed to complete program history leads to significant recall loss, in most cases greater than 40%. © 2016 ACM.";"API usage expertise, Blame, Change history, Partial Program Analysis"
"Yuniarti A., Atidnminanto A., Mardasatria A., Hariadi R.R., Suciati N.";"3D ITS campus on the web: A WebGL implementation";"Multimedia web experience can be increased using 3D graphics on the web. Proprietary systems need specific plug-ins to download and install. Therefore, open standard methods have been used increasingly. WebGL is one of those that is a cross-platform, web standard for a 3D graphics API based on OpenGL ES 2.0. There are many other Javascript libraries that abstract WebGL and results in higher code level. One of the libraries is Three.js, the most popular library/API for WebGL-based 3D graphics. This paper proposed an implementation of WebGL and Three.js libraries for a 3D ITS Campus information system. The proposed system can be viewed using two modes: ground and free modes. In the ground view mode, users can not move in vertical direction. Whereas the free view mode enables users to move in any direction. A usability testing was performed after development. The participants consist of 12 postgraduate students who are currently studying at the Informatics Department ITS, graduated from both ITS and non-ITS campus in their previous study. Results from the experiment show that the proposed system effectively render the ITS campus (83% of participants successfully view the 3D ITS campus on their own computers) and most participants suggest to add more buildings and natural objects like trees and ponds to the system. © 2015 IEEE.";"3D graphics, 3D information system, ITS Campus, Three.js, WebGL"
"Nakajima A., Ono Y.";"The Prospect of Open Online e-Learning System Based on the Free Culture Movement - Development of YouTutors as an Auto-Assignment Generator by Utilizing Creative Commons Contents Online";"This paper is concerned with the educational potential of open-source contents online, such as the Creative Commons and open Application Programming Interface (API), with the Free Culture movement as backgrounds. As a case study, we propose an open online e-learning system 'You Tutors', which automatically generates language-training materials by utilizing Creative Commons videos and open API of YouTube. As an introduction, we discuss the copy left licensing system and Creative Commons as a representative achievement of the Free Culture movement. To understand the affinity of the interaction between education and the Free Culture movement, we investigate the history of the movement. Furthermore, we examine the concepts structures of some licensing systems born in the context of the movement. We review related case studies especially selected from among practical open educational challenges. Then, we describe the development of an online English e-learning system 'You Tutors' as an original case study. We illustrate a way to re-use the data on the web and a way to adapt the Creative Commons contents into the e-learning system by mash up techniques. We conducted a usability experiment in English classes at the University of Tsukuba and found that students evaluated the auto-generated assignment system using online resources as adequate, after their self-learning application. © 2015 IEEE.";"Creative Commons, e-leaning, Free Culture Movement, MOOCs, Open Source"
"Nguyen T.T., Pham H.V., Vu P.M., Nguyen T.T.";"Recommending API usages for mobile apps with hidden Markov model";"Mobile apps often rely heavily on standard API frameworks and libraries. However, learning to use those APIs is often challenging due to the fast-changing nature of API frameworks and the insufficiency of documentation and code examples. This paper introduces DroidAssist, a recommendation tool for API usages of Android mobile apps. The core of DroidAssist is HAPI, a statistical, generative model of API usages based on Hidden Markov Model. With HAPIs trained from existing mobile apps, DroidAssist could perform code completion for method calls. It can also check existing call sequences to detect and repair suspicious (i.e. unpopular) API usages. © 2015 IEEE.";"API usage, Statistical code completion"
"Suter P., Wittern E.";"Inferring web API descriptions from usage data";"We describe a set of techniques to infer structured descriptions of web APIs from usage examples. Using trained classifiers, we identify fixed and variable segments in paths, and tag parameters according to their types. We implemented our techniques and evaluated their precision on 10 APIs for which we obtained: 1) descriptions, manually written by the API maintainers, and 2) server logs of the API usage. Our experiments show that our system is able to reconstruct the structure of both simple and complex web API descriptions, outperforming an existing tool with similar goals. Finally, we assess the impact of noise in the input data on the results of our method. © 2015 IEEE.";"Learning descriptions, Web APIs"
"Nguyen A.T., Nguyen T.T., Nguyen T.N.";"Divide-and-conquer approach for multi-phase statistical migration for source code";"Prior research shows that directly applying phrase-based SMT on lexical tokens to migrate Java to C# produces much semantically incorrect code. A key limitation is the use of sequences in phrase-based SMT to model and translate source code with well-formed structures. We propose mppSMT, a divide-and-conquer technique to address that with novel training and migration algorithms using phrase-based SMT in three phases. First, mppSMT treats a program as a sequence of syntactic units and maps/translates such sequences in two languages to one another. Second, with a syntax-directed fashion, it deals with the tokens within syntactic units by encoding them with semantic symbols to represent their data and token types. This encoding via semantic symbols helps better migration of API usages. Third, the lexical tokens corresponding to each sememe are mapped or migrated. The resulting sequences of tokens are merged together to form the final migrated code. Such divide-and-conquer and syntax-direction strategies enable phrase-based SMT to adapt well to syntactical structures in source code, thus, improving migration accuracy. Our empirical evaluation on several real-world systems shows that 84.8 - 97.9% and 70 - 83% of the migrated methods are syntactically and semantically correct, respectively. 26.3 - 51.2% of total migrated methods are exactly matched to the human-written C# code in the oracle. Compared to Java2CSharp, a rule-based migration tool, it achieves higher semantic accuracy from 6.6 - 57.7% relatively. Importantly, it does not require manual labeling for training data or manual definition of rules. © 2015 IEEE.";"Language Migration, Statistical Machine Translation, Syntax-directed Translation"
"Le Roux P.B., Kroon S., Bester W.";"DSaaS: A cloud service for persistent data structures";"In an attempt to tackle shortcomings of current approaches to collaborating on the development of structured data sets, we present a prototype platform that allows users to share and collaborate on the development of data structures via a web application, or by using language bindings or an API. Using techniques from the theory of persistent linked data structures, the resulting platform delivers automatically version-controlled map and graph abstract data types as a web service. The core of the system is provided by a Hash Array Mapped Trie (HAMT) which is made confluently persistent by path-copying. The system aims to make efficient use of storage, and to have consistent access and update times regardless of the version being accessed or modified. Copyright © 2016 by SCITEPRESS-Science and Technology Publications, Lda. All rights reserved.";"Cloud Computing, DaaS, Hash-Array Mapped Trie, Persistent Data Structure, SaaS, Version Control System"
"Neville D., Malton A., Brain M., Kroening D.";"Towards automated bounded model checking of API implementations";"We introduce and demonstrate the viability of a novel technique for verifying that implementations of application program interfaces (APIs) are bug free. Our technique applies a new abstract interpretation to extract an underlying model of API usage, and then uses this to synthesise a set of verifiable program fragments. These fragments are evaluated using CBMC and any potentially spurious property violation is presented to a domain expert user. The user's response is then used to refine the underlying model of the API to eliminate false positives. The refinement-analysis process is repeated iteratively. We demonstrate the viability of the technique by showing how it can find an integer underflow within Google's Brotli, an underflow that has been shown to lead directly to allow remote attackers to execute arbitrary code in CVE 2016-1968. © 2016, CEUR-WS. All rights reserved."
"Rossi D.";"UML-based model-driven REST API development";"In the last few years we have witnessed the expansion of REST APIs as a method to implement machineto-machine interactions in open distributed systems. Recently REST APIs can also be found in several B2B and enterprise scenarios that were previously reserved to alternative technologies such as SOAP-based Web Services. Despite that, the development of REST-based solutions has remained mostly inspired by agile approaches with no or limited explicit modeling artifacts produced during the development process. This clashes with software development methods in which modeling artifacts are expected to be available for all developed software. Another problem is related to the resource-based nature of these APIs that miss standardized methods to discover and understand their capabilities akin to what object-oriented interfaces can do for objects and services. In this paper we propose a model-driven approach to REST API development, this approach is composed by two main steps: (i) UML modeling of the API using specific profiles and (ii) a model transformation that exploits RAML, a recent RESTful API modeling language, as an intermediate notation that can be used to automatically produce documentation and code for various languages/platforms. Copyright © 2016 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.";"Model-driven development, REST, UML, Web Services"
"Huang C.Y., Wu C.H.";"Design and implement an interoperable Internet of Things application based on an extended OGC sensorthings API Standard";"The Internet of Things (IoT) is an infrastructure that interconnects uniquely-identifiable devices using the Internet. By interconnecting everyday appliances, various monitoring and physical mashup applications can be constructed to improve people's daily life. However, IoT devices created by different manufacturers follow different proprietary protocols and cannot communicate with each other. This heterogeneity issue causes different products to be locked in multiple closed ecosystems that we call IoT silos. In order to address this issue, a common industrial solution is the hub approach, which implements connectors to communicate with IoT devices following different protocols. However, with the growing number of proprietary protocols proposed by device manufacturers, IoT hubs need to support and maintain a lot of customized connectors. Hence, we believe the ultimate solution to address the heterogeneity issue is to follow open and interoperable standard. Among the existing IoT standards, the Open Geospatial Consortium (OGC) SensorThings API standard supports comprehensive conceptual model and query functionalities. The first version of SensorThings API mainly focuses on connecting to IoT devices and sharing sensor observations online, which is the sensing capability. Besides the sensing capability, IoT devices could also be controlled via the Internet, which is the tasking capability. While the tasking capability was not included in the first version of the SensorThings API standard, this research aims on defining the tasking capability profile and integrates with the SensorThings API standard, which we call the extended-SensorThings API in this paper. In general, this research proposes a lightweight JSON-based web service description, the ""Tasking Capability Description"", allowing device owners and manufacturers to describe different IoT device protocols. Through the extended-SensorThings API, users and applications can follow a coherent protocol to control IoT devices that use different communication protocols, which could consequently achieve the interoperable Internet of Things infrastructure.";"Internet of Things, Interoperable, OGC SensorThings API"
"Türpe S.";"Idea: Usable platforms for secure programming – mining Unix for insight and guidelines";"Just as security mechanisms for end users need to be usable, programming platforms and APIs need to be usable for programmers. To date the security community has assembled large catalogs of dos and don’ts for programmers, but rather little guidance for the design of APIs that make secure programming easy and natural. Unix with its setuid mechanism lets us study usable security issues of programming platforms. Setuid allows certain programs to run with higher privileges than the user or process controlling them. Operating across a privilege boundary entails security obligations for the program. Obligations are known and documented, yet developers often fail to fulfill them. Using concepts and vocabulary from usable security and usability of notations theory, we can explain how the Unix platform provokes vulnerabilities in such programs. This analysis is a first step towards developing platform design guidelines to address human factors issues in secure programming. © Springer International Publishing Switzerland 2016."
"Hasegawa K., Kanayama N., Nishide T., Okamoto E.";"Software library for ciphertext/key-policy functional encryption with simple usability";"In traditional public key encryption schemes, data encrypted by a public key pk can be decrypted only by a secret key sk corresponding to pk, and the relation between pk and sk is static. Therefore, the schemes are unsuitable for control of access to a single data by several users. Meanwhile, functional encryption (FE) is an encryption scheme that provides more sophisticated and flexible relations between pk and sk. Thus, FE enables only one pk to encrypt the data with any conditions for decryption, so it is considered a very useful tool for the access control of data on the cloud server. However, implementing the current FE scheme is a non-trivial task because the deep knowledge of the scheme is required. This is an obstacle factor to deploy the FE scheme in the real-world security systems. In this paper, we propose an implementation of the FE (Ciphertext-Policy FE and Key-Policy FE, which are useful classes of FE) library usable even for people who do not have the deep knowledge of these schemes. © 2016 Information Processing Society of Japan.";"Attribute-based encryption, Functional encryption, Implementation"
"Li B., Zhang Y., Lyu C., Li J., Gu D.";"SSG: Sensor security guard for android smartphones";"The smartphone sensors provide extraordinary user experience in various Android apps, e.g. sport apps, gravity sensing games. Recent works have been proposed to launch powerful sensor-based attacks such as location tracing and sound eavesdropping. The use of sensors does not require any permission in Android apps, so these attacks are very difficult to be noticed by the app users. Furthermore, the combination of various kinds of sensors generates numerous types of attacks which are hard to be systematically studied. To better address the attacks, we have developed a taxonomy on sensor-based attacks from five aspects. In this work, we propose a sensor API hooking and information filtering framework, Sensor Security Guard (SSG). Unlike any rough hooking framework, this system provides finegrained processing for different security levels set by the users, or by default. The sensor data is blocked, forged or processed under different mode strategies and then returned to the apps. In addition, according to the taxonomy, SSG develops fine-grained corresponding countermeasures. We evaluate the usability of SSG on 30 popular apps chosen from Google Market. SSG does not cause any crash of either the Android system or the apps while working. The result indicated that SSG could significantly preserve the users’ privacy with acceptable energy lost. © Institute for Computer Sciences, Social Informatics and Telecommunications Engineering 2016.";"Android, Hook, Security, Sensor API"
"Holzschuher F., Peinl R.";"Querying a graph database - Language selection and performance considerations";"NoSQL and especially graph databases are constantly gaining popularity among developers as they promise to deliver superior performance when handling highly interconnected data compared to relational databases. Apache Shindig is the reference implementation for OpenSocial with a highly interconnected data model. However, it had a relational database as back-end. In this paper we describe our experiences with the graph database Neo4j as back-end and compare Cypher, Gremlin and Java as alternatives for querying data with MySQL. We consider performance as well as usability from a developer's perspective. Our results show that Cypher is a good query language in terms of code readability and has a moderate overhead for most queries (20-200%). However, it has to be supplemented with ""stored procedures"" to make up for some performance deficits in pattern matching queries (>1000%). The RESTful API is unusable slow, whereas our WebSocket connection performs significantly better (>650%). © 2015 Elsevier Inc. All rights reserved.";"Benchmarks, Graph databases, Graph query processing, Neo4j, Performance optimization, WebSocket"
"Furtado L., Miranda B., Neto N., Meiguins B.";"IVOrpheus: A proposal for interaction by voice commands in three-dimensional environments of information visualization";"IVOrpheus is an information visualization tool for three-dimensional data that allows user's interaction by voice commands, mouse and keyboard input. The visualization technique used was the scatterplot 3D, which was implemented using Jmathplot API, and the speech recognition in Brazilian Portuguese was performed by Coruja software. IVOrpheus was developed in Java following the architectural pattern MVC, design patterns and open technologies. In voice interaction, some usability guidelines have been set in interface building process, making it more intuitive and contributing to lower the user cognitive effort. In addition, initial usability tests with users were performed to evaluate the application interface with and without interaction by voice. The tasks with and without voice interaction have shown similar results of time and completeness. The speech recognizer achieved a word error rate of approximately 17%. © 2015 IEEE.";"3D scatterplot, Brazilian Portuguese, Information visualization, IVOrpheus, Voice recognition"
"Wu W., Khomh F., Adams B., Guéhéneuc Y.-G., Antoniol G.";"An exploratory study of api changes and usages based on apache and eclipse ecosystems";"Frameworks are widely used in modern software development to reduce development costs. They are accessed through their Application Programming Interfaces (APIs), which specify the contracts with client programs. When frameworks evolve, API backward-compatibility cannot always be guaranteed and client programs must upgrade to use the new releases. Because framework upgrades are not cost-free, observing API changes and usages together at fine-grained levels is necessary to help developers understand, assess, and forecast the cost of each framework upgrade. Whereas previous work studied API changes in frameworks and API usages in client programs separately, we analyse and classify API changes and usages together in 22 framework releases from the Apache and Eclipse ecosystems and their client programs. We find that (1) missing classes and methods happen more often in frameworks and affect client programs more often than the other API change types do, (2) missing interfaces occur rarely in frameworks but affect client programs often, (3) framework APIs are used on average in 35 % of client classes and interfaces, (4) most of such usages could be encapsulated locally and reduced in number, and (5) about 11 % of APIs usages could cause ripple effects in client programs when these APIs change. Based on these findings, we provide suggestions for developers and researchers to reduce the impact of API evolution through language mechanisms and design strategies. © 2015 Springer Science+Business Media New York,API changes, API usages, Data mining, Empirical study, Framework ecosystems, Framework evolution"
"Zou Y.R., Mustafa N., Memon N.A., Eid M.";"ECO ECO: Changing climate related behaviors for cellphone-based videogames";"Global climate change has become a major issue of today's human society. Since most of our human activity could potentially have big environmental impacts once accumulated, it is especially important that the public is educated with the environmental effects of their daily actions. This paper's main purpose is to propose a gamified system that leverages the high saturation of smartphones and the rising popularity of Internet of Things (IoT) to educate young children with environmental concepts as well as encouraging them to commit to real-life ""green habits"". An android mobile game Eco Eco was developed to demonstrate the concept and test the proposed system's effectiveness for young users. This Farmville-like game is played only by conducting real-life environmental activities like using a reusable water bottle, walking more steps instead of using cars, or reduce usage of household electricity. The game, developed with Unity3D utilizes the Google Fit API for step count, CloudSight API for image recognition and a connected smart device for monitoring energy usage. A preliminary user test was also conducted to improve the usability of the system as well as to test the effects of this system. © 2015 IEEE.";"haptic communication system, Serious Games, smartphone, technology for visually impaired"
"Coblenz M., Seacord R., Myers B., Sunshine J., Aldrich J.";"A course-based usability analysis of Cilk Plus and OpenMP";"Cilk Plus and OpenMP are parallel language extensions for the C and C++ programming languages. The CPLEX Study Group of the ISO/IEC C Standards Committee is developing a proposal for a parallel programming extension to C that combines ideas from Cilk Plus and OpenMP. We conducted a preliminary comparison of Cilk Plus and OpenMP in a master's level course on security to evaluate the design tradeoffs in the usability and security of these two approaches. The eventual goal is to inform decision-making within the committee. We found several usability problems worthy of further investigation based on student performance, including declaring and using reductions, multi-line compiler directives, and the understanda-bility of task assignment to threads. © 2015 IEEE.";"API usability, Cilk Plus, empirical studies of programmers, OpenMP, parallel programming"
"Godwin A., Scott T.D., Potvin G., Sonnert G., Sadler P.M.";"The academic performance index: Creating a more robust and less biased measure of student academic performance";"This paper introduces an alternative to singular performance measures through the creation of a scaled index incorporating a variety of performance factors indicating overall student success as well as the creation of similar sub-indices for performances in the particular areas of math, English, and science. These indices have been used in two studies based on nationally representative college student data: the Sustainability and Gender in Engineering (SaGE) and the Outreach Programs and Science Career Intentions (OPSCI) projects. The Academic Performance Index (API) is a scale constructed out of students' weighted high school GPA, available standardized test scores (ACT/SAT), AP test scores (if any), highest levels of various high school coursework taken, and college credit hours earned prior to enrolling in college. Importantly, the API uses any and all available data in these domains, which can be up to 42 different indicators for an individual student in the case of the SaGE project. This index shows less bias regarding race and gender, when compared with commonly-used standardized tests scores. Additionally, this item is psychometrically better at indicating variation across students' performance. © 2015 IEEE.";"academic performance, API, controls, measurements"
"Robillard M.P., Chhetri Y.B.";"Recommending reference API documentation";"Reference documentation is an important source of information on API usage. However, information useful to programmers can be buried in irrelevant text, or attached to a non-intuitive API element, making it difficult to discover. We propose to detect and recommend fragments of API documentation potentially important to a programmer who has already decided to use a certain API element. We categorize text fragments in API documentation based on whether they contain information that is indispensable, valuable, or neither. From the fragments that contain knowledge worthy of recommendation, we extract word patterns, and use these patterns to automatically find new fragments that contain similar knowledge in unseen documentation. We implemented our technique in a tool, Krec, that supports both information filtering and discovery. In an evaluation study with randomly-sampled method definitions from ten open source systems, we found that with a training set derived from about 1000 documentation units, we could issue recommendations with 90 % precision and 69 % recall. In a study involving ten independent assessors, indispensable knowledge items recommended for API types were judged useful 57 % of the time and potentially useful an additional 30 % of the time. © 2014, Springer Science+Business Media New York.";"API documentation, Application programming interfaces, Natural language processing, Recommendation systems, Text classification"
"Saied M.A., Benomar O., Sahraoui H.";"Visualization based API usage patterns refining";"Learning to use existing or new software libraries is a difficult task for software developers, which would impede their productivity. Most of existing work provided different techniques to mine API usage patterns from client programs, in order to help developers to understand and use existing libraries. However, considering only client programs to identify API usage patterns, is a strong constraint as collecting several similar client programs for an API is not a trivial task. And even if these clients are available, all the usage scenarios of the API of interest may not be covered by those clients. In this paper, we propose a visualization based approach for the refinement of Client-based Usage Patterns. We first visualize the patterns structure. Then we enrich the patterns with API methods that are semantically related to them, and thus may contribute together to the implementation of a particular functionality for potential client programs. © 2015 IEEE.";"Documentation, Layout, Libraries, Matrix decomposition, Semantics, Software, Visualization"
"Serrano M.A., Melani A., Vargas R., Marongiu A., Bertogna M., Quiñones E.";"Timing characterization of OpenMP4 tasking model";"OpenMP is increasingly being supported by the newest high-end embedded many-core processors. Despite the lack of any notion of real-time execution, the latest specification of OpenMP (v4.0) introduces a tasking model that resembles the way real-time embedded applications are modeled and designed, i.e., as a set of periodic task graphs. This makes OpenMP4 a convenient candidate to be adopted in future real-time systems. However, OpenMP4 incorporates as well features to guarantee backward compatibility with previous versions that limit its practical usability in real-time systems. The most notable example is the distinction between tied and untied tasks. Tied tasks force all parts of a task to be executed on the same thread that started the execution, whereas a suspended untied task is allowed to resume execution on a different thread. Moreover, tied tasks are forbidden to be scheduled in threads in which other non-descendant tied tasks are suspended. As a result, the execution model of tied tasks, which is the default model in OpenMP to simplify the coexistence with legacy constructs, clearly restricts the performance and has serious implications on the response time analysis of OpenMP4 applications, making difficult to adopt it in real-time environments. In this paper, we revisit OpenMP design choices, introducing timing predictability as a new and key metric of interest. Our first results confirm that even if tied tasks can be timing analyzed, the quality of the analysis is much worse than with untied tasks. We thus reason about the benefits of using untied tasks, deriving a response time analysis for this model, and so allowing OpenMP4 untied model to be applied to real-time systems. © 2015 IEEE.";"Analytical models, Force, Programming, Real-time systems, Scheduling algorithms, Synchronization"
"Chen X., Sime G., Lutteroth C., Weber G.";"OAuthHub-A Service for Consolidating Authentication Services";"OAuth has become a widespread authorization protocol to allow inter-enterprise sharing of user preferences and data: A Consumer that wants access to a user's protected resources held by a Service Provider can use OAuth to ask for the user's authorization for access to these resources. However, it can be tedious for a Consumer to use OAuth as a way to organize user identities, since doing so requires supporting all Service Providers that the Consumer would recognize as users' 'identity providers'. Each Service Provider added requires extra work, at the very least, registration at that Service Provider. Different Service Providers may differ slightly in the API they offer, their authentication/authorization process or even their supported version of OAuth. The use of different OAuth Service Providers also creates privacy, security and integration problems. Therefore OAuth is an ideal candidate for Software as a Service, while posing interesting challenges at the same time. We use conceptual modelling to derive new high-level models and provide an analysis of the solution space. We address the aforementioned problems by introducing a trusted intermediary-OAuth Hub-into this relationship and contrast it with a variant, OAuth Proxy. Instead of having to support and control different OAuth providers, Consumers can use OAuth Hub as a single trusted intermediary to take care of managing and controlling how authentication is done and what data is shared. OAuth Hub eases development and integration issues by providing a consolidated API for a range of services. We describe how a trusted intermediary such as OAuth Hub can fit into the overall OAuth architecture and discuss how it can satisfy demands on security, reliability and usability. © 2015 IEEE.";"Analytical models, Authentication, Authorization, Privacy, Protocols, Servers"
"Shugay M., Bagaev D.V., Turchaninova M.A., Bolotin D.A., Britanova O.V., Putintseva E.V., Pogorelyy M.V., Nazarov V.I., Zvyagin I.V., Kirgizova V.I., Kirgizov K.I., Skorobogatova E.V., Chudakov D.M.";"VDJtools: Unifying Post-analysis of T Cell Receptor Repertoires";"Despite the growing number of immune repertoire sequencing studies, the field still lacks software for analysis and comprehension of this high-dimensional data. Here we report VDJtools, a complementary software suite that solves a wide range of T cell receptor (TCR) repertoires post-analysis tasks, provides a detailed tabular output and publication-ready graphics, and is built on top of a flexible API. Using TCR datasets for a large cohort of unrelated healthy donors, twins, and multiple sclerosis patients we demonstrate that VDJtools greatly facilitates the analysis and leads to sound biological conclusions. VDJtools software and documentation are available at https://github.com/mikessh/vdjtools. © 2015 Shugay et al."
"Li Q., Li X.";"Android Malware Detection Based on Static Analysis of Characteristic Tree";"The number of mobile malware is greatly increasing and the malware detection malware has become a critical problem. Android is fast becoming the most popular mobile platform resulting in quick increase in malware targeting the platform. Current static-analysis practice on Android application package (APK) mainly uses the features such as signature, md5 hash, permissions, data flows, API (Application Programming Interface) calls and etc. Extracted from the manifest file and the code. Such features lack consideration on the APK code organizations and object hierarchy, and thus they may be ineffective in detecting and predicting an APK'S application behaviors and maliciousness. Our research aims to find and implement a novel API-usage characterization approach for Android APK on different layers of resolutions, namely packages, classes, functions and APIs. A tree structure called 'Characteristic Tree' is used to contain such API-usage information on different layers of the tree structure, and a comparison algorithm is designed for calculating characteristic-tree similarity. This new detection method detection provides more meticulous insights in classifying and detecting Android malware of different types and code families. The variations in API-usage on different code layers imply code functionalities and application behaviors, and thus they can be used to improve current static-analysis method in malware detection and signature generation. Realistic malware packet samples of various types and families were used to validate the proposed approach, and results were discussed for its performance and future improvement. © 2015 IEEE.";"android, apk, characteristic-tree, detection, dex, dynamic-analysis, malware, static-analysis"
"Nguyen H.A., Dyer R., Nguyen T.N., Rajan H.";"Consensus-based mining of API preconditions in big code";"Formal specifications for APIs help developers correctly use them and enable checker tools automatically verify their uses. However, formal specifications are not always available with released APIs. In this work, we demonstrate an approach for mining API preconditions from a large-scale corpus of open-source software. It considers conditions guarding API calls in client code as potential preconditions of the corresponding APIs. Then it uses consensus among a large number of API usages to keep the ones appearing in the majority. Finally, the mined preconditions are ranked based on their frequencies and reported to users. © 2015 ACM.";"API preconditions, Big code, JML, Software mining"
"Fischer L., Hanenberg S.";"An empirical investigation of the effects of type systems and code completion on API usability using TypeScript and JavaScript in MS visual studio";"Recent empirical studies that compared static and dynamic type systems on API usability showed a positive impact of static type systems on developer productivity in most cases. Nevertheless, it is unclear how large this effect is in comparison to other factors. One obvious factor in programming is tooling: It is commonly accepted that modern IDEs have a large positive impact on developers, although it is not clear which parts of modern IDEs are responsible for that. One possible- and for most developers obvious candidate-is code completion. This paper describes a 2×2 randomized trial that compares JavaScript and Microsoft's statically typed alternative TypeScript with and without code completion in MS Visual Studio. While the experiment shows (in correspondence to previous experiments) a large positive effect of the statically typed language TypeScript, the code completion effect is not only marginal, but also just approaching statistical significance. This seems to be an indicator that the effect of static type systems is larger than often assumed, at least in comparison to code completion.";"Code completion, Empirical research, Programming languages, Type systems"
"[No author name available]";"DLS 2015 - Proceedings of the 11th Symposium on Dynamic Languages";"The proceedings contain 14 papers. The topics discussed include: from APIs to languages: generalizing method names, a formalization of typed Lua, gradual certified programming in coq, message safety in dart, control-flow analysis of dynamic languages via pointer analysis, compiling for multi-language task migration, high-performance cross-language interoperability in a multi-language runtime, Java-to-JavaScript translation via structured control flow reconstruction of compiler IR, language-independent storage strategies for tracing-JIT-based virtual machines, measuring polymorphism in python programs, tracking down performance variation against source code evolution, server-side type profiling for optimizing client-side JavaScript engines, and an empirical investigation of the effects of type systems and code completion on API usability using TypeScript and JavaScript in MS visual studio."
"Knodel O., Spallek R.G.";"Computing framework for dynamic integration of reconfigurable resources in a cloud";"Integrating FPGAs into clouds or data centers allows easy access to such reconfigurable resources and provides a promising opportunity to improve both performance and energy efficiency of such systems. Although currently the use of FPGAs as hardware accelerators and especially in clouds is mainly a topic of research, the integration of reconfigurable virtualized resources will become a task of growing importance in the future. We developed a cloud management and hypervisor system called RC3E providing FPGA resources as a service. This paper introduces a computing framework which extends our hypervisor and allows multiple (virtual) user designs on a single physical FPGA. The communication between host and FPGA is implemented by a communication API on the host and the integration of high-level synthesis (HLS) to accelerate applications. We demonstrate the usability of our framework by implementing a sample user design on an FPGA and measuring the performance with up to four simultaneous virtual user designs. © 2015 IEEE.";"Cloud Computing, Field Programmable Gate Arrays, High-Level Synthesis, Virtualization"
"Kim B., Jung H.";"LW-RDMA: Design and implementation of a lightweight RDMA API for InfiniBand-based clusters";"Due to the development of low-latency networks such as InfiniBand and Myrinet, cluster-based computing systems are now commonly used when implementing computing-intensive applications. InfiniBand is the de-facto standard for highperformance cluster-based computing systems. InfiniBand supports RDMA (Remote Direct Memory Access) features and provides a native API for these features. The use of the native-API-like VPI Verbs API is not easy owing to its complexity. However, customizing and optimizing can be done to improve the development efficiency. In this paper, we design and implement a lightweight RDMA API to improve the usability and applicability of InfiniBand-based clusters. The proposed method is termed LW-RDMA. The LW-RDMA API is lightweight and simple to use by those without expertise in the area of InfiniBand architecture and/or related details. In the experimental results, the implemented LW-RDMA showed better data transfer efficiency performance in some cases when compared to other RDMA techniques. © 2015 ACM.";"API, Clusters, Data transfer efficiency, InfiniBand, Remote Direct Memory Access"
"Papadopoulos P., Loukopoulos T., Anagnostopoulos I., Tziritas N., Vassilakopoulos M.";"RAC: A remote application calling framework for coordination of mobile apps";"Mobile applications (apps) have become part of our everyday life with a constantly increasing market. Of particular interest are apps aiding planning and collaboration among family members, or between co-workers. The architecture of such apps usually involves some Cloud storage medium, through which group members post and retrieve data. Naturally, all participants must have the same app installed in their devices for collaboration to be possible. In this paper we investigate an alternative option instead of app collaboration which is based on remote application calling (RAC). Under the RAC framework, a trusted source is able to invoke application actions at other people's devices, without necessarily owning himself the application it handles. We discuss RAC design and implementation related issues, focusing on Android devices. The usability of our approach is demonstrated through two widely used apps: alarm clock and map. © 2015 ACM.";"Alarm clock, Android, Map, Message passing, Mobile applications, Remote action, Remote API calling, Remote invocation, Web service"
"Cramer T., Dietrich R., Terboven C., Müller M.S., Nagel W.E.";"Performance Analysis for Target Devices with the OpenMP Tools Interface";"The requirement for large compute capabilities led to a wide use of accelerated high performance computing systems. In order to lower the burden for programming these new architectures, user friendly programming paradigms like OpenACC and OpenMP have come to existence. They offer pragmas to shift effort from the programmer to the compiler and runtime system, particularly for data management. However, for further improvement of the usability an adequate tools support is required as well. In our work we present in detail a general extension to the upcoming OpenMP tools interface (OMPT) with respect to the new OpenMP 4.0 target constructs. This extension aims to be a portable, vendor- and platform independent interface to enable the use of performance analysis tools with OpenMP for Accelerators. Finally, we evaluate the approach in a reference implementation to prove the validity and usability with the help of an instrumented OpenMP runtime and the Score-P measurement infrastructure. © 2015 IEEE.";"accelerator, HPC, OMPT, OpenMP, performance analysis, runtime, Score-P"
"Xu X., Luis G.M., Lobov A., Lastra J.L.M.";"Multiple ontology workspace management and performance assessment";"This paper describes the development of a multiple ontology workspace management system and its performance assessment. This management system provides users with their own ontology workspace as a repository. It aims to facilitate the storage and manipulation of ontology models for knowledge driven manufacturing execution systems. The system uses Jena TDB API to maintain the file system on the server and utilizes Spring framework to provide RESTful web services to expose functionalities to the users such as user account creation, ontology model upload and SPARQL query services. Besides the web interface for the interaction between the user and the system, the system also provides web service endpoints that are compatible with other query engines based on Graph Store HTTP Protocol defined in standard SPARQL 1.1. User authentication is also introduced in the system in order to keep the privacy and integrity of the user data. In the end the performance is tested to evaluate its usability. The developed system offers adequate performance for a large number of users and enables the users to store and retrieve information of ontology anywhere as long as internet is available. As the result, it improves the availability of ontology as an important role in knowledge representation, knowledge acquisition and knowledge driven manufacturing systems. © 2015 IEEE.";"knowledge driven manufacturing systems, ontology model management, ontology service performance, ontology user authorization"
"Favario L., Meo A.R., Masala E.";"A New Platform for Cross-Repository Creation and Sharing of Educational Resources: Architecture and a Case Study";"Currently there is a large amount of educational resources available, developed by many educational institutions at all level. One of the main challenges is to make use of such wealth of material in a simple and effective way, especially when pre-university education is involved, ranging from primary schools to high schools. The main difficulties experienced by the teachers willing to tailor the available material to the specific needs of their class are typically the lack of available time and the difficulties in learning the peculiar procedures that each repository system (including CMS, LMS etc.) requires. This work presents an architecture to integrate different repository systems using the Content Management Interoperability Services (CMIS) API, as well as an integration layer that provides a much more simplified interface suitable for the needs of the content creators (i.e., Teachers), and the users of the contents (i.e., The learners). Both the technical aspects of integration and the usability issues from the point of view of the teachers are described and considered in the design. The first experiments, evaluated by means of performance indicators and some user feedbacks, show that the platform has the potential for widespread adoption in the Italian educational environment. © 2015 IEEE.";"CMIS, E-learning, Open source, Platform integration, Remote education"
"Ono Y., Ishii T., Ohnishi A.";"Construction of a voice-based asynchronous communication system utilizing speech recognition and its potential for EFL learners' speaking ability: A pilot study";"The present paper deals with the construction of an asynchronous voice-based computer-mediated communication (CMC) system for less confident English as a Foreign Language learners. The results from this pilot evaluation of the system are discussed in terms of its usability and effectiveness at reducing foreign language anxiety. The proposed system incorporates a browser-driven Automatic Speech Recognition (ASR) into a blog to provide real-time feedback on their pronunciation before posting. With the results from the questionnaire survey conducted in this pilot study, we demonstrate that this system reduces foreign language anxiety in speaking and increases motivation for less motivated learners. © 2015 IEEE.";"Asynchronous CMC, Speech recognition, Voice blog, Web Speech API"
"En X.D., Zhili Z.";"A Local Bounding Box Method for Campus Navigation Based on Baidu Map";"Baidu Map provides most of the path navigation in the cities, but it has some drawbacks in small regions, such as the incomplete description, updating not timely. Sometimes it will bring misleading for us. In this paper, a campus navigation system is designed based on Baidu map API, using PHP, JavaScript and xml technologies. The system can provide the basic map function and search the path navigation between any two points in the campus. First, draw the campus map in detail and cover it on the Baidu Map by using the Baidu Map API class. Then, reconstruct a campus's geographic information on the local database. At last, call the Baidu Map API Service class to draw the navigation path on the map. In this paper, in order to avoid the path spillover we proposed a method called ""Local Bounding Box (LBB)"", which solves the cross-border issues. © 2015 IEEE.";"Baidu Map API, Campus Navigation, Path Navigation, XML Data"
"Duncan B., Zhang Y.";"Neural networks for sentiment analysis on Twitter";"The online medium has become a significant way that people express their opinions online. Sentiment analysis can be used to find out the polarity of an opinion, such as positive, negative, or neutral. Sentiment analysis has applications such as companies getting their customer's opinions on their products, political sentiment analysis, or opinions on movie reviews. Recent research has involved looking at text from online blogs, tweets, online movie reviews, etc. to try and classify the text as being positive, negative, or neutral. For this research, a feedforward neural network will be experimented with for sentiment analysis of tweets. The training set of tweets are collected using the Twitter API using positive and negative keywords. The testing set of tweets are collected using the same positive and negative keywords. © 2015 IEEE.";"feedforward pattern network, sentiment analysis, text classification"
"Kuznetsov K., Gorla A., Tavecchia I., Groß F., Zeller A.";"Mining Android Apps for Anomalies";"How do we know a program does what it claims to do? Our CHABADA prototype can cluster Android™ apps by their description topics and identify outliers in each cluster with respect to their API usage. A ""weather"" app that sends messages thus becomes an anomaly, likewise, a ""messaging"" app would typically not be expected to access the current location and would also be identified. In this paper we present a new approach for anomaly detection that improves the classification results of our original CHABADA paper [. 1]. Applied on a set of 22,500+ Android applications, our CHABADA prototype can now predict 74% of novel malware and as such, without requiring any known malware patterns, maintains a false positive rate close to 10%. © 2015 Elsevier Inc. All rights reserved.";"Android apps, App mining, Application behavior, Description analysis, Malware detection"
"Bernal-Cárdenas C.";"Improving energy consumption in android apps";"Mobile applications sometimes exhibit behaviors that can be attributed to energy bugs depending on developer implementation decisions. In other words, certain design decisions that are technically ""correct"" might affect the energy performance of applications. Such choices include selection of color palettes, libraries used, API usage and task scheduling order. We study the energy consumption of Android apps using a power model based on a multi-objective approach that minimizes the energy consumption, maximizes the contrast, and minimizes the distance between the chosen colors by com- paring the new options to the original palette. In addition, the usage of unnecessary resources can also be a cause of energy bugs depending on whether or not these are implemented correctly. We present an opportunity for continuous investigation of energy bugs by analyzing components in the background during execution on Android applications. This includes a potential new taxonomy type that is not covered by state-of-the-art approaches. © 2015 ACM.";"Empirical study, Energy consumption, Mobile applications"
"Santos C., Martins F., Vasconcelos V.T.";"Deductive verification of parallel programs using why3";"The Message Passing Interface specification (MPI) defines a portable message-passing API used to program parallel computers. MPI programs manifest a number of challenges on what concerns correctness: sent and expected values in communications may not match, resulting in incorrect computations possibly leading to crashes, and programs may deadlock resulting in wasted resources. Existing tools are not completely satisfactory: model-checking does not scale with the number of processes, testing techniques wastes resources and are highly dependent on the quality of the test set. As an alternative, we present a prototype for a type-based approach to programming and verifying MPI-like programs against protocols. Protocols are written in a dependent type language designed so as to capture the most common primitives in MPI, incorporating, in addition, a form of primitive recursion and collective choice. Protocols are then translated into Why3, a deductive software verification tool. Source code, in turn, is written in Why ML, the language of the Why3 platform, and checked against the protocol. Programs that pass verification are guaranteed to be communication safe and free from deadlocks. We verified several parallel programs from textbooks using our approach, and report on the outcome. © C. Santos, F. Martins & V.T. Vasconcelos."
"Sohan S.M., Anslow C., Maurer F.";"A Case Study of Web API Evolution";"When applications are integrated using web APIs, changes on a web API may break the dependent applications. This problem exists because old versions of the APIs may no longer be supported, a lack of adequate documentation to upgrade to a newer version, and insufficient communication of changes. In this paper we conducted a case study of evolving Web APIs to investigate what changes are made between versions and how the changes are documented and communicated to the API users. The findings are a list of recommendations for practitioners and researchers based on API change profiles, versioning, documentation and communication approaches that are observed in practice. This study will help inform developers of evolving Web APIs to make decision about versioning, documentation and communication methods. © 2015 IEEE.";"Case Study, RESTful, SOAP, Web API Evolution, WSDL"
"Saied M.A., Abdeen H., Benomar O., Sahraoui H.";"Could We Infer Unordered API Usage Patterns Only Using the Library Source Code?";"Learning to use existing or new software libraries is a difficult task for software developers, which would impede their productivity. Much existing work has provided different techniques to mine API usage patterns from client programs in order to help developers on understanding and using existing libraries. However, considering only client programs to identify API usage patterns is a strong constraint as the client programs source code is not always available or the clients themselves do not exist yet for newly released APIs. In this paper, we propose a technique for mining Non Client-based Usage Patterns (NCBUP miner). We detect unordered API usage patterns as distinct groups of API methods that are structurally and semantically related and thus may contribute together to the implementation of a particular functionality for potential client programs. We evaluated our technique through four APIs. The obtained results are comparable to those of client-based approaches in terms of usage-patterns cohesion. © 2015 IEEE.";"API Documentation, API Usage, Software Clustering, Usage Pattern"
"Sushine J., Herbsleb J.D., Aldrich J.";"Searching the State Space: A Qualitative Study of API Protocol Usability";"Application Programming Interfaces (APIs) often define protocols - restrictions on the order of client calls to API methods. API protocols are common and difficult to use, which has generated tremendous research effort in alternative specification, implementation, and verification techniques. However, little is understood about the barriers programmers face when using these APIs, and therefore the research effort may be misdirected. To understand these barriers better, we perform a two-part qualitative study. First, we study developer forums to identify problems that developers have with protocols. Second, we perform a think-aloud observational study, in which we systematically observe professional programmers struggle with these same problems to get more detail on the nature of their struggles and how they use available resources. In our observations, programmer time was spent primarily on four types of searches of the protocol state space. These observations suggest protocol-targeted tools, languages, and verification techniques will be most effective if they enable programmers to efficiently perform state search. © 2015 IEEE.";"APIs, protocols, qualitative research, typestate"
"[No author name available]";"IEEE International Conference on Program Comprehension";"The proceedings contain 38 papers. The topics discussed include: discovering loners and phantoms in commit and issue data, i know what you did last summer - an investigation of how developers spend their time, generating reproducible and replayable bug reports from android application crashes, searching the state space: a qualitative study of API protocol usability, generating refactoring proposals to remove clones from automated system tests, code, camera, action: how software developers document and share program knowledge using YouTube, two user perspectives in program comprehension: end users and developer users, exploring the use of concern element role information in feature location evaluation, manually locating features in industrial source code: the search actions of software nomads, the plague doctor: a promising cure for the window plague, and polymorphism in the spotlight: studying its prevalence in Java and SmallTalk."
"Sawant A.A., Bacchelli A.";"A dataset for API usage";"An Application Programming Interface (API) provides a specific set of functionalities to a developer. The main aim of an API is to encourage the reuse of already existing functionality. There has been some work done into API popularity trends, API evolution and API usage. For all the aforementioned research avenues there has been a need to mine the usage of an API in order to perform any kind of analysis. Each one of the approaches that has been employed in the past involved a certain degree of inaccuracy as there was no type check that takes place. We introduce an approach that takes type information into account while mining API method invocations and annotation usages. This approach accurately makes a connection between a method invocation and the class of the API to which the method belongs to. We try collecting as many usages of an API as possible, this is achieved by targeting projects hosted on GitHub. Additionally, we look at the history of every project to collect the usage of an API from earliest version onwards. By making such a large and rich dataset public, we hope to stimulate some more research in the field of APIs with the aid of accurate API usage samples. © 2015 IEEE.";"API usage, Dataset, GitHub"
"Wang W., Malik H., Godfrey M.W.";"Recommending posts concerning API issues in developer Q&A sites";"API design is known to be a challenging craft, as API designers must balance their elegant ideals against 'real-world' concerns, such as utility, performance, backwards compatibility, and unforeseen emergent uses. However, to date, there is no principled method to collect or analyze API usability information that incorporates input from typical developers. In practice, developers often turn to Q&A websites such as stackoverflow.com (SO) when seeking expert advice on API use, the popularity of such sites has thus led to a very large volume of unstructured information that can be searched with diligence for answers to specific questions. The collected wisdom within such sites could, in principle, be of great help to API designers to better support developer needs, if only it could be collected, analyzed, and distilled for practical use. In this paper, we present a methodology that combines several techniques, including social network analysis and topic mining, to recommend SO posts that are likely to concern API design-related issues. To establish a comparison baseline, we introduce two more recommendation approaches: a reputation-based recommender and a random recommender. We have found that when applied to Q&A discussion of two popular mobile platforms, Android and iOS, our methodology achieves up to 93% accuracy and is more stable with its recommendations when compared to the two baseline techniques. © 2015 IEEE.";"API usability, Application program interfaces, Online Q&A, Recommendation systems, Software ecosystems, Stackoverflow"
"Perakakis E., Ghinea G.";"HTML5 Technologies for Effective Cross-Platform Interactive/Smart TV Advertising";"Developing an interactive TV Commercial (iTVC) for Internet connected TVs is complicated by the number of different platforms, each with its own operating system and application programming interface (API). To achieve cross-platform compatibility, we propose to use standard web technologies, instead of proprietary APIs for each device. With our approach, only one iTVC was developed, which contained commonly used features of these kinds of advertisements, and used only web technologies (HTML5, CSS, and JavaScript). The iTVC was first developed on a desktop personal computer and was tested on three different smart TV platforms for feature compatibility. After achieving compatibility, a user study with 36 participants evaluated how platform-related differences affect aspects of user experience (UX) and effectiveness of the interactive ad. The measured UX/effectiveness aspects and usability were consistent regardless of the iTVC performance on each device. These results show the potential of web technologies to deliver a uniform (and effective) interactive Ad across a range of heterogeneous devices. © 2013 IEEE.";"Interactive TV advertising, smart TV advertising, t-commerce, user experience (UX)"
"Heiland R., Koranda S., Marru S., Pierce M., Welch V.";"Authentication and authorization considerations for a multi-tenant service";"Distributed cyberinfrastructure requires users (and machines) to perform some sort of authentication and authorization (together simply known as auth). In the early days of computing, authentication was performed with just a username and password combination, and this is still prevalent today. But during the past several years, we have seen an evolution of approaches and protocols for auth: Kerberos, SSH keys, X.509, OpenID, API keys, OAuth, and more. Not surprisingly, there are trade-offs, both technical and social, for each approach. The NSF Science Gateway communities have had to deal with a variety of auth issues. However, most of the early gateways were rather restrictive in their model of access and development. The practice of using community credentials (certificates), a well-intentioned idea to alleviate restrictive access, still posed a barrier to researchers and challenges for security and auditing. And while the web portal-based gateway clients offered users easy access from a browser, both the interface and the back-end functionality were constrained in the flexibility and extensibility they could provide. Designing a well-defined application programming interface (API) to fine-grained, generic gateway services (on secure, hosted cyberinfrastructure), together with an auth approach that has a lower barrier to entry, will hopefully present a more welcoming environment for both users and developers. This paper provides a review and some thoughts on these topics, with a focus on the role of auth between a Science Gateway and a service provider.";"API keys, Authentication, OAuth, Usability, X.509"
"Calabria A., Spinozzi G., Benedicenti F., Tenderini E., Montini E.";"adLIMS: A customized open source software that allows bridging clinical and basic molecular research studies";"Background: Many biological laboratories that deal with genomic samples are facing the problem of sample tracking, both for pure laboratory management and for efficiency. Our laboratory exploits PCR techniques and Next Generation Sequencing (NGS) methods to perform high-throughput integration site monitoring in different clinical trials and scientific projects. Because of the huge amount of samples that we process every year, which result in hundreds of millions of sequencing reads, we need to standardize data management and tracking systems, building up a scalable and flexible structure with web-based interfaces, which are usually called Laboratory Information Management System (LIMS). Methods: We started collecting end-users' requirements, composed of desired functionalities of the system and Graphical User Interfaces (GUI), and then we evaluated available tools that could address our requirements, spanning from pure LIMS to Content Management Systems (CMS) up to enterprise information systems. Our analysis identified ADempiere ERP, an open source Enterprise Resource Planning written in Java J2EE, as the best software that also natively implements some highly desirable technological advances, such as the high usability and modularity that grants high use-case flexibility and software scalability for custom solutions. Results: We extended and customized ADempiere ERP to fulfil LIMS requirements and we developed adLIMS. It has been validated by our end-users verifying functionalities and GUIs through test cases for PCRs samples and pre-sequencing data and it is currently in use in our laboratories. adLIMS implements authorization and authentication policies, allowing multiple users management and roles definition that enables specific permissions, operations and data views to each user. For example, adLIMS allows creating sample sheets from stored data using available exporting operations. This simplicity and process standardization may avoid manual errors and information backtracking, features that are not granted using track recording on files or spreadsheets. Conclusions: adLIMS aims to combine sample tracking and data reporting features with higher accessibility and usability of GUIs, thus allowing time to be saved on doing repetitive laboratory tasks, and reducing errors with respect to manual data collection methods. Moreover, adLIMS implements automated data entry, exploiting sample data multiplexing and parallel/transactional processing. adLIMS is natively extensible to cope with laboratory automation through platform-dependent API interfaces, and could be extended to genomic facilities due to the ERP functionalities. © 2015 Calabria et al."
"Mitra R.";"Rapido: A sketching tool for web API designers";"Well-designed Web APIs must provide high levels of usability and must ""get it right"" on the first release. One strategy for accomplishing this feat is to identify usability issues early in the design process before a public release. Sketching is a useful way of improving the user experience early in the design phase. Designers can create many sketches and learn from them. The Rapido tool is designed to automate the Web API sketching process and help designers improve usability in an iterative fashion.";"API, Design, REST, Sketching, Usability, Web API"
"Schäfer T., Scheck A., Bruneß D., May P., Koch I.";"The new protein topology graph library web server";"Summary: We present a new, extended version of the Protein Topology Graph Library web server. The Protein Topology Graph Library describes the protein topology on the super-secondary structure level. It allows to compute and visualize protein ligand graphs and search for protein structural motifs. The new server features additional information on ligand binding to secondary structure elements, increased usability and an application programming interface (API) to retrieve data, allowing for an automated analysis of protein topology. © The Author 2015. Published by Oxford University Press."
"Schreiner M., Rädle R., Jetter H.-C., Reiterer H.";"Connichiwa - A framework for cross-device web applications";"While Mark Weiser's vision of ubiquitous computing is getting closer to reality, a fundamental part of it-the interconnection of devices into a ""ubiquitous network"",-is not achieved yet. Differences in hardware, architecture, and missing standardizations are just some reasons for this. We think that existing research is not versatile enough and too tailored to either single applications, hardware, or location. We contribute Connichiwa-a versatile framework for creating web applications across multiple devices. We base Connichiwa on four key goals: integration of existing devices, independence of network infrastructure, versatility of application scenario, and usability of its API. Connichiwa runs web applications on off-the-shelf consumer devices. With no external dependencies, such as a server, it enables a great variety of possible scenarios. We tested the technical feasibility of Connichiwa in seven example applications and plan to evaluate the framework and the usability of its API in a one-week Hackathon.";"Cross-device, Framework, Ubiquitous networks, Web"
"Malloch J., Sinclair S., Wanderley M.M.";"Distributed tools for interactive design of heterogeneous signal networks";"We introduce libmapper, an open source, cross-platform software library for flexibly connecting disparate interactive media control systems at run-time. This library implements a minimal, openly-documented protocol meant to replace and improve on existing schemes for connecting digital musical instruments and other interactive systems, bringing clarified, strong semantics to system messaging and description. We use automated discovery and message translation instead of imposed system-representation standards to approach “plug-and-play” usability without sacrificing design flexibility. System modularity is encouraged, and data are transported between peers without centralized servers. © 2014, Springer Science+Business Media New York.";"Media mapping, Networking"
"Lamba Y., Khattar M., Sureka A.";"Pravaaha: Mining android applications for discovering API call usage patterns and trends";"Software libraries and frameworks, consisting of a collection of Class and Interface definitions, provide a mechanism for code reuse by providing methods, APIs, components (generic functionality) and a support structure for developers to build applications, products and solutions. KitKat, Jelly Bean, Ice Cream Sandwich, Honeycomb and Gingerbread are different versions (open-source) of Android, one of the most popular mobile platforms in the world. In this paper, we present the results of our large-scale (consisting of 1, 120 open-source applications and 17:4 million lines of code) API usage analysis of Android applications. Our work is motivated by the need to mine actual Android API usage, frequent API call usage patterns and trends to understand and generate empirical data on how developers are using the mobile platform in their applications. Extracting popular and frequently-invoked methods, API packages and API call-usage patterns is useful to both the API Producers and API Consumers. For example, API Producers can view the quantitative data on API usage as a feedback from users on the relevance, usability and applicability of the respective APIs. We conduct a series of experiments on analysing the Android platform API usage (usage of different packages, usage of methods, usage across categories) and present the results of our analysis using graphs such as Bubble Chart, Radar Chart, Heat-Map for effective visualization of the results and for extraction of actionable information. Copyright 2015 ACM.";"Android applications, API call usage patterns, Empirical software engineering and measurements, Mining software repositories"
"Niu H., Keivanloo I., Zou Y.";"API usage pattern recommendation for software development";"Application Programming Interfaces (APIs) facilitate pragmatic reuse and improve the productivity of software development. An API usage pattern documents a set of method calls from multiple API classes to achieve a reusable functionality. Existing approaches often use frequent-sequence mining to extract API usage patterns. However, as reported by earlier studies, frequent-sequence mining may not produce a complete set of usage patterns. In this paper, we explore the possibility of mining API usage patterns without relying on frequent-pattern mining. Our approach represents the source code as a network of object usages where an object usage is a set of method calls invoked on a single API class. We automatically extract usage patterns by clustering the data based on the co-existence relations between object usages. We conduct an empirical study using a corpus of 11,510 Android applications. The results demonstrate that our approach can effectively mine API usage patterns with high completeness and low redundancy. We observe 18% and 38% improvement on F-measure and response time respectively comparing to usage pattern extraction using frequent-sequence mining. © 2016 Elsevier Inc.";"Clustering, Object usage, Usage pattern"
"Scheller T., Kühn E.";"Automated measurement of API usability: The API Concepts Framework";"Context Usability is an important software quality attribute for APIs. Unfortunately, measuring it is not an easy task since many things like experienced evaluators, suitable test users, and a functional product are needed. This makes existing usability measurement methods difficult to use, especially for non-professionals. Objective To make API usability measurement easier, an automated and objective measurement method would be needed. This article proposes such a method. Since it would be impossible to find and integrate all possible factors that influence API usability in one step, the main goal is to prove the feasibility of the introduced approach, and to define an extensible framework so that additional factors can easily be defined and added later. Method A literature review is conducted to find potential factors influencing API usability. From these factors, a selected few are investigated more closely with usability studies. The statistically evaluated results from these studies are used to define specific elements of the introduced framework. Further, the influence of the user as a critical factor for the framework's feasibility is evaluated. Results The API Concepts Framework is defined, with an extensible structure based on concepts that represent the user's actions, measurable properties that define what influences the usability of these concepts, and learning effects that represent the influence of the user's experience. A comparison of values calculated by the framework with user studies shows promising results. Conclusion It is concluded that the introduced approach is feasible and provides useful results for evaluating API usability. The extensible framework easily allows to add new concepts and measurable properties in the future. © 2015 Elsevier B.V. All rights reserved.";"API design, API usability, Complexity measures, Metrics"
"Rama G.M., Kak A.";"Some structural measures of API usability";"In this age of collaborative software development, the importance of usable APIs is well recognized. There already exists a rich body of literature that addresses issues ranging from how to design usable APIs to assessing qualitatively the usability of a given API. However, there does not yet exist a set of general-purpose metrics that can be pressed into service for a more quantitative assessment of API usability. The goal of this paper is to remedy this shortcoming in the literature. Our work presents a set of formulas that examine the API method declarations from the perspective of several commonly held beliefs regarding what makes APIs difficult to use.We validate the numerical characterizations of API usability as produced by our metrics through the APIs of several software systems. Copyright © 2013 John Wiley & Sons, Ltd.";"API usability, Application programming interface, Metrics"
"Saied M.A., Sahraoui H., Dufour B.";"An observational study on API usage constraints and their documentation";"Nowadays, APIs represent the most common reuse form when developing software. However, the reuse benefits depend greatly on the ability of client application developers to use correctly the APIs. In this paper, we present an observational study on the API usage constraints and their documentation. To conduct the study on a large number of APIs, we implemented and validated strategies to automatically detect four types of usage constraints in existing APIs. We observed that some of the constraint types are frequent and that for three types, they are not documented in general. Surprisingly, the absence of documentation is, in general, specific to the constraints and not due to the non documenting habits of developers. © 2015 IEEE."
"Saied M.A., Benomar O., Abdeen H., Sahraoui H.";"Mining multi-level API usage patterns";"Software developers need to cope with complexity of Application Programming Interfaces (APIs) of external libraries or frameworks. However, typical APIs provide several thousands of methods to their client programs, and such large APIs are difficult to learn and use. An API method is generally used within client programs along with other methods of the API of interest. Despite this, co-usage relationships between API methods are often not documented. We propose a technique for mining Multi-Level API Usage Patterns (MLUP) to exhibit the co-usage relationships between methods of the API of interest across interfering usage scenarios. We detect multi-level usage patterns as distinct groups of API methods, where each group is uniformly used across variable client programs, independently of usage contexts. We evaluated our technique through the usage of four APIs having up to 22 client programs per API. For all the studied APIs, our technique was able to detect usage patterns that are, almost all, highly consistent and highly cohesive across a considerable variability of client programs. © 2015 IEEE.";"API Documentation, API Usage, Software Clustering, Usage Pattern"
"[No author name available]";"2015 IEEE 22nd International Conference on Software Analysis, Evolution, and Reengineering, SANER 2015 - Proceedings";"The proceedings contain 84 papers. The topics discussed include: modeling the evolution of development topics using dynamic topic models, understanding developers' natural language queries with interactive clarification, an observational study on API usage constraints and their documentation, an observational study on API usage constraints and their documentation, measuring the quality of design pattern detection results, JCHARMING: a bug reproduction approach using crash traces and directed model checking, towards a common metamodel for traces of high performance computing systems to enable software analysis tasks, automated extraction of failure reproduction steps from user interaction traces, misery loves company: crowdstacking traces to aid problem detection, and who should review my code? a file location-based code-reviewer recommendation approach for modern code review."
"Pigula P., Nosál M.";"Unified compile-time and runtime Java annotation processing";"Java provides two different options for processing source code annotations. One of them is the annotation processing API used in compile time, and the other is the Reflection API used in runtime. Both options provide different API for accessing program metamodel. In this paper, we examine the differences between those representations and we discuss options on how to unify these models along with advantages and disadvantages of this approach. Based on this proposal, we design a unified Java language model and present a prototype tool which can populate a unified model during both compilation and runtime. The paper includes the designed API of this unified language model. To verify our approach, we have performed experiments to show the usability of the unified metamodel. © 2015, IEEE."
"Kapros E., Peirce N.";"Usability of educational technology APIs: Findings and guidelines";"This paper describes a project that reviewed the usability of existing Educational Technology Application Programming Interfaces (EdTech APIs). The focus was on web-based APIs and the portals through which these are offered to developers. After analysing the state of art with regard to existing EdTech APIs and after conducting a literature review on API usability, a survey was circulated among developers and CTOs of EdTech organisations. The results of the aforementioned three steps were triangulated and resulted in usability guidelines for EdTech APIs. The contribution of this project is twofold: firstly, the production of a concrete set of EdTech API usability guidelines and, secondly, their implementation in a proof-of-concept a portal for two different EdTech offerings. © Springer International Publishing Switzerland 2015.";"API, Programming, Usability"
"Kinash N., Tikhomirov A., Trufanov A., Berestneva O., Boukhanovsky A., Ashurova Z.";"Analysis of large-scale networks using high performance technology (vkontakte case study)";"Case study Vkontakte presents an approach to the analysis of large-scale social networks. The paper describes the API usage to design the friend lists for construction of massive social network. It will avoid errors during the building process and select the most efficient parallel graph frameworks for the large network analysis. The case studied the basic parameters of the network Vkontakte, and determined its topology different from scale-free character. The collected dataset is opened for free public download. © Springer International Publishing Switzerland 2015.";"Dataset, Large-scale networks, Vulnerability metrics"
"Businge J., Serebrenik A., van den Brand M.G.J.";"Eclipse API usage: the good and the bad";"Today, when constructing software systems, many developers build their systems on top of frameworks. Eclipse is such a framework that has been in existence for over a decade. Like many other evolving software systems, the Eclipse platform has both stable and supported interfaces (“good”) and unstable, discouraged and unsupported interfaces (“bad”). In this study, we investigate Eclipse interface usage by Eclipse third-party plug-ins (ETPs) based on whether they use bad interfaces or not. The investigations, based on empirical analysis present the following observations. First, we discovered that 44 % of the 512 analyzed Eclipse third-party plug-ins depend on “bad” interfaces and that developers continue to use “bad” interfaces. Second, we have observed that plug-ins that use or extend at least one “bad” interface are comparatively larger and use more functionality from Eclipse than those that use only “good” interfaces. Third, the findings show that the ETPs use a diverse set of “bad” interfaces. Fourth, we observed that the reason why the bad interfaces are being eliminated from the ETPs’ source code is, because (ETP developers believe) these non-APIs will cause incompatibilities when a version of the ETP is ported to new Eclipse SDK release. Finally, we observed that when developers eliminate problematic “bad” interfaces, they either re-implement the same functionality in their own API, find equivalent SDK good interfaces, or completely delete the entities in the ETPs’ source code that use the functionality from the “bad” interfaces. © 2013, Springer Science+Business Media New York.";"API usage, Eclipse, Software evolution"
"Aibin M., Blazejewski M.";"Complex Elastic Optical Network Simulator (CEONS)";"This paper presents the features of an advanced software simulator for the Elastic Optical Network (EON) - Complex Elastic Optical Networks Simulator (CEONS). The CEONS is as a test environment for solving three main issues addressed in EON: Routing and Spectrum Assignment (RSA) problems, Routing, Modulation and Spectrum Assignment (RMSA) problems, and addressing regenerator placement problem. With a universal API, users can design their own algorithms in any programming language and implement them in the simulator as plugins to solve the problems mentioned above. The ease and versatility of implementing the algorithms allows usage of the CEONS in advanced problems and for the introduction of EON technology. © 2015 IEEE.";"Dynamic routing, Elastic optical networks, Regenerator placement, Simulator, Software"
"Tsouroplis R., Petychakis M., Alvertis I., Biliri E., Lampathaki F., Askounis D.";"Internet-based enterprise innovation through a community-based API builder to manage APIs";"More and more users, these days, keep fragmented data across the web in different applications, through various types of devices, PC, mobiles, wearable devices, etc. By taking advantage of an aggregative Graph Application Programming Interface (API), users have the ability to harness shattered data and keep them into a privacy-aware platform (Cloudlet) where permissions can be applied, and therefore let developers build useful applications from it. To make this unifying Graph API, the API Builder is proposed, as a tool for easily creating new APIs and connecting them with existing ones from Cloud-based Services (CBS), thus providing integration among services and making it easier for users and/or enterprises to reach a larger audience while conveying their message. Typical obstacles, like keeping up to date with CBS API versioning, that seems daunting for developers, are also tackled through semi-automation and the help of the community empowering the API Builder. In that way, application developers do not have to worry for merging various APIs or if the application-generated data are locked in silos of companies, now the user is the judge who gives access to their data and meta-data (i.e. especially context), to enable smarter, context-adaptive and richer in content applications. © 2015 Springer International Publishing Switzerland.";"APIs, Cloud-based services, Community-based platform, Evolving APIs API Builder, Graph API"
"Rizzardini R.H.";"Cloud interoperability service architecture for education environments";"MOOC adoption is growing, and several challenges are presented with it. One of them is the use of innovative tools for learning, with a special emphasis in having learners to represent their acquired knowledge in creative forms, therefore, some experiences in that regard will be introduced. Thus, orchestrating the learning experience with cloud-based external tools (realized as Web 2.0 tools) brings interoperability issues such as automated management of tools and interoperability scalability. This paper presents a new version of an architecture that is capable of interoperability with external tools by defining a semantic description of the tools' Web API using linked data. This creates the next generation of tool interoperability for educational environments. Furthermore, it makes machine discovery of the Web API possible, therefore, it does not require custom system interfaces to interoperate. It simplifies the plugging in of new external tools and maintenance of integrated services. Additionally, the architecture makes it possible to automate simple and complex tasks to be performed with the external tools, such as creating thousands of tool instances to be used by MOOC learners. The results are very promising and demonstrate that this approach is innovative, scalable and highly accurate. Currently, no standard, specification or framework has the same type of flexibility, integration simplicity and robust management for external tools. © J.UCS.";"Cloud education environments, Cloud-based tools, Hydra, Interoperability, JSON-LD, MOOC, Scalability, Semantic web, Vocabularies"
"González-Burgueño A., Santiago S., Escobar S., Meadows C., Meseguer J.";"Analysis of the PKCS#11 API using the maude-NPA tool";"Cryptographic Application Programmer Interfaces (Crypto APIs) are designed to allow a secure interoperation between applications and cryptographic devices such as smartcards and Hardware Security Modules (HSMs). However, several Crypto APIs have been shown to be subject to attacks in which sensitive information is disclosed to an attacker, such as the RSA Laboratories Public Key Standards PKCS#11, an API widely adopted in industry. Recently, there has been a growing interest on applying automated crypto protocol analysis methods to formally analyze APIs. However, the PKCS#11 has been proven difficult to analyze using such methods since it involves non-monotonic mutable global state. In this paper we specify and analyze the PKCS#11 in Maude-NPA, a general purpose crypto protocol analysis tool. © Springer International Publishing Switzerland 2015.";"Cryptographic application programming interfaces (cryptographic APIs), Maude-NPA, PKCS#11, Symbolic cryptographic protocol analysis"
"George J.A., Hemalatha M.";"Improving authentication and authorization for identity based cloud environment using oauth with fuzzy based blowfish algorithm";"Cloud computing involves group of remote servers, software, networks, centralized storage, which allows different number of online services and resources to virtualized business environment, individual users and educational institutions. But the main challenges are security between the user information, trust between the user and service provider. In business environment, Private Cloud Model (PCM) provides tight security of the application data even though in cloud, security issues such as authorization, confidentiality still exist. Therefore, the paper focuses on security, authentication and authorization using OAuth protocol. OAuth protocol authorizes the user while accessing the data from one application via another application for managing identities. OAuth HTTP based protocol is used for authorization and security is implemented using Fuzzy based blowfish encryption algorithm (FBFE). In OAuth, authorization is granted in four different ways like authorization code, implicit, resource owner password credential and client credential. OAuth establishes authorization between application and API user using token and redirect URI. © 2015 Praise Worthy Prize S.r.l. - All rights reserved.";"Authorization, Client credential, Fuzzy based blowfish algorithm, HTTP, OAuth private cloud model, Resource owner credential"
"Abbasi A.A., Jin H., Wu S.";"A software-defined cloud resource management framework";"Network systems employ policies that are inherently dynamic in nature and that depend on temporal conditions defined in terms of external events such as the measurement of bandwidth, use of hosts, intrusion detection or specific time events. Software-defined networking (SDN) offers the opportunity to make networks easier to configure by providing richer configuration methods. To reduce network monitoring costs and traffic overheads, herein, we propose a softwaredefined cloud resource management framework that uses a Fuzzy Analytical Hierarchy Process (Fuzzy-AHP) to customize the network resource allocation. The framework can be incorporated into SDN-enabled cloud infrastructures by using an Application Program Interface (API). Using real-time data, we demonstrate that our framework can improve network resource management and is capable of handling increasing traffic requests. We also validate our framework efficiency through simulations. © Springer International Publishing Switzerland 2015.";"Cloud computing, Fuzzy Analytical Hierarchy Process (Fuzzy-AHP), Network management, Resource management, Scheduling, Software-defined networking"
"Lozano A., Mens K., Kellens A.";"Usage contracts: Offering immediate feedback on violations of structural source-code regularities";"Developers often encode design knowledge through structural regularities such as API usage protocols, coding idioms and naming conventions. As these regularities express how the source code should be structured, they provide vital information for developers using or extending that code. Adherence to such regularities tends to deteriorate over time because they are not documented and checked explicitly. This paper introduces uContracts, an internal DSL to codify and verify such regularities as 'usage contracts'. Our DSL aims at covering most common usage regularities, while still providing a means to express less common ones. Common regularities are identified based on regularities supported by existing approaches to detect bugs or suggest missing code fragments, techniques that mine for structural regularities, as well as on the analysis of an open-source project. We validate our DSL by documenting the structural regularities of an industrial case study, and analyse how useful the information provided by checking these regularities is for the developers of that case study. © 2015 Elsevier B.V. All rights reserved.";"IDE integration, Internal domain-specific language, Software development tool support, Source code analysis, Structural regularities"
"Kapre N.";"Sparse graph processing with soft-processors";"Modern FPGAs can be configured to exploit the large amount of on chip parallelism possible from the distributed SRAM memory blocks for algorithms operating on large sparse graphs. To simplify the programming and configuration of such memory-centric organizations, we can customize an array of soft processors for these graph algorithms. In particular, we can deliver significant performance improvements for bulk synchronous graph algorithms with a custom processor that implements a graph-specific ISA. We develop a C++ API using Vivado High-Level Synthesis to describe graph computations and generate custom soft processors from these high-level descriptions. Our preliminary experiments suggest that our soft processor outperform Micro blaze and NIOS-II/f soft processors by ≈6×. While not the focus of this work, this design can scale out to a cluster of 16 - 32 low-power, energy-efficient Zed boards and Microzed boards to compete with server-class x86 nodes. © 2015 IEEE."
"Miller M.A., Schwartz T., Hoover P., Yoshimoto K., Sivagnanam S., Majumdar A.";"The CIPRES workbench: A flexible framework for creating science gateways";"Here we describe the CIPRES Workbench (CW), an open source software framework for creating new science gateways with minimal overhead. The CW is a web application that can be deployed on a modest server, and can be configured to submit command line instructions to any resource where the application has submission privileges. It is designed to be highly configurable / customizable, and supports GUI-based access to HPC resources through a web browser interface as well as programmatic access via a ReSTful API. Using browser access, the CW architecture creates an environment with secure user accounts where user input data, job results, and job provenance are stored. The ReSTful API allows users with a registered a client application to deliver command lines to analytical codes and retrieve results from remote compute resources. A development effort is underway to allow the CW to submit jobs via the Science Gateways as a Platform (SciGaP) services hosted at Indiana University. Copyright © 2015 ACM.";"Open source, Restful services, Science gateway, SciGaP, Software, Workbench"
"Zheng M., Xue H., Zhang Y., Wei T., Lui J.C.S.";"Enpublic apps: Security threats using iOS enterprise and developer certificates";"Compared with Android, the conventional wisdom is that iOS is more secure. However, both jailbroken and nonjailbroken iOS devices have number of vulnerabilities. For iOS, apps need to interact with the underlying system using Application Programming Interfaces (APIs). Some of these APIs remain undocumented and Apple forbids apps in App Store from using them. These APIs, also known as ""private APIs"", provide powerful features to developers and yet they may have serious security consequences if misused. Furthermore, apps which use private APIs can bypass the App Store and use the ""Apple's Enterprise/Developer Certificates"" for distribution. This poses a significant threat to the iOS ecosystem. So far, there is no formal study to understand these apps and how private APIs are being encapsulated. We call these iOS apps which distribute to the public using enterprise certificates as ""enpublic"" apps. In this paper, we present the design and implementation of iAnalytics, which can automatically analyze ""enpublic"" apps' private API usages and vulnerabilities. Using iAnalytics, we crawled and analyzed 1,408 enpublic iOS apps. We discovered that: 844 (60%) out of the 1408 apps do use private APIs, 14 (1%) apps contain URL scheme vulnerabilities, 901 (64%) enpublic apps transport sensitive information through unencrypted channel or store the information in plaintext on the phone. In addition, we summarized 25 private APIs which are crucial and security sensitive on iOS 6/7/8, and we have filed one CVE (Common Vulnerabilities and Exposures) for iOS devices. Copyright © 2015 ACM."
"De Benedictis A., Rak M., Turtur M., Villano U.";"REST-based SLA management for cloud applications";"In cloud computing, possible risks linked to availability, performance and security can be mitigated by the adoption of Service Level Agreements (SLAs) formally agreed upon by cloud service providers and their users. This paper presents the design of services for the management of cloud-oriented SLAs that hinge on the use of a REST-based API. Such services can be easily integrated into existing cloud applications, platforms and infrastructures, in order to support SLA-based cloud services delivery. After a discussion on the SLA life-cycle, an agreement protocol state diagram is introduced. It takes explicitly into account negotiation, remediation and renegotiation issues, is compliant with all the active standards, and is compatible with the WS-Agreement standard. The requirement analysis and the design of a solution able to support the proposed SLA protocol is presented, introducing the REST API used. This API aims at being the basis for a framework to build SLA-based applications. © 2015 IEEE.";"API, Cloud, REST, SLA, WS-Agreement"
"Tang X.";"Attention, test code is low-quality!";"In this paper, we describe the formatting guidelines for ACM SIG Proceedings. Software testing is an essential process during software development and maintenance for improving software quality. Test code, the artefact during software testing, has been widely used in many software quality assurance techniques. Traditionally, software quality assurance techniques, e.g., automatic bug repair, fault localization, test case prioritization, and mining API usage from test code are based on the hypothesis of a sound quality of the test code. However, via empirical study on four open source projects, we found that the quality of test code is quite low comparing with corresponding source code, and this might hurt the above software quality assurance techniques. In this paper, we studied more than 140,000 LOC(lines of code) test code from four large scale and widely used open source projects and found that it is common for test code to be unregulated and of low-quality in open source projects. First, the comment clone ratio, unreleased resource ratio and clone code ratio of test code is much higher than that of corresponding source code, second, bug-fixed coverage is down to 0. We have learned the following lessons: the quality of test code is quite low comparing with corresponding source code, and the low quality test code may misguide existing software quality assurance techniques. Categories and Subject Descriptors D.2.5 [Software Engineering]: [Testing and Debugging] General Terms Experimentation, Measurement. © 2015 for this paper by its authors.";"Empirical study, Software quality assurance, Test code quality, Testing"
"Svajlenko J., Keivanloo I., Roy C.K.";"Big data clone detection using classical detectors: an exploratory study";"Big data analysis is an emerging research topic in various domains, and clone detection is no exception. The goal is to create big data inter-project clone corpora across open-source or corporate-source code repositories. Such corpora can be used to study developer behavior and to reduce engineering costs by extracting globally duplicated efforts into new APIs and as a basis for code completion and API usage support. However, building scalable clone detection tools is challenging. It is often impractical to use existing state-of-the-art tools to analyze big data because the memory and execution time required exceed the average user's resources. Some tools have inherent limitations in their data structures and algorithms that prevent the analysis of big data even when extraordinary resources are available. These limitations are impossible to overcome if the source code of the tool is unavailable or if the user lacks the time or expertise to modify the tool without harming its performance or accuracy. In this research, we have investigated the use of our shuffling framework for scaling classical clone detection tools to big data. The framework achieves scalability on commodity hardware by partitioning the input dataset into subsets manageable by the tool and computing resources. A non-deterministic process is used to randomly ‘shuffle’ the contents of the dataset into a series of subsets. The tool is executed for each subset, and its output for each is merged into a single report. This approach does not require modification to the subject tools, allowing their individual strengths and precision to be captured at an acceptable loss of recall. In our study, we explored the performance and applicability of the framework for the big data dataset, IJaDataset 2.0, which consists of 356 million lines of code from 25,000 open-source Java projects. We begin with a computationally inexpensive version of our framework based on pure random shuffling. This version was successful at scaling the tools to IJaDataset but required many subsets to achieve a desirable recall. Using our findings, we incrementally improved the framework to achieve a satisfactory recall using fewer resources. We investigated the use of efficient file tracking and file-similarity heuristics to bias the shuffling algorithm toward subsets of the dataset that contain undetected clone pairs. These changes were successful in improving the recall performance of the framework. Our study shows that the framework is able to achieve up to 90–95% of a tool's native recall using standard hardware. Copyright © 2014 John Wiley & Sons, Ltd. Copyright © 2014 John Wiley & Sons, Ltd.";"big data, clone corpus, clone detection, scalability, shuffling framework"
"Honko H., Andalibi V., Aaltonen T., Parak J., Saaranen M., Viik J., Korhonen I.";"W2E-Wellness warehouse engine for semantic interoperability of consumer health data";"Novel health monitoring devices and applications allow consumers easy and ubiquitous ways to monitor their health status. However, technologies from different providers lack both technical and semantic interoperability and hence the resulting health data is often deeply tied to a specific service, which is limiting its re-usability and utilization in different services. We have designed a Wellness Warehouse Engine (W2E) that bridges this gap and enables seamless exchange of data between different services. W2E provides interfaces to various data sources and makes data available via unified Representational State Transfer Application Programming Interface (REST API) to other services. Importantly, it includes Unifier - an engine that allows transforming input data into generic units re-usable by other services, and Analyzer - an engine that allows advanced analysis of input data, such as combining different data sources into new output parameters. In this paper, we describe the architecture of W2E and demonstrate its applicability by using it for unifying data from four consumer activity trackers, using a test base of 20 subjects each carrying out three different tracking sessions. Finally, we discuss challenges of building a scalable Unifier engine for the ever-enlarging number of new devices. © 2015 IEEE.";"Data Unification, Data Warehousing, Energy Expenditure, Physical Activity, Semantic Interoperability."
"Weiss J.M.";"Comparison of POSIX threads, OpenMP and C++11 concurrency frameworks";"Multi-core architectures have become the norm on highend computing devices, from desktop computers to tablets to cell phones. In order to take full advantage of parallelism, it is essential to write multithreaded applications. In the past, parallel processing in C++ was been restricted to external libraries. But the C++11 release introduces concurrency constructs into the language itself, providing benefits to software development, optimization, and portability. This paper compares performance and usability of the new C++11 concurrency interface to two widely-used external parallel processing libraries: POSIX threads and OpenMP. Copyright © 2015 by The International Society for Computers and Their Applications (ISCA)."
"Alotaibi H.M., Alamer R.A., Al-Khalifa H.S.";"MLab: A mobile language learning lab system for language learners";"This paper describes the design and development of a mobile language lab system called MLab. The MLab system aims to replace the traditional language lab—which typically has a restrictive layout and lacks interaction—with a more user-friendly, low-cost mobile language lab. The target users of MLab are language teachers and students, and the system offers them the freedom to move around and use their own devices at any time and in any place. The MLab system was developed using several web technologies and Application Programming Interface (API) to provide a fast and convenient method of accessing required content. To evaluate the MLab system, a pilot test was conducted with a class of 15 students and their teacher. The results showed high usability rates and generally positive attitudes toward using the system. © 2015, J.UCS.";"Language lab, Language teaching, MALL, Mobile lab, Web technologies"
"Joe W., Lee J., Jeong K.";"CSN: The conceptually manageable sensor network";"For the last decade, computer science and information technology have been rapidly expanding their application areas from computation and data processing inside computers to the real time monitoring and management of the real world outside computers. For those emerging applications such as Internet of Things, the flexible, scalable, and interoperable, collaborating sensor networks are crucial. In this paper, we present a sensor network system called the conceptually manageable sensor network (CSN). CSN is intended to support the conceptual management and integration of sensor networks and to provide well-defined and logical APIs for the facilitation of application development. The CSN design is based on the simple and intuitive conceptual model: sets and message queues. In order to minimize the system development efforts and to inherit the system quality of production level open source software, the CSN system is intentionally implemented as a set of extensions to the open source messaging system called ActiveMQ. We conducted some preliminary usability and performance tests for the current CSN implementation. For the usability test, we used data sets from a real world project for the energy-efficient management of Indoor Air Quality in subway stations. Both usability and performance tests showed promising results. © 2015 Woojin Joe et al."
"Chakroun I., Vander Aa T., De Fraine B., Haber T., Wuyts R., Demeuter W.";"ExaShark: A scalable hybrid array kit for exascale simulation";"Many problems in high-performance computing, such as stencil applications in iterative solvers or in particle-based simulations, have a need for regular distributed grids. Libraries offering such n-dimensional regular grids need to take advantage of the latest high-performance computing technologies and scale to exascale systems, but also need to be usable by non HPC experts. This paper presents ExaShark: a library for handling n-dimensional distributed data structures that strikes a balance between performance and usability. ExaShark is an open source middleware, offered as a library, targeted at reducing the increasing programming burden on heterogeneous current and future exascale architectures. It offers its users a global-array-like usability while its runtime can be configured to use shared memory threading techniques (Pthreads, OpenMP, TBB), inter-node distribution techniques (MPI, GPI), or combinations of both. ExaShark has been used to develop applications such as a Jacobian 2D heat simulation and advanced pipelined conjugate gradient solvers. These applications are used to demonstrate the performance and usability of ExaShark. Copyright © 2015 Society for Modeling & Simulation International (SCS).";"Exascale simulation, Middleware library, N-dimensional grids, Numerical solvers, Partitioned global address space"
"Chen L., Chen K., Shao C., Zhu P.";"SocAware: A middleware for social applications in online social networks";"The popularity of online social network (OSN) services has given rise to a variety of social network applications. However these applications lack a common platform for information sharing and people interoperating. In this paper, we propose SocAware, a middleware designed for OSN services. SocAware extracts social relation from heterogeneous networks, and builds a uniform knowledge base to manage the social information. SocAware distinguishes itself from other OSN middlewares by analyzing the OSN activities to classify the social relations, and by calculating the strength of social relations to provide reusability between social applications. We also provide a set of API to facilitate third-party application development and the effective utilization of these relations. In order to validate SocAware, we developed two prototype applications above the middleware. The experimental results demonstrate the usability and expansibility of the middleware. © 2014 IEEE.";"Middleware, Online social network, Social applications, Social relation strength"
"Brown J., Knepley M.G., Smith B.F.";"Run-time extensibility and librarization of simulation software";"Build-time configuration and environment assumptions are hampering progress and usability in scientific software. This situation, which would be utterly unacceptable in nonscientific software, somehow passes for the norm in scientific packages. The scientific software community needs reusable, easy-to-use software packages that are flexible enough to accommodate next-generation simulation and analysis demands. © 1999-2011 IEEE.";"extensible software, object-oriented, scientific computing, simulation, software composability, software library"
"Arora R., Chen K., Gupta M., Clark S., Song C.";"Leveraging diagrid hub for interactively generating and running parallel programs";"Interactive Parallelization Tool (IPT) is a semi-automatic tool that can be used by domain experts and students for transforming certain classes of existing applications into multiple parallel variants. An end-user of IPT provides existing application and high-level specifications for parallelization as input. On the basis of the specifications provided by the end-user, IPT carries out the code changes in the given existing application to generate parallel variants that can be run on different High Performance Computing (HPC) platforms. The parallel programming paradigms that are currently supported by IPT are MPI, OpenMP, and CUDA. The supported base languages are C and C++. Though IPT is still under active development, it has been recently made available on a web-enabled platform, named DiaGrid Hub, with the support from the XSEDE Extended Collaborative Support Service (ECSS). While the main goal of IPT is to make parallel programming easy for its end-users, the main goal of DiaGrid Hub is to enable the research community with instant access to HPC and High Throughput Computing platforms through a user-friendly web-interface. By deploying IPT on DiaGrid Hub, our goal is to enable the end-users to generate parallel versions of their existing applications without having to install IPT locally. They can also immediately compile and run the generated applications on Purdue and XSEDE resources that are available through DiaGrid Hub. Hence, the collaborative project that is reported in this paper lowers the entry-barriers to parallel programming and the usage of the national CyberInfrastructure (CI). In this paper, we present our ongoing work on deploying IPT over DiaGrid and testing the usability of IPT through a web-interface. Copyright © 2015 ACM.";"Diagrid, Exascale, High performance computing, Interactive parallelization, Parallel programming"
"Murukannaiah P.K., Singh M.P.";"Platys: An active learning framework for place-aware application development and its evaluation";"We introduce a high-level abstraction of location called place. A place derives its meaning from a user's physical space, activities, or social context. In this manner, place can facilitate improved user experience compared to the traditional representation of location, which is spatial coordinates. We propose the Platys framework as a way to address the special challenges of place-aware application development. The core of Platys is a middleware that (1) learns a model of places specific to each user via active learning, a machine learning paradigm that seeks to reduce the user-effort required for training the middleware, and (2) exposes the learned user-specific model of places to applications at run time, insulating application developers from dealing with both low-level sensors and user idiosyncrasies in perceiving places. We evaluated Platys via two studies. First, we collected place labels and Android phone sensor readings from 10 users. We applied Platys' active learning approach to learn each user's places and found that Platys (1) requires fewer place labels to learn a user's places with a desired accuracy than do two traditional supervised approaches, and (2) learns places with higher accuracy than two unsupervised approaches. Second, we conducted a developer study to evaluate Platys' efficiency in assisting developers and its effectiveness in enabling usable applications. In this study, 46 developers employed either Platys or the Android location API to develop a place-aware application. Our results indicate that application developers employing Platys, when compared to those employing the Android API, (1) develop a place-aware application faster and perceive reduced difficulty and (2) produce applications that are easier to understand (for developers) and potentially more usable and privacy preserving (for application users). © 2015 ACM.";"Active learning, Contextaware, Location-aware, Middleware, Mobile application development, Place recognition, Place-aware, Privacy, Semi-supervised learning, Usability"
"Lemic F., Handziski V., Wirström N., Van Haute T., De Poorter E., Voigt T., Wolisz A.";"Web-based platform for evaluation of RF-based indoor localization algorithms";"The experimental efforts for optimizing the performance of RF-based indoor localization algorithms for specific environments and scenarios is time consuming and costly. In this work, we address this problem by providing a publicly accessible platform for streamlined experimental evaluation of RF-based indoor localization algorithms, without the need of a physical testbed infrastructure. We also offer an extensive set of raw measurements that can be used as input data for indoor localization algorithms. The datasets are collected in multiple testbed environments, with various densities of measurement points, using different measuring devices and in various scenarios with controlled RF interference. The platform encompasses two core services: one focused on storage and management of raw data, and one focused on automated calculation of metrics for performance characterization of localization algorithms. Tools for visualization of the raw data, as well as software libraries for convenient access to the platform from MATLAB and Python, are also offered. By contrasting its fidelity and usability with respect to remote experiments on dedicated physical testbed infrastructure, we show that the virtual platform produces comparative performance results while offering significant reduction in the complexity, time and labor overheads. © 2015 IEEE."
"Toegl R., Winter J., Gissing M., Winkler T., Nauman M., Hong T.W.";"Programming interfaces for the TPM";"The paradigm of Trusted Computing promises a new approach to improve the security of embedded and mobile systems. The core functionality, based on a hardware component known as Trusted Platform Module (TPM), is widely available. However, integration and application in embedded systems remains limited at present, simply because of the extremely steep learning curve involved in using the programmer–facing interfaces. In this chapter, we describe the current state of the Trusted Computing Group's software architecture and present previous approaches to improve usability. We report on a novel design of a high–level API for Trusted Computing for Java which has been optimized for ease–of–use and clear abstraction of Trusted Computing concepts. We derive requirements and design goals and outline the API design. Finally, we show the application and benchmarks in embedded systems. The result of this effort has been standardized as Java Specification Request 321. © Springer International Publishing Switzerland 2015."
"Giancarlo R., Scaturro D., Utro F.";"ValWorkBench: An open source Java library for cluster validation, with applications to microarray data analysis";"The prediction of the number of clusters in a dataset, in particular microarrays, is a fundamental task in biological data analysis, usually performed via validation measures. Unfortunately, it has received very little attention and in fact there is a growing need for software tools/libraries dedicated to it. Here we present ValWorkBench, a software library consisting of eleven well known validation measures, together with novel heuristic approximations for some of them. The main objective of this paper is to provide the interested researcher with the full software documentation of an open source cluster validation platform having the main features of being easily extendible in a homogeneous way and of offering software components that can be readily re-used. Consequently, the focus of the presentation is on the architecture of the library, since it provides an essential map that can be used to access the full software documentation, which is available at the supplementary material website [1]. The mentioned main features of ValWorkBench are also discussed and exemplified, with emphasis on software abstraction design and re-usability. A comparison with existing cluster validation software libraries, mainly in terms of the mentioned features, is also offered. It suggests that ValWorkBench is a much needed contribution to the microarray software development/algorithm engineering community. For completeness, it is important to mention that previous accurate algorithmic experimental analysis of the relative merits of each of the implemented measures [19,23,25], carried out specifically on microarray data, gives useful insights on the effectiveness of ValWorkBench for cluster validation to researchers in the microarray community interested in its use for the mentioned task. © 2014 Elsevier Ireland Ltd.";"Bioinformatics software, Microarray cluster analysis, Pattern discovery in bioinformatics and biomedicine"
"Rosoiu M.-E., David J., Euzenat J.";"A linked data framework for android";"Mobile devices are becoming major repositories of personal information. Still, they do not provide a uniform manner to deal with data from both inside and outside the device. Linked data provides a uniform interface to access structured interconnected data over the web. Hence, exposing mobile phone information as linked data would improve the usability of such information. We present an API that provides data access in RDF, both within mobile devices and from the outside world. This API is based on the Android content provider API which is designed to share data across Android applications. Moreover, it introduces a transparent URI dereferencing scheme, exposing content outside of the device. As a consequence, any application may access data as linked data without any a priori knowledge of the data source. © Springer-Verlag Berlin Heidelberg 2015."
"[No author name available]";"CEUR Workshop Proceedings";"The proceedings contain 31 papers. The topics discussed include: trusted, fair multi-segment business models, enabled by a user-centric, privacy-aware platform, for a data-driven era, gamifying software development environments using cognitive principles, community-based API builder to manage APIs and their connections with cloud-based services, applying idea management system (IMS) approach to design and implement a collaborative environment in public service related open innovation processes, towards visually monitoring multiple perspectives of business process compliance, the influence of syntactic quality of enterprise process models on model comprehension, KPI-based activity planning for people working in flexible processes, usability evaluation of variability modeling by means of common variability language, patterns for identifying and structuring features from textual descriptions: an exploratory study, and a resource oriented architecture to handle data volume diversity."
"Bukhari A.C., Nagy M.L., Krauthammer M., Ciccarese P., Baker C.J.O.";"ICyrus: A semantic framework for biomedical image discovery";"Images have an irrefutably central role in scientific discovery and discourse. However, the issues associated with knowledge management and utility operations unique to image data are only recently gaining recognition. In our previous work, we have developed Yale Image finder (YIF), which is a novel Biomedical image search engine that indexes around two million biomedical image data, along with associated metadata. While YIF is considered to be a veritable source of easily accessible biomedical images, there are still a number of usability and interoperability challenges that have yet to be addressed. To overcome these issues and to accelerate the adoption of the YIF for next generation biomedical applications, we have developed a publically accessible semantic API for biomedical images with multiple modalities. The core API called iCyrus is powered by a dedicated semantic architecture that exposes the YIF content as linked data, permitting integration with related information resources and consumption by linked data-aware data services. To facilitate the adhoc integration of image data with other online data resources, we also built semantic web services for iCyrus, such that it is compatible with the SADI semantic web service framework. The utility of the combined infrastructure is illustrated with a number of compelling use cases and further extended through the incorporation of Domeo, a well known tool for open annotation. Domeo facilitates enhanced search over the images using annotations provided through crowdsourcing. The iCyrus triplestore currently holds more than thirty-five million triples and can be accessed and operated through syntactic or semantic query interfaces. Core features of the iCyrus API, namely: data reusability, system interoperability, semantic image search, automatic update and dedicated semantic infrastructure make iCyrus a state of the art resource for image data discovery and retrieval. © Copyright 2015 for the individual papers by the papers' authors.";"Interoperable web services, Linked biomedical images, Yale Image Finder"
"[No author name available]";"11th International Conference on Security and Privacy in Communication Networks, SecureComm 2015";"The proceedings contain 48 papers. The special focus in this conference is on Mobile, System and Software Security. The topics include: Enforcing permissions with system-wide application execution context, detection, classification and characterization of android malware using API data dependency, improving security and usability for provider independent login architectures with mobile devices, using provenance patterns to vet sensitive behaviors in android apps, isolated execution of sensitive components for mobile applications, intrinsic code attestation by instruction chaining for embedded devices, defeating kernel driver purifier, kernel data attack is a realistic security threat, cloud-based anti-malware via reversible sketch, mining network traffic anomalies with hadoop, a secure interface for isolated execution environment to dynamically use external services, authenticating top-k results of secure multi-keyword search in cloud computing, resource efficient privacy preservation of online social media conversations, real-time privacy leakage monitoring without system modification for android, practicality of using side-channel analysis for software integrity checking of embedded systems, remote activation of hardware trojans via a covert temperature channel, route leaks identification by detecting routing loops, stateful black-box fuzzing of proprietary network protocols, deriving behavioral fingerprints from DNS traffic, enhancing traffic analysis resistance for tor hidden services with multipath routing, an improved method for anomaly-based network scan detection, an attribute-based signcryption scheme to secure attribute-defined multicast communications, generation of transmission control rules compliant with existing access control policies and a markov random field approach to automated protocol signature inference."
"Hastings J., Haug K., Steinbeck C.";"Ten recommendations for software engineering in research";"Research in the context of data-driven science requires a backbone of well-written software, but scientific researchers are typically not trained at length in software engineering, the principles for creating better software products. To address this gap, in particular for young researchers new to programming, we give ten recommendations to ensure the usability, sustainability and practicality of research software. © 2014 Hastings et al., licensee BioMed Central Ltd.";"Best practices, Software engineering"
"Demangeon R., Honda K., Hu R., Neykova R., Yoshida N.";"Practical interruptible conversations: distributed dynamic verification with multiparty session types and Python";"The rigorous and comprehensive verification of communication-based software is an important engineering challenge in distributed systems. Drawn from our industrial collaborations (Ocean Observatories Initative, http://www.oceanobservatories.org/, JBoss Savara Project, http://www.jboss.org/savara) on Scribble, a choreography description language based on multiparty session types, and its theoretical foundations (Honda et al., in POPL, pp 273–284, 2008), this article proposes a dynamic verification framework for structured interruptible conversation programming. We first present our extension of Scribble to support the specification of asynchronously interruptible conversations. We then implement a concise API for conversation programming with interrupts in Python that enables session types properties to be dynamically verified for distributed processes. Finally, we expose the underlying theory of our interrupt mechanism, studying its syntax and semantics, its integration in MPST theory and proving the correctness of our design. Our framework ensures the global safety of a system in the presence of asynchronous interrupts through independent runtime monitoring of each endpoint, checking the conformance of the local execution trace to the specified protocol. The usability of our framework for describing and verifying choreographic communications has been tested by integration into the large scientific cyberinfrastructure developed by the Ocean Observatories Initiative. Asynchronous interrupts have proven expressive enough to represent and verify their main classes of communication patterns, including asynchronous streaming and various timeout-based protocols, without introducing any implicit synchronisations. Benchmarks show conversation programming and monitoring can be realised with little overhead. © 2014, Springer Science+Business Media New York.";"Distributed systems, Python, Runtime monitoring, Session types"
"Nguyen H.A., Dyer R., Nguyen T.N., Rajan H.";"Mining preconditions of APIs in large-scale code corpus";"Modern software relies on existing application programming interfaces (APIs) from libraries. Formal specifications for the APIs enable many software engineering tasks as well as help developers correctly use them. In this work, we mine large-scale repositories of existing open-source software to derive potential preconditions for API methods. Our key idea is that APIs' preconditions would appear frequently in an ultra-large code corpus with a large number of API usages, while project-specific conditions will occur less frequently. First, we find all client methods invoking APIs. We then compute a control dependence relation from each call site and mine the potential conditions used to reach those call sites. We use these guard conditions as a starting point to automatically infer the preconditions for each API. We analyzed almost 120 million lines of code from SourceForge and Apache projects to infer preconditions for the standard Java Development Kit (JDK) library. The results show that our technique can achieve high accuracy with recall from 75-80% and precision from 82-84%. We also found 5 preconditions missing from human written specifications. They were all confirmed by a specification expert. In a user study, participants found 82% of the mined preconditions as a good starting point for writing specifications. Using our mining result, we also built a benchmark of more than 4,000 precondition-related bugs. Copyright 2014 ACM.";"Big code mining, JML, Preconditions, Specification mining"
"David Hincapié-Ramos J., Ivanchuk L., Sridharan S.K., Irani P.";"SmartColor: Real-time color correction and contrast for optical see-through head-mounted displays";"Users of optical see-through head-mounted displays (OHMD) perceive color as a blend of the display color and the background. Color-blending is a major usability challenge as it leads to loss of color encodings and poor text legibility. Color correction aims at mitigating color blending by producing an alternative color which, when blended with the background, more closely approaches the color originally intended. To date, approaches to color correction do not yield optimal results or do not work in real-time. This paper makes two contributions. First, we present QuickCorrection, a realtime color correction algorithm based on display profiles. We describe the algorithm, measure its accuracy and analyze two implementations for the OpenGL graphics pipeline. Second, we present SmartColor, a middleware for color management of userinterface components in OHMD. SmartColor uses color correction to provide three management strategies: correction, contrast, and show-up-on-contrast. Correction determines the alternate color which best preserves the original color. Contrast determines the color which best warranties text legibility while preserving as much of the original hue. Show-up-on-contrast makes a component visible when a related component does not have enough contrast to be legible. We describe the SmartColor's architecture and illustrate the color strategies for various types of display content. © 2014 IEEE.";"Color Blending, Contrast, Correction, Head-Mounted Displays, See-through Displays, Transparency"
"Pozhidaev M.";"The framework for accessible applications: Text-based case for blind people";"This paper offers a Java framework for creating accessible applications for blind and visually impaired people as part of a proposed general conception based on the maximum use of objects filled with text data only. It offers new types of applications more easily recognizable by disabled persons, helping them to do their work faster and more comfortably. Strong and weak points are analyzed. The published prototype of the proposed platform is described as well as the conclusions of the performed experiments. The prototype is implemented on Java SE and wrapped by a GNU/Linux environment as a bootable ISO-image. Copyright 2014 ACM.";"Accessibility, API, Blind people, Java, Usability, User interfaces"
"Bodden E.";"TS4J: A fluent interface for defining and computing typestate analyses";"Typestate analyses determine whether a program's use of a given API obeys this API's usage constraints in the sense that the right methods are called on the right objects in the right order. Previously, we and others have described approaches that generate typestate analyses from textual finitestate property definitions written in specialized domainspecific languages. While such an approach is feasible, it requires a heavyweight compiler, hindering an effective integration into the programmer's development environment and thus often also into her software-development practice. Here we explain the design of a pure-Java interface facilitating both the definition and evaluation of typestate analyses. The interface is fluent, a term coined by Eric Evans and Martin Fowler. Fluent interfaces provide the user with the possibility to write method-invocation chains that almost read like natural-language text, in our case allowing for a seemingly declarative style of typestate definitions. In all previously described approaches, however, fluent APIs are used to build configuration objects. In this work, for the first time we show how to design a fluent API in such a way that it also encapsulates actual computation, not just configuration. We describe an implementation on top of Soot, Heros and Eclipse, which we are currently evaluating together with pilot customers in an industrial context at Fraunhofer SIT. © Copyright 2014 ACM.";"Dynamic Analysis, Fluent Interfaces, Static Analysis, Typestate"
"Akbar R.J., Omori T., Maruyama K.";"Mining API usage patterns by applying method categorization to improve code completion";"Developers often face difficulties while using APIs. API usage patterns can aid them in using APIs efficiently, which are extracted from source code stored in software repositories. Previous approaches have mined repositories to extract API usage patterns by simply applying data mining techniques to the collection of method invocations of API objects. In these approaches, respective functional roles of invoked methods within API objects are ignored. The functional role represents what type of purpose each method actually achieves, and a method has a specific predefined order of invocation in accordance with its role. Therefore, the simple application of conventional mining techniques fails to produce API usage patterns that are helpful for code completion. This paper proposes an improved approach that extracts API usage patterns at a higher abstraction level rather than directly mining the actual method invocations. It embraces a multilevel sequential mining technique and uses categorization of method invocations based on their functional roles. We have implemented a mining tool and an extended Eclipse's code completion facility with extracted API usage patterns. Evaluation results of this tool show that our approach improves existing code completion. © 2014 The Institute of Electronics, Information and Communication Engineers.";"Code completion, Recommendation, Sequential pattern mining, Software repositories"
"Zhu Z., Zou Y., Xie B., Jin Y., Lin Z., Zhang L.";"Mining API usage examples from test code";"Lack of effective usage examples in API documents has been proven to be a great obstacle to API learning. To deal with this issue, several approaches have been proposed to automatically extract usage examples from client code or related web pages, which are unfortunately not available for newly released API libraries. In this paper, we propose a novel approach to mining API usage examples from test code. Although test code can be a good source of usage examples, the issue of multiple test scenarios might lead to repetitive and interdependent API usages in a test method, which make it complicated and difficult to extract API usage examples. To address this issue, we study the JUnit test code and summarize a set of test code patterns. We employ a code pattern based heuristic slicing approach to separate test scenarios into code examples. Then we cluster the similar usage examples for recommendation. An evaluation on four open source software libraries demonstrates that the accuracy of our approach is much higher than the state-of-art approach eXoaDoc on test code. Furthermore, we have developed an Eclipse plug in tool UsETeC. © 2014 IEEE.";"API, code patterns, code slicing, test code, usage example"
"Watson R.";"Applying the cognitive dimensions of API usability to improve API documentation planning";"This interactive poster explores the application of the 12 cognitive dimensions of API usability to API documentation planning by using the dimensions to identify and characterize the factors that influence the documentation that the users of an API require. Many factors can complicate estimating and planning the documentation an API requires. Even when an API's documentation requirements can be estimated, it can be difficult to present to stakeholders an objective basis for the estimate. The cognitive dimensions of API usability have characterized APIs and their users successfully and they have been used to communicate these characterizations to stakeholders. It follows that the same dimensions could also help identify the documentation that an API requires to provide a satisfactory and successful experience for the software developers who use the API. © Copyright 2014 ACM.";"API, API reference documentation, Application programming interface, Software documentation, Software libraries"
"Ko D., Ma K., Park S., Kim S., Kim D., Traon Y.L.";"API document quality for resolving deprecated APIs";"Using deprecated APIs often results in security vulnerability or performance degradation. Thus, invocations to deprecated APIs should be immediately replaced by alternative APIs. To resolve deprecated APIs, most developers rely on API documents provided by service API libraries. However, the documents often do not have sufficient information. This makes many deprecated API usages remain unresolved, which leads programs to vulnerable states. This paper reports a result of studying document quality for deprecated APIs. We first collected 260 deprecated APIs of eight Java libraries as well as the corresponding API documents. These documents were manually investigated to figure out whether it provides alternative APIs, rationales, or examples. Then, we examined 2,126 API usages in 249 client applications and figured out whether those were resolved in the subsequent versions. This study revealed that 1) 3.6 APIs was deprecated and 3.6 deprecated APIs are removed from the library a month on average, 2) only 61% of API documents provided alternative APIs while rationale and examples were rarely documented, and 3) 62% of deprecate API usages in client applications were resolved if the corresponding API documents provided alternative APIs while 49% were resolved when the documents provided no alternative APIs. Based on these results, we draw future directions to encourage resolving deprecated APIs. © 2014 IEEE."
"Cardoso B., Romão T.";"The timeline as a programming interface";"The task of implementing meaningful reactive behavior in mobile applications is not trivial. To abstract over platform-specific details while writing expressive and legible code, we've developed EveWorks, a framework for context awareness that interfaces with the rest of the application code through statements written in a simple, interpreted language. In this work, we explain the conceptualization that stands at the core of our framework's language, inspired by one of the most ubiquitous representations of temporality, the timeline.";"API usability, Daily life event reaction, Framework, Mobile application development, Timeline"
"Nguyen A.T., Nguyen H.A., Nguyen T.T., Nguyen T.N.";"Statistical learning approach for mining API usage mappings for code migration";"The same software product nowadays could appear in multiple platforms and devices. To address business needs, software companies develop a software product in a programming language and then migrate it to another one. To support that process, semi-automatic migration tools have been proposed. However, they require users to manually define the mappings between the respective APIs of the libraries used in two languages. To reduce such manual effort, we introduce StaMiner, a novel data-driven approach that statistically learns the mappings between APIs from the corpus of the corresponding client code of the APIs in two languages Java and C#. Instead of using heuristics on the textual or structural similarity between APIs in two languages to map API methods and classes as in existing mining approaches, StaMiner is based on a statistical model that learns the mappings in such a corpus and provides mappings for APIs with all possible arities. Our empirical evaluation on several projects shows that StaMiner can detect API usage mappings with higher accuracy than a state-of-the-art approach. With the resulting API mappings mined by StaMiner, Java2CSharp, an existing migration tool, could achieve a higher level of accuracy. © 2014 ACM.";"API mappings, API usages, Code migration, Statistical learning"
"Nguyen A.T., Nguyen H.A., Nguyen T.T., Nguyen T.N.";"Statistical learning of API mappings for language migration";"The process of migrating software between languages is called language migration or code migration. To reduce manual ef-fort in defining the rules of API mappings for code migra-tion, in this work, we investigate a data-driven model that statistically learns the mappings between API usages from the corpus of the corresponding methods in the client code of the APIs in two languages. Copyright © 2014 ACM.";"Language migration, Statistical machine translation"
"Ghafari M., Heydarnoori A.";"Towards a visualized code recommendation for APIs enriched with specification mining";"This paper positions an idea for an interactive code recommendation system. In this work, candidate recommendations are abstracted as a graph-based visualization of the API usages that are decorated with the API specifications and the usage rules mined from the unit test cases of the given API and its usage examples. The user can then progressively explore this graph to obtain her desired code with- out delving into the implementation details. © 2014 ACM.";"Code recommendation, Specification, Unit test, Visualization"
"Petersen P., Hanenberg S., Robbes R.";"An empirical comparison of static and dynamic type systems on API usage in the presence of an IDE: Java vs. Groovy with eclipse";"Several studies have concluded that static type systems offer an advantage over dynamic type systems for programming tasks involving the discovery of a new API. However, these studies did not take into account modern IDE features, the advanced navigation and code completion techniques available in modern IDEs could drastically alter their conclusions. This study describes an experiment that compares the usage of an unknown API using Java and Groovy using the IDE Eclipse. It turns out that the previous finding that static type systems improve the usability of an unknown API still holds, even in the presence of a modern IDE. Copyright © 2014 ACM.";"Empirical research, Programming languages, Type systems"
"Linares-Vásquez M., Bavota G., Bernal-Cárdenas C., Oliveto R., Di Penta M., Poshyvanyk D.";"Mining energy-greedy API usage patterns in android apps: An empirical study";"Energy consumption of mobile applications is nowadays a hot topic, given the widespread use of mobile devices. The high demand for features and improved user experience, given the available powerful hardware, tend to increase the apps' energy consumption. However, excessive energy consumption in mobile apps could also be a consequence of energy greedy hardware, bad programming practices, or particular API usage patterns. We present the largest to date quantitative and qualitative empirical investigation into the categories of API calls and usage patterns that-in the context of the Android development framework-exhibit particularly high energy consumption profiles. By using a hardware power monitor, we measure energy consumption of method calls when executing typical usage scenarios in 55 mobile apps from different domains. Based on the collected data, we mine and analyze energy-greedy APIs and usage patterns. We zoom in and discuss the cases where either the anomalous energy consumption is unavoidable or where it is due to suboptimal usage or choice of APIs. Finally, we synthesize our findings into actionable knowledge and recipes for developers on how to reduce energy consumption while using certain categories of Android APIs and patterns. Copyright 2014 ACM.";"Empirical study, Energy consumption, Mobile applications"
"Mijailović Ž., Milićev D.";"Empirical analysis of GUI programming concerns";"The focus of this paper is on identification of typical graphical user interface (GUI) programming concerns. As opposed to some other proposals available in the literature that indicate GUI programming concerns by simple intuition, we have conducted a systematic empirical analysis to derive our proposal. It included an analysis of an existing application programming interface (API), its use in industrial projects, and an analysis of the requirements and issues reported during software maintenance. In addition, we have evaluated more than 50 GUI frameworks and APIs and proved usefulness and generality of our classification of concerns. As an additional proof of applicability of the proposed classification, we have refactored the inheritance hierarchy of the selected GUI API using concern-oriented interfaces. We have implemented a supporting tool that complements the developed API and supports its concern-oriented use. The evaluation of the refactored API showed positive effects on API usability. © 2014 Elsevier Ltd.";"Graphical user interfaces (GUI), GUI application programming interface (API), GUI concerns, GUI programming, Separation of concerns"
"Ghafari M.";"Extracting code examples from unit test cases";"Understanding how to properly use APIs of large libraries is difficult, error prone, and time consuming. Software developers resort to study to learn APIs. Several approaches have been proposed to mine these examples, but the sources from which they mine examples as well as their mining approaches hamper their applicability in some practical scenarios. Unit test cases seem to be an additional source of significant API examples, which may overcome the aforementioned difficulties. Synthesizing meaningful examples from tests not only improves the applicability of current code recommendation systems, but also facilitates providing up to date API examples to augment documentation. However, mining examples of API use from unit tests is a non trivial task and arises several research challenges summarized in this paper. © 2014 IEEE.";"code examples, code recommendation, unit test cases"
"Chen C., Zhang K.";"Who asked what: Integrating crowdsourced FAQs into API documentation";"Documentation is important for learning Application Pro-gramming Interfaces (APIs). In addition to official docu-ments, much crowdsourced API knowledge is available on the Web. Crowdsourced API documentation is fragmented, scattered around the Web, and disconnected from official doc-umentation. Developers often rely on Web search to retrieve additional programming help. We propose to connect these two types of documentation by capturing developers' Web browsing behavior in the context of document reading and integrating crowdsourced frequently asked questions (FAQs) into API documents. Such an integration not only provides relevant API help more conveniently, but also opens a new approach to promoting knowledge collaboration and studying API users' information needs. Copyright © 2014 ACM.";"API, Crowdsourcing, Documentation, Search, Social media"
"[No author name available]";"11th Working Conference on Mining Software Repositories, MSR 2014 - Proceedings";"The proceedings contain 63 papers. The topics discussed include: mining energy-greedy API usage patterns in android apps: an empirical study, greenminer: a hardware based mining software repositories software energy consumption framework, mining questions about software energy consumption, prediction and ranking of co-change candidates for clones, incremental origin analysis of source code files, characterizing and predicting blocking bugs in open source projects, the promises and perils of mining GitHub, mining questions asked by web developers, MUX: algorithm selection for software model checkers, finding patterns in static analysis alerts, an empirical study of just-in-time defect prediction using cross-project models, and the impact of code review coverage and code review participation on software quality."
"Asaduzzaman M., Roy C.K., Schneider K.A., Hou D.";"Context-sensitive code completion tool for better API usability";"Developers depend on APIs of frameworks and libraries to support the development process. Due to the large number of existing APIs, it is difficult to learn, remember, and use them during the development of a software. To mitigate the problem, modern integrated development environments provide code completion facilities that free developers from remembering every detail. In this paper, we introduce CSCC, a simple, efficient context-sensitive code completion tool that leverages previous code examples to support method completion. Compared to other existing code completion tools, CSCC uses new sources of contextual information together with lightweight source code analysis to better recommend API method calls. © 2014 IEEE.";"API methods, Code Completion, Eclipse plugin"
"Pandit M.R., Bhardwaj T., Khatri V.";"Steps towards web ubiquitous computing";"With evasion of digital convergence [1], computing has by and large pervaded into our environment. WWW has enhanced day-to-day life by utilizing information such as Location awareness, User-context awareness, touch API, mutation observer [2], and many more. The future [3] trends in ubiquitous computing [4] provide a great scope for innovation and value-added services.With approach of “computing being embedded,” the future sees its usage more pervasive and appealing. Web is evolving and so are supporting technologies (in terms of hardware technologies). Many real-life examples including augmented-reality, wearable technologies, gesture-based recognition systems, etc., are already in place illustrating its high-end usage. Such diverse future targeting billions of people and devices need streamlined approach. Some steps have already been taken care by World Wide Web consortium (W3C) to provide standards relating to API usage. In this paper, we highlight various aspects of web-ubiquitous computing and how they can be dealt w.r.t to their implementation. © Springer India 2014.";"Future trends in web ubiquitous computing, Ubiquitous computing recommendation, Web ubiquitous computing, WWW pervasive computing"
"Lorenzon A.F., Filho A.C.S.B., Cera M.C.";"The impact of different multi-threading interfaces on embedded systems";"The popularity of multicore embedded systems brings new challenges to the development of parallel applications: at the same time it is necessary to exploit the availability of multiple cores, it is also mandatory to consume less energy. To speed up the development process and make it as more transparent as possible to the programmer, parallelism is exploited through the use of Application Programming Interfaces (API). Each one of these API implements different ways to exchange data. However, data exchange occurs between the threads in shared memory regions, which have higher energy consumption. Therefore, each API will present different energy costs to communicate. In this paper, we present the first step to show that different APIs have different impacts on energy consumption, through the analysis of the communication mechanism that each one employs, the number of memory accesses necessary for the communication, and the number of executed instructions according to the API used. Our results show that OpenMP presents a higher communication overhead, with more memory accesses and instructions executed, when compared to Pthreads. © 2013 IEEE.";"Embedded Systems, Parallel Programming, Power Consumption"
"Khan M.A., Muhammad S., Muhammad T.";"Identifying performance issues based on method invocation patterns of an API";"Software systems use many third party libraries by invoking their APIs. A software system may potentially use an API in an inefficient manner, for example, by creating unnecessary or a large number of short-lived objects. This can cause performance degradation in terms of memory usage and latency in critical applications. In this paper we use an object invocation model based on object creation and their method invocations from different code locations. We use a framework to extract the model features from a running software system. The extracted features are then used in a clustering based mechanism to identify problematic code locations within the software system. We demonstrate our approach by analyzing Java Collection API objects in a Java-based open source editor JEdit. We have successfully identified interesting code locations and discussed their impact on software performance. Copyright is held by the owner/author(s).";"API object invocation model, API usage analysis, Bytecode instrumentation, Dynamic program analysis"
"Kashyap V., Hardekopf B.";"Security signature inference for javascript-based browser addons";"JavaScript-based browser addons are a tempting target for malicious developers|addons have high privileges and ready access to a browser user's confidential information, and they have none of the usual sandboxing or other security restric- Tions used for client-side webpage JavaScript. Therefore, vetting third-party addons is important both for addon users and for the browser providers that host oficial addon repos- itories. The current state-of-the-art vetting methodology is manual and ad-hoc, which makes the vetting process diffi- cult, tedious, and error-prone. In this paper, we propose a method to help automate this vetting process. We describe a novel notion of addon se- curity signatures, which provide detailed information about an addon's information ows and API usage, along with a novel static analysis to automatically infer these signatures from the addon code. We implement our analysis and em- pirically evaluate it on a benchmark suite consisting of ten real browser addons taken from the oficial Mozilla addon repository. Our results show that our analysis is practical and useful for vetting browser addons. Copyright © 2014 by the Association for Computing Machinery, Inc. (ACM).";"Browser addons, Javascript, Static analysis"
"Acretoaie V., Störrle H.";"Hypersonic: Model analysis and checking in the cloud";"Modeling tools are traditionally delivered as monolithic desktop applications, optionally extended by plug-ins or special purpose central servers. This delivery model suffers from several drawbacks, ranging from poor scalability to difficult maintenance and the proliferation of shelfware"". Objective: In this paper we investigate the conceptual and technical feasibility of a new software architecture for modeling tools, where certain advanced features are factored out of the client and moved towards the Cloud. With this approach we plan to address the above mentioned drawbacks of existing modeling tools. Method: We base our approach on RESTful Web services. Using features implemented in the existing Model Analysis and Checking (MACH) tool, we create a RESTful Web service API offering model analysis facilities. We refer to it as the Hypersonic API. We provide a proof of concept implementation for the Hypersonic API using model clone detection as our example case. We also implement a sample Web application as a client for these Web services. Results: Our initial experiments with Hypersonic demonstrate the viability of our approach. By applying standards such as REST and JSON in combination with Prolog as an implementation language, we are able to transform MACH from a command line tool into the first Web-based model clone detection service with remarkably little effort.";"Clone detection, Hypersonic, MACH, Models in the cloud, Prolog, Web services"
"De Roover C., Stevens R.";"Building development tools interactively using the EKEKO meta-programming library";"EKEKO is a Clojure library for applicative logic meta-programming against an Eclipse workspace. EKEKO has been applied successfully to answering program queries (e.g., ""does this bug pattern occur in my code?""), to analyzing project corpora (e.g., 'how often does this API usage pattern occur in this corpus?'), and to transforming programs (e.g., ""change occurrences of this pattern as follows"") in a declarative manner. These applications rely on a seamless embedding of logic queries in applicative expressions. While the former identify source code of interest, the latter associate error markers with, compute statistics about, or rewrite the identified source code snippets. In this paper, we detail the logic and applicative aspects of the EKEKO library. We also highlight key choices in their implementation. In particular, we demonstrate how a causal connection with the Eclipse infrastructure enables building development tools interactively on the Clojure read-eval-print loop. © 2014 IEEE."
"Wu W., Adams B., Gueheneuc Y.-G., Antoniol G.";"ACUA: API change and usage auditor";"Modern software uses frameworks through their Application Programming Interfaces (APIs). Framework APIs may change while frameworks evolve. Client programs have to upgrade to new releases of frameworks if security vulnerabilities are discovered in the used releases. Patching security vulnerabilities can be delayed by non-security-related API changes when the frameworks used by client programs are not up to date. Keeping frameworks updated can reduce the reaction time to patch security leaks. Client program upgrades are not cost free, developers need to understand the API usages in client programs and API changes between framework releases before conduct upgrading tasks. In this paper, we propose a tool ACUA to generate reports containing detailed API change and usage information by analyzing the binary code of both frameworks and clients programs written in Java. Developers can use the API change and usage reports generated by ACUA to estimate the work load and decide when to starting upgrading client programs based on the estimation. © 2014 IEEE.";"API change and usage, framework API evolution, Software maintenance"
"Bianchini D.";"Deriving folksonomies for improving web API search";"Web APIs, that is, software components made available by third parties through web interfaces, can be aggregated to develop web applications, also known as mashups. Also in this application domain, tagging performed by other mashup designers, who used available Web APIs and mashups composed of them, might be exploited as knowledge that progressively emerges from the community of designers. Web API tagging has some peculiar aspects that will be analyzed in this paper. On the other hand, folksonomies are Web 2.0 tools for conceptualizing knowledge emerging from the bottom. In this paper, we discuss the adoption of folksonomy concepts in modeling Web API use for mashup development. We motivate the adoption of folksonomies in this context and we present the differences with other models that represent very close information. Our folksonomy model is meant to be fully compliant with existing and commonly used public Web API repositories. It is not intended to substitute them, but to complement their contents in order to enable advanced Web API search facilities in such a collaborative environment. © Springer-Verlag Berlin Heidelberg 2014."
"Shin J.";"Investigating the accuracy of the openFDA API using the FDA Adverse Event Reporting System (FAERS)";"The US Food and Drug Administration (FDA) Adverse Event Reporting System (FAERS) is a database that contains information on adverse event and medication error reports submitted to the FDA. Each quarter the FDA releases the data to the public, but accessing the data requires researchers to download, import, and consolidate data for every quarter starting from 2004. In an effort to provide easier access to this, the FDA launched the openFDA initiative in June 2014, which gives the public API access to information about adverse events reports. Although the API enables easier access to the FAERS data, the quality of the API design and the features of the data set will determine the reliability of the information retrieved. Thus, errors in the API can result in inaccurate and unreliable data analysis. Furthermore, the number of adverse events reports retrieved by the API for a particular drug can differ from the FAERS data files due to the openFDA harmonization process and the existence of multiple entries and variations for any given drug name in the FAERS data files. Since there are no universal rule that can be used to identify errors or potential issues, we propose evaluating the openFDA API by searching for a particular drug (brand name), Yaz, and the generic name, Drospirenone Ethinyl Estradiol, and comparing the results against the FAERS data files. Our results show that in the case of Yaz, the openFDA API and the drug harmonization process is inaccurate and inconsistent. © 2014 IEEE.";"adverse events, FAERS, FDA, FDA Adverse Events Reporting System, openFDA"
"Steele G.L., Jr., Lea D., Flood C.H.";"Fast splittable pseudorandom number generators";"We describe a new algorithm SPLITMIX for an objectoriented and splittable pseudorandom number generator (PRNG) that is quite fast: 9 64-bit arithmetic/logical operations per 64 bits generated. A conventional linear PRNG object provides a generate method that returns one pseudorandom value and updates the state of the PRNG, but a splittable PRNG object also has a second operation, split, that replaces the original PRNG object with two (seemingly) independent PRNG objects, by creating and returning a new such object and updating the state of the original object. Splittable PRNG objects make it easy to organize the use of pseudorandom numbers in multithreaded programs structured using forkjoin parallelism. No locking or synchronization is required (other than the usual memory fence immediately after object creation). Because the generate method has no loops or conditionals, it is suitable for SIMD or GPU implementation. Copyright 2014 ACM.We derive SPLITMIX from the DOTMIX algorithm of Leiserson, Schardl, and Sukha by making a series of program transformations and engineering improvements. The end result is an object-oriented version of the purely functional API used in the Haskell library for over a decade, but SPLITMIX is faster and produces pseudorandom sequences of higher quality, it is also far superior in quality and speed to Java.util.Random, and has been included in Java JDK8 as the class Java.util.SplittableRandom. We have tested the pseudorandom sequences produced by SPLITMIX using two standard statistical test suites (DieHarder and TestU01) and they appear to be adequate for ""everyday"" use, such as in Monte Carlo algorithms and randomized data structures where speed is important.";"Collections, Determinism, Java, Multithreading, Nondeterminism, Object-oriented, Parallel computing, Pedigree, Pseudorandom, Random number generator, Recursive splitting, Scala, Spliterator, Splittable data structures, Streams"
"Padhye R., Mukherjee D., Sinha V.S.";"API as a social glue";"The rapid growth of social platforms such as Facebook, Twit-ter and LinkedIn underscores the need for people to connect to existing and new contacts for recreational and profes-sional purposes. A parallel of this phenomenon exists in the software development arena as well. Open-source code shar-ing platforms such as GitHub provide the ability to follow people and projects of interest. However, users are manu-ally required to identify projects or other users whom they might be interested in following. We observe that most soft-ware projects use third-party libraries and that developers who contribute to multiple projects often use the same li-brary APIs across projects. Thus, the library APIs seem to be a good fingerprint of their skill set. Hence, we argue that library APIs can form the social glue to connect people and projects having similar interests. We propose APINet, a system that mines API usage profiles from source code version management systems and create a social network of people, projects and libraries. We describe our initial im-plementation that uses data from 568 open-source projects hosted on GitHub. Our system recommends to a user new projects and people that they may be interested in, suggests communities of people who use related libraries and finds experts for a given topic who are closest in a user's social graph. Copyright © 2014 ACM.";"Mining software repositories, Recommender systems, Social networks, Usage expertise"
"Sainz F., Mateo S., Beltran V., Bosque J.L., Martorell X., Ayguadé E.";"Leveraging OmpSs to exploit hardware accelerators";"CUDA and OpenCL are the most widely used programming models to exploit hardware accelerators. Both programming models provide a C-based programming language to write accelerator kernels and a host API used to glue the host and kernel parts. Although this model is a clear improvement over a low-level and ad-hoc programming model for each hardware accelerator, it is still too complex and cumbersome for general adoption. For large and complex applications using several accelerators, the main problem becomes the explicit coordination and management of resources required between the host and the hardware accelerators that introduce a new family of issues (scheduling, data transfers, synchronization,...) that the programmer must take into account. In this paper, we propose a simple extension to OmpSs - a data-flow programming model - that dramatically simplifies the integration of accelerated code, in the form of CUDA or OpenCL kernels, into any C, C++ or Fortran application. Our proposal fully replaces the CUDA and OpenCL host APIs with a few pragmas, so we can leverage any kernel written in CUDA C or OpenCL C without any performance impact. Our compiler generates all the boilerplat code while our runtime system takes care of kernels scheduling, data transfers between host and accelerators and synchronizations between host and kernels parts. To evaluate our approach, we have ported several native CUDA and OpenCL applications to OmpSs by replacing all the CUDA or OpenCL API calls by a few number of pragmas. The OmpSs versions of these applications have competitive performance and scalability but with a significantly lower complexity than the original ones. © 2014 IEEE.";"Accelerator, CUDA, OmpSs, OpenCL"
"Steele G.L., Jr., Lea D., Flood C.H.";"Fast splittable pseudorandom number generators";"We describe a new algorithm SPLITMIX for an object-oriented and splittable pseudorandom number generator (PRNG) that is quite fast: 9 64-bit arithmetic/logical operations per 64 bits generated. A conventional linear PRNG object provides a generate method that returns one pseudorandom value and updates the state of the PRNG, but a splittable PRNG object also has a second operation, split, that replaces the original PRNG object with two (seemingly) independent PRNG objects, by creating and returning a new such object and updating the state of the original object. Splittable PRNG objects make it easy to organize the use of pseudorandom numbers in multithreaded programs structured using fork-join parallelism. No locking or synchronization is required (other than the usual memory fence immediately after object creation). Because the generate method has no loops or conditionals, it is suitable for SIMD or GPU implementation. We derive SPLITMIX from the DOTMIX algorithm of Leiserson, Schardl, and Sukha by making a series of program transformations and engineering improvements. The end result is an object-oriented version of the purely functional API used in the Haskell library for over a decade, but SPLITMIX is faster and produces pseudorandom sequences of higher quality, it is also far superior in quality and speed to java.util. Random, and has been included in Java JDK8 as the class java.util. SplittableRandom. We have tested the pseudorandom sequences produced by SPLITMIX using two standard statistical test suites (DieHarder and TestU01) and they appear to be adequate for ""everyday"" use, such as in Monte Carlo algorithms and randomized data structures where speed is important. Copyright © 2014 ACM.";"Collections, Determinism, Java, Multithreading, Nondeterminism, Object-oriented, Parallel computing, Pedigree, Pseudorandom, Random number generator, Recursive splitting, Scala, Spliterator, Splittable data structures, Streams"
"Diprose J.P., Plimmer B., Macdonald B.A., Hosking J.G.";"A human-centric API for programming socially interactive robots";"Whilst robots are increasingly being deployed as social agents, it is still difficult to program them to interact socially. This is because current programming tools either require programmers to work at a low level or lack features needed to create certain aspects of social interaction. High level, domain specific tools with features designed specifically to meet the requirements of social interaction have the potential to ease the creation of social applications. We present a domain specific application programming interface (API) that is designed to meet the requirements of social interaction. The Cognitive Dimensions Framework was used as a design tool during the design process and the API was validated by implementing an exemplar application. The evaluation of the API showed that programmers with no robotics knowledge were positively impressed by the notation and that its organization, domain specific interfaces and object oriented nature positively affected several Cognitive Dimensions. © 2014 IEEE.";"api, application programming interfaces, cognitive dimensions, design, human robot interaction, humanoid robot, social robot interaction, usability"
"Lee S., Lee S., Lim S., Jung J., Choi S., Kim N., Lee J.-B.";"An API design process in terms of usability: A case study on building more usable apis for smart TV platform";"Products are released based on various platforms. An Application programing interface (API) is important to develop platform based applications effectively. Previously, we had some difficulties in developing applications using our platform APIs. Their name was ambiguous, and their functions were not primitive, and even their documentation was not enough to refer to. Therefore, we had to maintain our platform APIs. In this paper, we propose an API design process and API evaluation guidelines. 'API Analysts' elicit functions from requirement documents. 'API designer' design APIs for the functions following the guidelines. 'Technical writers' produce documentation for the APIs. 'API reviewers' evaluate the APIs and API documentation conforming to the proposed guidelines. Proposed process made our platform APIs more convenient to use for developing applications. © 2014 IEEE.";"api, applicaton programming interface, platform product, process, requirements, software, usability"
"Diprose J.P.";"Tools for programming human robot interaction";"Whilst robots are increasingly being used in scenarios that involve human-robot interaction, it is still difficult to program them to interact with humans. This is because current programming tools either require programmers to work at low abstraction levels or they lack features needed to implement particular aspects of human-robot interaction. Our goal is to create an API that is both capable of programming a wide range of human-robot interaction scenarios and is easy to use by the various users of human-robot interaction programming tools. We have taken a first step toward this API by developing an exemplar, high level API for programming social interaction and evaluating it with the Cognitive Dimensions framework. We plan to explore other aspects of human-robot interaction, including navigation and manipulation and exploring how they should be integrated with our existing primitives for programming social interaction. © 2014 IEEE.";"api, application programming interfaces, cognitive dimensions, design, human robot interaction, humanoid robot, manipulation, navigation, social robot interaction, usability"
"Lu H.K.";"Keeping your API keys in a safe";"Cloud API (Application Programming Interface) enables client applications to access services and manage resources hosted in the Cloud. To protect themselves and their customers, Cloud service providers (CSP) often require client authentication for each API call. The authentication usually depends on some kind of secret (or called API key), for example, secret access key, password, or access token. As such, the API key unlocks the door to the treasure inside the Cloud. Hence, protecting these keys is critical. It is a difficult task especially on the client side, such as users' computers or mobile devices. How do CSPs authenticate client applications? What are security risks of managing API keys in common practices? How can we mitigate these risks? This paper focuses on finding answers to these questions. By reviewing popular client authentication methods that CSPs use and using Cloud APIs as software developers, we identified various security risks associated with API keys. To mitigate these risks, we use hardware secure elements for secure key provisioning, storage, and usage. The solution replaces the manual key handling with end-to-end security between CSP and its customers' secure elements. This removes the root causes of the identified risks and enhances API security. It also enhances the usability by eliminating manual key operations and alleviating software developers' worries of working with cryptography. © 2014 IEEE.";"client authentication, key management, secure elements, security"
"Nagaraju S.";"Shapers: Capturing free form shapes for bendable device interactions";"Future mobile and wearable devices are heavily influenced by advances in materials which make the devices flexible to interact. In this paper, we propose a system to capture the shape of bent device at graphics framework and make use of the shape to develop novel user interactions for native and app store downloadable applications on consumer electronic devices. We further detail the API, parameters and prototype on Android for shape generation along with OpenGL based emulation for bendable device deformation, followed by usability study results. © 2014 The Authors. Published by Elsevier B.V.";"Bendable displays, Bezier curves, Flexible displays, Gestures, Graphics Framework, NURBS, Tangible interaction"
"Ramakrishnan L., Poon S., Hendrix V., Gunter D., Pastorello G.Z., Agarwal D.";"Experiences with user-centered design for the tigres workflow API";"Scientific data volumes have been growing exponentially. This has resulted in the need for new tools that enable users to operate on and analyze data. Cyber infrastructure tools, including workflow tools, that have been developed in the last few years has often fallen short if user needs and suffered from lack of wider adoption. User-centered Design (UCD) process has been used as an effective approach to develop usable software with high adoption rates. However, UCD has largely been applied for user-interfaces and there has been limited work in applying UCD to application program interfaces and cyber infrastructure tools. We use an adapted version of UCD that we refer to as Scientist-Centered Design (SCD) to engage with users in the design and development of Tigres, a workflow application programming interface. Tigres provides a simple set of programming templates (e.g., sequence, parallel, split, merge) that can be can used to compose and execute computational and data transformation pipelines. In this paper, we describe Tigres and discuss our experiences with the use of UCD for the initial development of Tigres. Our experience-to-date is that the UCD process not only resulted in better requirements gathering but also heavily influenced the architecture design and implementation details. User engagement during the development of tools such as Tigres is critical to ensure usability and increase adoption. © 2014 IEEE."
"Park J.H., Hung J.C., Yen N.Y., Jeong Y.-S.";"Guest editorial: Advanced convergence technologies: Big data, IoT, cloud computing";"The special issue 2014, Volume 15 of Journal of Internet Technology presents an overview of the state-of-the-art of issues and solution guidelines for the Advanced Convergence Technologies, Big Data, IoT and Cloud Computing. Joon-Min Gil and co-researchers presented a user-created computing framework for desktop grids as entitled 'Organizing a User-Created Computing Environment by RESTful Web Service Open APIs in Desktop Grids.' Using the framework, application developers can utilize DGSs easily and conveniently as computational tools in order to solve their own applications. Sadiq Almuairfi and co-researchers compared IPAS with other authentication schemes by performing two experiments and asking participants to answer a questionnaire as entitled 'A Comparative Study of Authentication Schemes with Security and Usability of IPAS.' They explained the usability and security of IPAS from the users' point of view. Prosper Mafole et al. proposed a novel fragmentation scheme called backoff-free fragment retransmission (BFFR)."
"Ertugrul A.M., Onal I.";"RemindMe: An enhanced mobile location-based reminder application";"In this study, a location based reminder application RemindMe, enhanced with various location tagging options using social networking APIs is proposed. Main purpose of this application is to allow users to create reminders based on the location besides time and to notify users with those reminders automatically. In terms of ease of use, a hybrid structure consisting of various components is formed for location tagging. First of all, the user tags the locations using the applications such as Google Maps or Foursquare or via the embedded sensors of the Android device. Then, he creates reminders for the tagged locations and when he gets close to this location, the system notifies the user. Our application is separated from similar applications with its enhanced location tagging feature. Moreover, by consisting of various services, it is open to innovations on the way to become a social reminder application. The usability test results indicate that RemindMe is an effective location based reminder application. © 2014 IEEE.";"Foursquare, Google Maps, location based reminder"
"Danelutto M., Torquati M.";"Loop parallelism: A new skeleton perspective on data parallel patterns";"Traditionally, skeleton based parallel programming frameworks support data parallelism by providing the programmer with a comprehensive set of data parallel skeletons, based on different variants of map and reduce patterns. On the other side, more conventional parallel programming frameworks provide application programmers with the possibility to introduce parallelism in the execution of loops with a relatively small programming effort. In this work, we discuss a ""ParallelFor"" skeleton provided within the FastFlow framework and aimed at filling the usability and expressivity gap between the classical data parallel skeleton approach and the loop parallelisation facilities offered by frameworks such as OpenMP and Intel TBB. By exploiting the low run-time overhead of the FastFlow parallel skeletons and the new facilities offered by the C++11 standard, our ParallelFor skeleton succeeds to obtain comparable or better performance than both OpenMP and TBB on the Intel Phi many-core and Intel Nehalem multi-core for a set of benchmarks considered, yet requiring a comparable programming effort. © 2014 IEEE.";"algorithmic skeleton, data parallelism, loop parallelism, multi- and many-core, parallel design patterns"
"Spliet R., Howes L., Gaster B.R., Varbanescu A.L.";"KMA: A dynamic memory manager for OpenCL";"OpenCL is becoming a popular choice for the parallel programming of both multi-core CPUs and GPGPUs. One of the features missing in OpenCL, yet commonly required in irregular parallel applications, is dynamic memory allocation. In this paper, we propose KMA, a first dynamic memory allocator for OpenCL. KMA's design is based on a thorough analysis of a set of 11 algorithms, which shows that dynamic memory allocation is a necessary commodity, typically used for implementing complex data structures (arrays, lists, trees) that need constant restructuring at runtime. Taking into account both the survey findings and the status- quo of OpenCL, we design KMA as a two-layer memory manager that makes smart use of the patterns we identified in our application analysis: its basic functionality provides generic malloc() and free() APIs, while the higher layer provides support for building and efficiently managing dynamic data structures. Our experiments measure the performance and usability of KMA, using both microbenchmarks and a real-life case-study. Results show that when dynamic allocation is mandatory, KMA is a competitive allocator. We conclude that embedding dynamic memory allocation in OpenCL is feasible, but it is a complex, delicate task due to the massive parallelism of the platform and the portability issues between different OpenCL implementations. Copyright 2014 ACM.";"Dynamic memory allocation, Massive parallelism, Multi-/many- cores, OpenCL kernels"
"Kumar V., Zheng Y., Cavé V., Budimlić Z., Sarkar V.";"HabaneroUPC++: A compiler-free PGAS library";"The Partitioned Global Address Space (PGAS) programming models combine shared and distributed memory features, providing the basis for high performance and high productivity parallel programming environments. UPC++ [39] is a very recent PGAS implementation that takes a library-based approach and avoids the complexities associated with compiler transformations. However, this implementation does not support dynamic task parallelism and only relies on other threading models (e.g., OpenMP or pthreads) for exploiting parallelism within a PGAS place. In this paper, we introduce a compiler-free PGAS library called HabaneroUPC++, which supports a tighter integration of intraplace and inter-place parallelism than standard hybrid programming approaches. The library makes heavy use of C++11 lambda functions in its APIs. C++11 lambdas avoid the need for compiler support while still retaining the syntactic convenience of languagebased approaches. The HabaneroUPC++ library implementation is based on a tight integration of the UPC++ library and the Habanero-C++ library, with new extensions to support the integration. The UPC++ library is used to provide PGAS communication and function shipping support using GASNet, and the Habanero-C++ library is used to provide support for intra-place work-stealing integrated with function shipping. We demonstrate the programmability and performance of our implementation using two benchmarks, scaled up to 6K cores. The insights developed in this paper promise to further enhance the usability and popularity of PGAS programming models. (c) 2014 Association for Computing Machinery. Copyright 2014 ACM 978-1-4503-3247-7/14/10...$15.00.";"Habanero, PGAS, Scheduling, UPC++, Work-stealing"
"Zaghi S.";"OFF, Open source Finite volume Fluid dynamics code: A free, high-order solver based on parallel, modular, object-oriented Fortran API";"OFF, an open source (free software) code for performing fluid dynamics simulations, is presented. The aim of OFF is to solve, numerically, the unsteady (and steady) compressible Navier-Stokes equations of fluid dynamics by means of finite volume techniques: the research background is mainly focused on high-order (WENO) schemes for multi-fluids, multi-phase flows over complex geometries. To this purpose a highly modular, object-oriented application program interface (API) has been developed. In particular, the concepts of data encapsulation and inheritance available within Fortran language (from standard 2003) have been stressed in order to represent each fluid dynamics ""entity"" (e.g. the conservative variables of a finite volume, its geometry, etc...) by a single object so that a large variety of computational libraries can be easily (and efficiently) developed upon these objects. The main features of OFF can be summarized as follows: Programming LanguageOFF is written in standard (compliant) Fortran 2003, its design is highly modular in order to enhance simplicity of use and maintenance without compromising the efficiency, Parallel Frameworks Supported the development of OFF has been also targeted to maximize the computational efficiency: the code is designed to run on shared-memory multi-cores workstations and distributed-memory clusters of shared-memory nodes (supercomputers), the code's parallelization is based on Open Multiprocessing (OpenMP) and Message Passing Interface (MPI) paradigms, Usability, Maintenance and Enhancement in order to improve the usability, maintenance and enhancement of the code also the documentation has been carefully taken into account, the documentation is built upon comprehensive comments placed directly into the source files (no external documentation files needed): these comments are parsed by means of doxygen free software producing high quality html and latex documentation pages, the distributed versioning system referred as git has been adopted in order to facilitate the collaborative maintenance and improvement of the code, CopyrightsOFF is a free software that anyone can use, copy, distribute, study, change and improve under the GNU Public License version 3. The present paper is a manifesto of OFF code and presents the currently implemented features and ongoing developments. This work is focused on the computational techniques adopted and a detailed description of the main API characteristics is reported. OFF capabilities are demonstrated by means of one and two dimensional examples and a three dimensional real application.";"CFD, Finite volume scheme, MPI, OOP Fortran, OpenMP, Riemann's Problem solver, WENO"
"Viyanon W.";"Bus search: Development and evaluation of performance and usability of mobile application for blind or visually impaired";"This paper describes the design and development of a mobile application supporting independent travel in accessing public buses for people who are blind or visually impaired. The key objective is to develop solutions that are low cost, have an intuitive and easy to use interface. The Android architecture was used with speech recognition (SR) technology in order to assist blind or visually impaired users. With the help of A-GPS in phones and through Web Services using GPRS, Location Based Services can be implemented on android based on smart phones to provide value-added services: retrieving current traffic conditions, providing routing information, getting estimated wait time for users. The mobile application supports two languages, English and Thai as voice inputs using open-source CMU Sphinx for Thai and Google speech recognition API for English. Empirical analysis under various environments such as indoor, outdoor, and building surrounded and usability studies were performed to illustrate the efficacy of the application. The results of average of application response time are acceptable according to SOASTA's survey. Improved feedback was added based on usability study results.";"Android mobile application, Assistive technology, Location Based Services, Speech recognition"
"Dickinson A.W.L., Abolmaesumi P., Gobbi D.G., Mousavi P.";"SimITK: Visual programming of the ITK image-processing library within simulink";"The Insight Segmentation and Registration Toolkit (ITK) is a software library used for image analysis, visualization, and image-guided surgery applications. ITK is a collection of C++ classes that poses the challenge of a steep learning curve should the user not have appropriate C++ programming experience. To remove the programming complexities and facilitate rapid prototyping, an implementation of ITK within a higher-level visual programming environment is presented: SimITK. ITK functionalities are automatically wrapped into ""blocks"" within Simulink, the visual programming environment of MATLAB, where these blocks can be connected to form workflows: visual schematics that closely represent the structure of a C++ program. The heavily templated C++ nature of ITK does not facilitate direct interaction between Simulink and ITK, an intermediary is required to convert respective data types and allow intercommunication. As such, a SimITK ""Virtual Block"" has been developed that serves as a wrapper around an ITK class which is capable of resolving the ITK data types to native Simulink data types. Part of the challenge surrounding this implementation involves automatically capturing and storing the pertinent class information that need to be refined from an initial state prior to being reflected within the final block representation. The primary result from the SimITK wrapping procedure is multiple Simulink block libraries. From these libraries, blocks are selected and interconnected to demonstrate two examples: a 3D segmentation workflow and a 3D multimodal registration workflow. Compared to their pure-code equivalents, the workflows highlight ITK usability through an alternative visual interpretation of the code that abstracts away potentially confusing technicalities. © 2014 Society for Imaging Informatics in Medicine.";"Image processing, Image registration, Image segmentation, Software design, Visual programming"
"Popelka S., Dedkova P.";"Extinct village 3D visualization and its evaluation with eye-movement recording";"The objective of the project was to create 3D visualization of extinct village and its evaluation using eye-tracking. As an area of interest, extinct village Čistá was selected. The village was located in Karlovy Vary Region in Czech Republic and was destroyed in 1948. The purpose of destroying the village was emerging of military training area. Second purpose was to create instructional video for military purposes ""Fight in the settlement"". During the creation of this video, the village was destroyed. The main content of the project was to create an interactive web application that includes 3D model of the extinct village Čistá. As underlying data, aerial photos made in 1947 and stable cadastre from 1841 were used. Buildings were made according to historical photographs and screen shots from instruction video ""Fight in a settlement"". Resulting 3D model and underlying data were loaded into Google Earth API and are available for the general public now. The last part was to test the model usability using eye-tracking. In total, 28 respondents participated in the experiment. The experiment contained three parts - the overall views of the village, details of the model and tasks, where users were searching for particular building. Results from testing were of statistical and graphical nature. Link to the application was placed on the web site of the project of an educational trail about extinct villages in Slavkov forest area. Created 3D model and application present the extinct village Čistá to potential visitors the educational trail. © 2014 Springer International Publishing.";"3D, Cartography, Eye-tracking, Reconstruction, Visualization"
"Spiza S., Hanenberg S.";"Type names without static type checking already improve the usability of APIs (As Long as the Type Names are Correct): An Empirical Study";"In the discussion about the usefulness of static or dynamic type systems there is often the statement that static type systems improve the documentation of software. In the meantime there exists even some empirical evidence for this statement. One of the possible explanations for this positive influence is that the static type system of programming languages such as Java require developers to write down the type names, i.e. lexical representations which potentially help developers. Because of that there is a plausible hypothesis that the main benefit comes from the type names and not from the static type checks that are based on these names. In order to argue for or against static type systems it is desirable to check this plausible hypothesis in an experimental way. This paper describes an experiment with 20 participants that has been performed in order to check whether developers using an unknown API already benefit (in terms of development time) from the pure syntactical representation of type names without static type checking. The result of the study is that developers do benefit from the type names in an API's source code. But already a single wrong type name has a measurable significant negative impact on the development time in comparison to APIs without type names. Copyright © 2014 ACM. Copyright © 2014 ACM.";"Empirical research, Programming languages, Type systems"
"Kührer M., Hoffmann J., Holz T.";"CloudSylla: Detecting suspicious system calls in the cloud";"To protect computer systems against the tremendous number of daily malware threats, security software is typically installed on individual end hosts and the responsibility to keep this software updated is often assigned to (inexperienced) users. A critical drawback of this strategy, especially in enterprise networks, is that a single unprotected client system might lead to severe attacks such as industrial espionage. To overcome this problem, a potential approach is to move the responsibility to utilize the latest detection mechanisms to a centralized, continuously maintained network service to identify suspicious behavior on end hosts and perform adequate actions once a client invokes malicious activities. In this paper, we propose a security approach called CloudSylla (Cloud-based SY scaLL Analysis) in which we utilize a centralized network service to analyze the clients’ activities directly at the API and system call level. This enables, among other advantages, a centralized management of signatures and a unified security policy. To evaluate the applicability of our approach, we implemented prototypes for desktop computers and mobile devices and found this approach to be applicable in practice as no substantial limitations of usability are caused on the client side. © Springer International Publishing Switzerland 2014."
"Shimizu Y.";"Incorporating Green into Production and Consumption Behaviours toward Sustainable Logistics Optimization in Process Systems";"Recently, realizing low carbon society has attracted a great interest under a provision for essential infrastructure aligned with sustainable development. Deployment of green logistics incorporating co-existence of manufacturers and consumers will be a new key issue for such technologies. Noticing such circumstance, in this paper, we have extended our approaches for logistics optimization to cope with green logistics associated with production and consumption behaviours in process systems. Taking a multi-layer logistics network, we have developed a novel approach that tries to evaluate the minimum total cost and CO2 emission under appropriate constraints through adjusting prone and aversion consciousness on sustainability among the logistics members. Numerical experiment has been carried out to validate effectiveness of the proposed approach. Moreover, to enhance usability toward real-world applications, we provide a system development aimed at using Google map API. © 2014 Elsevier B.V.";"Co-Exist of Production, Consumption, Green Logistics Optimization, Hybrid Meta-Heuristic Method, Sustainability"
"Khan H., Atwater A., Hengartner U.";"Itus: An implicit authentication framework for android";"Security and usability issues with pass-locks on mobile devices have prompted researchers to develop implicit authentication (IA) schemes, which continuously and transparently authenticate users using behavioural biometrics. Contemporary IA schemes proposed by the research community are challenging to deploy, and there is a need for a framework that supports: different behavioural classifiers, given that different apps have different requirements, app developers using IA without becoming domain experts, and real-time classification on resource-constrained mobile devices. We present Itus, an IA framework for Android that allows the research community to improve IA schemes incrementally, while allowing app developers to adopt these improvements at their own pace. CopyrightWe describe the Itus framework and how it provides: ease of use: Itus allows app developers to use IA by changing as few as two lines of their existing code|on the other hand, Itus provides an oracle capable of making advanced recommendations should developers wish to fine-tune the classifiers, exibility: developers can deploy Itus in an application-specific manner, adapting to their unique needs, extensibility: researchers can contribute new behavioural features and classifiers without worrying about deployment particulars, low performance overhead: Itus operates with minimal performance overhead, allowing app developers to deploy it without compromising end-user experience. These goals are accomplished with an API allowing individual stakeholders to incrementally improve Itus without reengineering new systems. We implement Itus in two demo apps and measure its performance impact. To our knowledge, Itus is the first open-source extensible IA framework for Android that can be deployed off-the-shelf. © 2014 by the Association for Computing Machinery, Inc. (ACM).";"Behavioural biometrics, Implicit authentication, Security"
"Stroggylos K., Mitropoulos D., Tzermias Z., Papadopoulos P., Rafailidis F., Spinellis D., Ioannidis S., Katsaros P.";"TRACER: A platform for securing legacy code";"A security vulnerability is a programming error that introduces a potentially exploitable weakness into a computer system. Such a vulnerability can severely affect an organization's infrastructure and cause significant financial damage to it. Hence, one of the basic pursuits in every new software release should be to mitigate such defects. A number of tools and techniques are available for performing vulnerability detection in software written in various programming platforms. One of the most common approaches to identify software vulnerabilities is static analysis [1]. This kind of analysis is performed by automated tools either on the program's source or object code and without actually executing it. However, since the formats in which static analysis tools store and present their results vary wildly, it is typically difficult to utilize many of them in the scope of a project. By automating the process of running a variety of vulnerability detectors and collecting their results in an efficient manner during development, the task of tracking security defects throughout the evolution history of software projects can be simplified. In this paper we present TRACER, a framework to support the development of secure applications by constantly monitoring software projects for vulnerabilities. TRACER simplifies the integration of existing tools that detect software vulnerabilities and promotes their use during development and maintenance. Instead of designing and implementing TRACER from the ground up, we built it on top of the open source Alitheia Core [2] platform, which is designed for facilitating large scale quantitative software engineering studies. While Alitheia Core aims for efficient estimation of the quality of software projects, TRACER was designed with a focus on software security. To support the specific objectives of TRACER, a set of new components was added at each level of the Alitheia Core architecture. These include a model for representing software vulnerabilities, a mechanism for automatic vulnerability detection triggering, a REST API for accessing the analysis results, and an archetype for plug-ins to integrate new vulnerability detection tools in the platform. Like Alitheia Core, TRACER monitors multiple data sources associated with the development of a software project, such as the source code repository and bug tracking system, and automatically analyzes each revision. Therefore it can be used to track security defects throughout the evolution of a project. In most cases, the detection of vulnerabilities on a software artifact involves only two steps: invoking an external tool created for this purpose with specific arguments as required, and evaluating the results it generates. There is a vast number of software vulnerability detection tools available, each one having different operating requirements. Such a tool can be integrated in TRACER by creating a corresponding driver that implements these two steps and stores the results using the data model provided by the platform. Thus we can leverage the functionality provided by existing tools, without duplicating it. Such an external tool driver is called a vulnerability detector plug-in, and it uses the Alitheia Core infrastructure to handle automatic activation, as well as storage and retrieval of results. Each vulnerability detector is associated with the set of vulnerability types it can detect and the different types of software artifacts or programming constructs that it can analyze. This allows the platform to automatically trigger it when needing to check if a software project or artifact is vulnerable to a specific type of attacks or a new artifact is submitted to the system for evaluation. To demonstrate the efficiency and usability of the platform, we have created plug-ins to integrate two different tools for vulnerability detection, namely: FindBugs [3], and Frama-c [4]. The former analyzes applications written in Java, while the latter examines applications written in c. This highlights the fact that our platform does not depend on the programming language used to develop the project that is being analyzed, and that the simplicity of integrating third party tools leads to high levels of expandability of the platform. © 2014 Springer International Publishing.";"Legacy software, Software Security, Static Analysis, Trusted Applications"
"Chang K.S.-P., Myers B.A., Cahill G.M., Simanta S., Morris E., Lewis G.";"A plug-in architecture for connecting to new data sources on mobile devices";"A key use for mobile devices is to search and view online information while on the go. As a result, many mobile applications serve as front ends for online databases. While there are many thousands of data sources that provide web service APIs giving access to their databases, creating mobile applications to use those sources requires significant mobile programming knowledge and a significant amount of time. We introduce Spinel, a plug-in architecture for Android, and a set of web-based configuration tools that together enable users to connect mobile applications to new data sources without programming. Spinel also provides APIs that make it easy for developers to create new applications that use those data sources. We provide three demonstration Android applications that use such data: Listpad for entering personal lists, Listviewer for viewing results of data queries, and Mapviewer for displaying query results on a map. An informal usability study showed that users could successfully attach new data sources to those applications. © 2013 IEEE.";"end-user programming, mashups, mobile devices, plug-ins, web APIs"
"Zhu Z., Zou Y., Jin Y., Xie B.";"Generating API-usage example for project developers";"Usage examples have been shown very helpful for API learning in software reuse. Nowadays, many approaches have been proposed to automatically extract usage examples from client code or web pages for API users. However, they overlooked the benefit of API developers in example publishing and few works paid attention to help API developers to generate usage examples automatically. In this paper, we proposed an approach to generate API-usage example based on test code before the project are released. It analyzed which parts in test code are important for indicating APIusage and summarized some test code patterns, then a heuristic slice algorithm are proposed to extract referential test code as APIusage example based on these patterns. In the experiments, we gave some case studies on the commons-lang3 open source software library. It proved that our approach can provide good assistance for developers in APIs usage example generation.";"Software reuse, Test code, Test scenario, Usage example"
"Wang W., Godfrey M.W.";"Detecting API usage obstacles: A study of iOS and android developer questions";"Software frameworks provide sets of generic functionalities that can be later customized for a specific task. When developers invoke API methods in a framework, they often encounter obstacles in finding the correct usage of the API, let alone to employ best practices. Previous research addresses this line of questions by mining API usage patterns to induce API usage templates, by conducting and compiling interviews of developers, and by inferring correlations among APIs. In this paper, we analyze API-related posts regarding iOS and Android development from a Q&A website, stackoverflow.com. Assuming that API-related posts are primarily about API usage obstacles, we find several iOS and Android API classes that appear to be particularly likely to challenge developers, even after we factor out API usage hotspots, inferred by modelling API usage of open source iOS and Android applications. For each API with usage obstacles, we further apply a topic mining tool to posts that are tagged with the API, and we discover several repetitive scenarios in which API usage obstacles occur. We consider our work as a stepping stone towards understanding API usage challenges based on forum-based input from a multitude of developers, input that is prohibitively expensive to collect through interviews. Our method helps to motivate future research in API usage, and can allow designers of platforms - such as iOS and Android - to better understand the problems developers have in using their platforms, and to make corresponding improvements. © 2013 IEEE."
"Wang J., Dang Y., Zhang H., Chen K., Xie T., Zhang D.";"Mining succinct and high-coverage API usage patterns from source code";"During software development, a developer often needs to discover specific usage patterns of Application Programming Interface (API) methods. However, these usage patterns are often not well documented. To help developers to get such usage patterns, there are approaches proposed to mine client code of the API methods. However, they lack metrics to measure the quality of the mined usage patterns, and the API usage patterns mined by the existing approaches tend to be many and redundant, posing significant barriers for being practical adoption. To address these issues, in this paper, we propose two quality metrics (succinctness and coverage) for mined usage patterns, and further propose a novel approach called Usage Pattern Miner (UP-Miner) that mines succinct and high-coverage usage patterns of API methods from source code. We have evaluated our approach on a large-scale Microsoft codebase. The results show that our approach is effective and outperforms an existing representative approach MAPO. The user studies conducted with Microsoft developers confirm the usefulness of the proposed approach in practice. © 2013 IEEE.";"API usage, Mining software repositories, Sequence mining, Software reuse, Usage pattern"
"[No author name available]";"2013 10th Working Conference on Mining Software Repositories, MSR 2013 - Proceedings";"The proceedings contain 63 papers. The topics discussed include: why so complicated? simple term filtering and weighting for location-based bug report assignment recommendation, bug report assignee recommendation using activity profiles, retrieving and analyzing mobile apps feature requests from online reviews, Gerrit software code review data from android, why, when, and what: analyzing stack overflow questions by topic, type, and code, deficient documentation detection: a methodology to locate deficient project documentation using topic analysis, detecting API usage obstacles: a study of iOS and Android developer questions, a discriminative model approach for suggesting tags automatically for stack overflow questions, a study of innovation diffusion through link sharing on stack overflow, building reputation in stackoverflow: an empirical investigation, and intensive metrics for the study of the evolution of open source projects: case studies from apache software foundation projects."
"Gascon H., Yamaguchi F., Arp D., Rieck K.";"Structural detection of Android malware using embedded call graphs";"The number of malicious applications targeting the Android system has literally exploded in recent years. While the security community, well aware of this fact, has proposed several methods for detection of Android malware, most of these are based on permission and API usage or the identification of expert features. Unfortunately, many of these approaches are susceptible to instruction level obfuscation techniques. Previous research on classic desktop malware has shown that some high level characteristics of the code, such as function call graphs, can be used to find similarities between samples while being more robust against certain obfuscation strategies. However, the identification of similarities in graphs is a non-trivial problem whose complexity hinders the use of these features for malware detection. In this paper, we explore how recent developments in machine learning classification of graphs can be efficiently applied to this problem. We propose a method for malware detection based on efficient embeddings of function call graphs with an explicit feature map inspired by a linear-time graph kernel. In an evaluation with 12,158 malware samples our method, purely based on structural features, outperforms several related approaches and detects 89% of the malware with few false alarms, while also allowing to pin-point malicious code structures within Android applications. © 2013 ACM.";"graph kernels, machine learning, malware detection"
"Moritz E., Linares-Vasquez M., Poshyvanyk D., Grechanik M., McMillan C., Gethers M.";"ExPort: Detecting and visualizing API usages in large source code repositories";"This paper presents a technique for automatically mining and visualizing API usage examples. In contrast to previous approaches, our technique is capable of finding examples of API usage that occur across several functions in a program. This distinction is important because of a gap between what current API learning tools provide and what programmers need: current tools extract relatively small examples from single files/functions, even though programmers use APIs to build large software. The small examples are helpful in the initial stages of API learning, but leave out details that are helpful in later stages. Our technique is intended to fill this gap. It works by representing software as a Relational Topic Model, where API calls and the functions that use them are modeled as a document network. Given a starting API, our approach can recommend complex API usage examples mined from a repository of over 14 million Java methods. © 2013 IEEE.";"API usage, call graph, code search, visualization"
"Piccioni M., Furia C.A., Meyer B.";"An empirical study of API usability";"Modern software development extensively involves reusing library components accessed through their Application Programming Interfaces (APIs). Usability is therefore a fundamental goal of API design, but rigorous empirical studies of API usability are still relatively uncommon. In this paper, we present the design of an API usability study which combines interview questions based on the cognitive dimensions framework, with systematic observations of programmer behavior while solving programming tasks based on ''tokens''. We also discuss the implementation of the study to assess the usability of a persistence library API (offering functionalities such as storing objects into relational databases). The study involved 25 programmers (including students, researchers, and professionals), and provided additional evidence to some critical features evidenced by related studies, such as the difficulty of finding good names for API features and of discovering relations between API types. It also discovered new issues relevant to API design, such as the impact of flexibility, and confirmed the crucial importance of accurate documentation for usability. © 2013 IEEE.";"application programming interfaces"
"McDonnell T., Ray B., Kim M.";"An empirical study of API stability and adoption in the android ecosystem";"When APIs evolve, clients make corresponding changes to their applications to utilize new or updated APIs. Despite the benefits of new or updated APIs, developers are often slow to adopt the new APIs. As a first step toward understanding the impact of API evolution on software ecosystems, we conduct an in-depth case study of the co-evolution behavior of Android API and dependent applications using the version history data found in github. Our study confirms that Android is evolving fast at a rate of 115 API updates per month on average. Client adoption, however, is not catching up with the pace of API evolution. About 28% of API references in client applications are outdated with a median lagging time of 16 months. 22% of outdated API usages eventually upgrade to use newer API versions, but the propagation time is about 14 months, much slower than the average API release interval (3 months). Fast evolving APIs are used more by clients than slow evolving APIs but the average time taken to adopt new versions is longer for fast evolving APIs. Further, API usage adaptation code is more defect prone than the one without API usage adaptation. This may indicate that developers avoid API instability. © 2013 IEEE."
"Freitas A., O'Riain S., Curry E.";"A distributional semantic search infrastructure for linked dataspaces";"This paper describes and demonstrates a distributional semantic search service infrastructure for Linked Dataspaces. The center of the approach relies on the use of a distributional semantics infrastructure to provide semantic search and query services over data for users and applications, improving data accessibility over the Dataspace. By accessing the services through a REST API, users can semantically index and search over data using the distributional semantic knowledge embedded in the reference corpus. The use of distributional semantic models, which rely on the automatic extraction from large corpora, supports a comprehensive and approximative semantic matching mechanism with a low associated adaptation cost for the inclusion of new data sources. © Springer-Verlag 2013.";"Dataspaces, Distributional semantics, Explicit semantic analysis, Linked data, Semantic matching, Semantic search"
"Amini R., Lisetti C.";"HapFACS: An open source API/Software to generate FACS-based expressions for ECAs animation and for corpus generation";"We present HapFACS (ver. beta), a new open source software and API for generating FACS-based facial expressions on 3D virtual characters that have accompanying lip-synchronized animation abilities. HapFACS has two main usage scenarios: First, with the HapFACS software, users can generate repertoires of realistic FACS-validated facial expressions, either as static images or as videos, Second, with the accessible HapFACS API, users can animate speaking virtual characters with real-time realistic facial expressions, and embed these expressive characters in their own application(s) without any prior experience in computer graphics and modeling. We describe how HapFACS (1) provides control over 49 FACS Action Units at all levels of intensity, (2) enables the animation of faces with a single AU or a composition of AUs, activated unilaterally or bilaterally, and (3) can be applied to any supported character in the underlying 3D-character system. Finally, we provide details of evaluation experiments we conducted with FACS-certified scorers to validate the facial expressions generated by HapFACS. © 2013 IEEE.";"EmFACS, Facial action coding system, FACS-based facial expression generation, HapFACS, Haptek"
"Cardoso J.C.S., José R.";"Evaluation of a programming toolkit for interactive public display applications";"Interaction is repeatedly pointed out as a key enabling element towards more engaging and valuable public displays. Still, most digital public displays today do not support any interactive features. We argue that this is mainly due to the lack of efficient and clear abstractions that developers can use to incorporate interactivity into their applications. As a consequence, interaction represents a major overhead for developers, and users are faced with inconsistent interaction models across different displays. This paper describes the results of the evaluation of a widget toolkit for generalized interaction with public displays. Our toolkit was developed for web-based applications and it supports multiple interaction mechanisms, automatically generated graphical interfaces, asynchronous events and concurrent interaction. We have evaluated the toolkit along various dimensions - system performance, API usability, and real-world deployment - and we present and discuss the results in this paper. © 2013 ACM.";"Interaction abstraction, Public display applications, Toolkit"
"Sankhe P., Kuriakose S., Lahiri U.";"A step towards a robotic system with smartphone working as its brain: An assistive technology";"This paper describes a novel smartphone based navigation application. The smartphone based robotic system is sensitive to both the tactile and head-movement input commands from a user. Here we present our design used for developing a prototype of the robotic system as a proof-of-concept of an assistive technology that could facilitate partially disabled people to navigate effectively. Additionally we designed a usability study where our prototype was validated by seven healthy participants. Such an intelligent robotic system controlled by a smartphone can find a variety of applications based on navigation systems for disabled persons, educational tools especially for children with autism, surveillance and social telepresence. The hardware prototype could then be further used for development purposes to build a variety of applications using Application Program Interfaces (APIs) that can program the robot to do a custom task. © 2013 IEEE.";"assistive technology, Human robot interaction, navigation, smartphones"
"Lin H., Jia J., Wu X., Cai L.";"TalkingAndroid: An interactive, multimodal and real-time talking avatar application on mobile phones";"In this paper, we present a novel interactive, multimodal and real-time 3D talking avatar application, on mobile platforms. The application is based on a novel network independent, stand-alone framework using cross-platform JNI and OpenGL ES library. In this framework, we implement the audio synthesis, facial animation rendering and the audio-visual synchronization process on the mobile client using the native APIs to optimize the render performance and power consumption. We also utilize the existing interactive APIs on the mobile devices to extend the usability of the application. Experiment results show that the proposed framework for mobile platforms can run smoothly on the current mobile devices with real-time multimodal interaction. Compared to the traditional video streaming method and the client-server framework, the proposed framework has much lower network requirement, with much shorter interaction delay and more efficient power consumption. The presented application can be used in entertainment, education and many other interactive areas. © 2013 APSIPA.";"3D talking avatar, Android, mobile phones, standalone framework"
"Fujimoto T., Nishimura K., Takahashi K., Yachi M., Takahashi K., Yamauchi Y.";"Global math: Development of online platform for mathematical thinking games";"While some gaming portals provide learning-based games, most of them either merely showcase games without offering any function for user feedback for the developers or do not provide open access to individual developers, even if a website has functions for data collection. Therefore, it is difficult for individual developers and small independent teams to obtain user feedback for making enhancements in their games in the prototyping phase. The purpose of this research is to develop and evaluate an open online platform system to host mathematical thinking games. Through a joint research project in collaboration with the University of Tokyo and Benesse Corporation, we have developed the 'Global Math' platform, which is an open online platform to host mathematical thinking games for Indie game developers and students interested in developing learning games. The platform features the 'Global Math API', which enables game developers to obtain play log data by simply registering and embedding certain JavaScript codes. The API offers an interface that stores play log data in the Global Math platform database. The platform offers data-analytic functions to monitor how the games are played and received by audiences. As a formative assessment of the platform in terms of usability and effectiveness, four teams of undergraduate students who study game design participated in a game design project using the platform. The teams worked on the project for two months and uploaded four game prototypes successfully. The survey findings indicate that the students found that this project offered them an opportunity to think about different aspects of game design that they had not considered previously, and they found it appealing to develop mathematical learning games. It showed that developing mathematical games can be engaging for students as long as they are provided with the necessary resources. The survey also indicates that more instructional and technical support for developers is necessary to use the functions of the platform.";"Embedded assessment, Game platform, Game-based learning, Mathematical games, Social media"
"Dayarathna M., Suzumura T.";"A first view of exedra: A domain-specific language for large graph analytics workflows";"In recent years, many programming models, software libraries, and middleware have appeared for processing large graphs of various forms. However, there exists a significant usability gap between the graph analysis scientists, and High Performance Computing (HPC) application programmers due to the complexity of HPC graph analysis software. In this paper we provide a basic view of Exedra, a domain-specific language (DSL) for large graph analysis in which we aim to eliminate the aforementioned complexities. Exedra consists of high level language constructs for specifying different graph analysis tasks on distributed environments. We implemented Exedra DSL on a scalable graph analysis platform called Dipper. Dipper uses Igraph/R interface for creating graph analysis workflows which in turn gets translated to Exedra statements. Exedra statements are interpreted by Dipper interpreter, and gets mapped to user specified libraries/ middleware. Exedra DSL allows for synthesize of graph algorithms that are more efficient compared to bare use of graph libraries while maintaining a standard interface that could use even future graph analysis software. We evaluated Exedra's feasibility for expressing graph analysis tasks by running Dipper on a cluster of four nodes. We observed that Dipper has the ability of reducing the time taken for graph analysis when the workflow was distributed on all four nodes despite the communication, and data format conversion overhead of the Dipper framework.";"Domain-specific language, Exascale, Large graph data analysis, Program synthesis, Programming techniques, Workflow"
"Elangovan V.K., Badia R.M., Parra E.A.";"OmpSs-OpenCL programming model for heterogeneous systems";"The advent of heterogeneous computing has forced programmers to use platform specific programming paradigms in order to achieve maximum performance. This approach has a steep learning curve for programmers and also has detrimental influence on productivity and code re-usability. To help with this situation, OpenCL an open-source, parallel computing API for cross platform computations was conceived. OpenCL provides a homogeneous view of the computational resources (CPU and GPU) thereby enabling software portability across different platforms. Although OpenCL resolves software portability issues, the programming paradigm presents low programmability and additionally falls short in performance. In this paper we focus on integrating OpenCL framework with the OmpSs task based programming model using Nanos run time infrastructure to address these shortcomings. This would enable the programmer to skip cumbersome OpenCL constructs including OpenCL plaform creation, compilation, kernel building, kernel argument setting and memory transfers, instead write a sequential program with annotated pragmas. Our proposal mainly focuses on how to exploit the best of the underlying hardware platform with greater ease in programming and to gain significant performance using the data parallelism offered by the OpenCL run time for GPUs and multicore architectures. We have evaluated the platform with important benchmarks and have noticed substantial ease in programming with comparable performance. © © Springer-Verlag Berlin Heidelberg 2013."
"Kalavri V., Vlassov V.";"MapReduce: Limitations, optimizations and open issues";"MapReduce has recently gained great popularity as a programming model for processing and analyzing massive data sets and is extensively used by academia and industry. Several implementations of the MapReduce model have emerged, the Apache Hadoop framework being the most widely adopted. Hadoop offers various utilities, such as a distributed file system, job scheduling and resource management capabilities and a Java API for writing applications. Hadoop's success has intrigued research interest and has led to various modifications and extensions to the framework. Implemented optimizations include performance improvements, programming model extensions, tuning automation and usability enhancements. In this paper, we discuss the current state of the Hadoop framework and its identified limitations. We present, compare and classify Hadoop/MapReduce variations, identify trends, open issues and possible future directions. © 2013 IEEE.";"Big Data, MapReduce, Survey"
"Hu R., Neykova R., Yoshida N., Demangeon R., Honda K.";"Practical interruptible conversations: Distributed dynamic verification with session types and Python";"The rigorous and comprehensive verification of communication-based software is an important engineering challenge in distributed systems. Drawn from our industrial collaborations [33,28] on Scribble, a choreography description language based on multiparty session types, this paper proposes a dynamic verification framework for structured interruptible conversation programming. We first present our extension of Scribble to support the specification of asynchronously interruptible conversations. We then implement a concise API for conversation programming with interrupts in Python that enables session types properties to be dynamically verified for distributed processes. Our framework ensures the global safety of a system in the presence of asynchronous interrupts through independent runtime monitoring of each endpoint, checking the conformance of the local execution trace to the specified protocol. The usability of our framework for describing and verifying choreographic communications has been tested by integration into the large scientific cyberinfrastructure developed by the Ocean Observatories Initiative. Asynchronous interrupts have proven expressive enough to represent and verify their main classes of communication patterns, including asynchronous streaming and various timeout-based protocols, without requiring additional synchronisation mechanisms. Benchmarks show conversation programming and monitoring can be realised with little overhead. © 2013 Springer-Verlag."
"De Roover C., Lammel R., Pek E.";"Multi-dimensional exploration of API usage";"This paper is concerned with understanding API usage in a systematic, explorative manner for the benefit of both API developers and API users. There exist complementary, less explorative methods, e.g., based on code search, code completion, or API documentation. In contrast, our approach is highly interactive and can be seen as an extension of what IDEs readily provide today. Exploration is based on multiple dimensions: i) the hierarchically organized scopes of projects and APIs, ii) metrics of API usage (e.g., number of project classes extending API classes), iii) metadata for APIs, iv) project- versus API-centric views. We also provide the QUAATLAS corpus of Java projects which enhances the existing QUALITAS corpus to enable API-usage analysis. We implemented the exploration approach in an open-source, IDE-like, Web-enabled tool EXAPUS. © 2013 IEEE.";"API usage, code exploration, EXAPUS, metadata, program comprehension, QUAATLAS, QUALITAS, reverse engineering"
"Song F., Touili T.";"Model-checking software library API usage rules";"Modern software increasingly relies on using libraries which are accessed via Application Programming Interfaces (APIs). Libraries usually impose constraints on how API functions can be used (API usage rules) and programmers have to obey these API usage rules. However, API usage rules often are not well-documented or documented informally. In this work, we show how to use the SCTPL logic to precisely specify API usage rules in libraries, where SCTPL can be seen as an extension of the branching-time temporal logic CTL with variables, quantifiers, and predicates over the stack. This allows library providers to formally describe API usage rules without knowing how their libraries will be used by programmers. We also propose an approach to automatically check whether programs using libraries violate or not the corresponding API usage rules. Our approach consists in modeling programs as pushdown systems (PDSs), and checking API usage rules on programs using SCTPL model checking for PDSs. To make the model-checking procedure more efficient, we propose an abstraction that reduces drastically the size of the program model. Moreover, we characterize a sub-logic rSCTPL of SCTPL preserved by the abstraction. rSCTPL is sufficient to precisely specify all the API usage rules we met. We implemented our techniques in a tool and applied it to check several API usage rules. Our tool detected several previously unknown errors in well-known programs, such as Nssl, Verbs, Acacia+, Walksat and Getafix. Our experimental results are encouraging. © 2013 Springer-Verlag Berlin Heidelberg."
"[No author name available]";"Integrated Formal Methods - 10th International Conference, IFM 2013, Proceedings";"The proceedings contain 29 papers. The topics discussed include: systems design guided by progress concerns, assume-guarantee specifications of state transition diagrams for behavioral refinement, automated anonymity verification of the ThreeBallot voting system, compositional verification of software product lines, deductive verification of state-space algorithms, inductive verification of hybrid automata with strongest postcondition calculus, priced timed automata and statistical model checking, improved reachability analysis in DTMC via divide and conquer, solving games using incremental induction, model-checking software library API usage rules, detecting vulnerabilities in Java-card bytecode verifiers using model-based testing, integrating formal predictions of interactive system behaviour with user evaluation, integrating proved state-based models for constructing correct distributed algorithms, and a compositional automata-based semantics for property patterns."
"Katayama S.-Y., Goda T., Shiramatsu S., Ozono T., Shintani T.";"A fast synchronization mechanism for collaborative web applications based on HTML5";"We are developing a collaborative web application for editing PDF documents using web browsers. Our system enables users to edit the same document in real-time. Users can share annotations on papers in real-time on web browsers. One of the advantages of our system is very high availability. Users only need to have their own web browsers. To improve the usability of our system, we need to consider synchronization delay. Synchronization delay consists of network delay and drawing delay. Our system draws PDF files by using JavaScript, it is not fast enough for real-time collaborative editing. We propose a new synchronization method using Canvas API to reduce drawing delay. We show how to implement a real-time collaborative editing system by using the method. We present evaluation results that indicate the method is suited for collaborative web applications. © 2013 IEEE.";"collaborative, consistency, revision, synchronization, web"
"Blom S., Kiniry J., Huisman M.";"How do developers use APIs? A case study in concurrency";"With the omnipresent usage of APIs in software development, it has become important to analyse how the routines and functionalities of APIs are actually used. This information is in particular useful for API developers, to make decisions about future updates of the API. However, also for developers of static analysis and verification tools this information is highly important, because it indicates where and how to put the most efficient effort in annotating APIs, to make them usable for the static analysis and verification tools. This paper presents an analysis of the usage of the routines and functionalities of the Java concurrency library java. util. concurrent. It discusses the Histogram tool that we developed for this purpose, i.e., to efficiently analyse a large collection of bytecode classes. The Histogram tool is used on a representative benchmark set, the Qualitas Corpus. The paper discusses the results of the analysis of this benchmark set in detail. This covers both an analysis of the important classes and methods used by the current releases of the benchmark collection, as well as an analysis of the time it took for the Java concurrency library to start being used in released software. © 2013 IEEE.";"API usage, java. util. concurrent, Qualitas Corpus, static analysis"
"Linares-Vásquez M., Bavota G., Bernal-Cárdenas C., Di Penta M., Oliveto R., Poshyvanyk D.";"API change and fault proneness: A threat to the success of android apps";"During the recent years, the market of mobile software applications (apps) has maintained an impressive upward trajectory. Many small and large software development companies invest considerable resources to target available opportunities. As of today, the markets for such devices feature over 850K+ apps for Android and 900K+ for iOS. Availability, cost, functionality, and usability are just some factors that determine the success or lack of success for a given app. Among the other factors, reliability is an important criteria: users easily get frustrated by repeated failures, crashes, and other bugs, hence, abandoning some apps in favor of others. This paper reports a study analyzing how the fault- and change-proneness of APIs used by 7, 097 (free) Android apps relates to applications' lack of success, estimated from user ratings. Results of this study provide important insights into a crucial issue: making heavy use of fault- and change-prone APIs can negatively impact the success of these apps. Copyright 2013 ACM.";"Android, API changes, Empirical studies, Mining software repositories"
"Herbold S., Harms P.";"AutoQUEST - Automated quality engineering of event-driven software";"In this paper, we present Auto QUEST, a testing platform for Event-Driven Software (EDS) that decouples the implementation of testing techniques from the concrete platform they should be applied to. Auto QUEST provides the means to define testing techniques against an abstract Application Programming Interface (API) and provides plug-ins to port the testing techniques to distinct platforms. The requirements on plug-in implementations for Auto QUEST are kept low to keep the porting effort low. We implemented several testing techniques on top of Auto QUEST and provide five plug-ins for concrete software platforms, which demonstrates the capabililities of our approach. © 2013 IEEE.";"event-driven software, GUI testing, test automation, usability analysis, usage-based testing"
"Klein F., Rubinsteiny D., Sonsz K., Einabadix F., Herhut S., Slusallek P.";"Declarative AR and image processing on the Web with Xflow";"Recently, modernWeb browser became capable of supporting powerful, interactive 3D graphics both via the low-level, imperative API of WebGL as well as via a high-level, declarative approach like XML3D. The obvious next step (particularly with respect to mobile platforms) is to combine video from the real world with matched virtual content - Augmented or Mixed Reality (AR/MR). However, AR requires extensive image or video processing, feature detection and tracking, and applying the results to 3D rendering - all of which is hard to implement in a Web context. In this paper we present a novel approach that encapsulates lowlevel image-processing and AR operations into re-usable high-level XML3D/Xflow components that are part of the HTML-5 DOM. A Web developer can then easily and flexibly arrange these components into (possibly complex) processing flow-graphs without having to worry about the internal computations and the structure of these modules. Our extended Xflow implementation automatically optimizes, schedules, and synchronizes the processing of the flow graph(s) in the context of real-time 3D rendering. Finally, we provide an integration model that greatly simplifies building AR applications for the browser. We demonstrate this with several simple AR and image processing applications using a polyfill implementation working in all modern browsers and evaluate the performance. Finally, we show how the declarative framework can be optimized with respect to performance and usability using parallelization with Web Workers and RiverTrail. Copyright © ACM 978-1-4503-2133-4/13/06 $15.00.";"Dataflow, Visualization, Web3D, WebGL, XML3D"
"Khatoon S., Mahmood A., Li G., Xu J.";"A novel integrated framework to increase software quality by mining source code";"Source code contain lot of structural features that embody latent information that if identified can help software engineers to develop quality software in least amount of time. For instance, many programming rules are hidden in set of function calls, variable usage, data accesses in functions, object interaction etc. that seldom exist outside the minds of developers. Violations of these rules may introduce bugs which are difficult to uncover, report to bug-tracking systems and fix unless the rules are explicitly documented and made available to the development team. In order to address this problem there is a need to apply strong analysis techniques on source code to find latent programming patterns that can be potentially useful for performing various software engineering tasks. This study demonstrates how data mining techniques can be applied on source code to improve software quality and productivity by proposing a framework. This new approach is able to find different programming patterns such as programming rules, variable correlation, code clones and frequent API usage patterns. Furthermore, efficient algorithms are proposed to automatically detect violation to the extracted rules. Proposed framework is validated by developing a prototype and evaluated on various projects of significant size and complexity. Results shows proposed technique greatly reduced time and cost of manually checking defects from source code by programmers. © 2013 Academic Journals Inc.";"API usage, Bug detection, Copy-paste code, Data mining, Programming patterns, Programming rule, Rule violation, Source code mining"
"Sangeetha R.";"Detection of malicious code in user mode";"A particular type of executable malware code is malicious code that harms the computer or networks without the user intervention. Static analysis is used to identify the location of system calls from service request and monitor the executables at runtime, but difficult to determine the obfuscated code because code uses dynamic code generation and obfuscation techniques. This technique hides the win32 API calls at runtime. Malicious code can interact with operating system through Win32 API usage. Malicious executables can hide their win32 API usage during Static analysis. Our proposed approach is used to distinguish the software executables and analyze the virtual address and API names of instructions from system calls are recorded to match with the interrupt address table. The recorded instructions are found in Address table, the services are forwarded to kernel mode. Filter is mainly focus on separating the address belongs to its local id and remote id for validating the dispatch id in system service dispatch table. Through filter using the process creation algorithm to finalize it service request from legitimate user. The overall processing is done by user mode before the injected code entering into the kernel mode. © 2013 IEEE.";"Malicious code, static analysis, system call"
"Scheller T., Kühn E.";"Usability evaluation of configuration-based API design concepts";"Usability is an important quality attribute for designing APIs, but usability-related decision factors are often unknown. This is also the case when looking at APIs for configuration tasks, like for dependency injection or object-relational mapping. In these areas three different API design concepts can be found, which are annotations, fluent interfaces, and XML. There exists no research concerning usability-related characteristics and differences between these concepts. In this paper, we present a usability study that identifies such characteristics and differences between the three concepts, by comparing three different variants of an API for dependency injection. From the study results we evaluate advantages and disadvantages in different use cases, and show how to build more usable configuration-based APIs. © 2013 Springer-Verlag.";"Annotations, API Design, API Usability, Fluent Interfaces, XML"
"Khatoon S., Li G., Mahmood A.";"Comparison and evaluation of source code mining tools and techniques: A qualitative approach";"Program source code substantially is structured and contains semantically rich programming constructs such as variables, functions, data structures, and program structures which indicate patterns. Mining source code by using different data mining techniques to extract the valuable hidden patterns is the new revolution in software engineering. Over last decade many tools and techniques have been proposed by researcher to extract pertinent information and uncover relationships and trends from source code about a particular characteristic of Software Engineering (SE) tasks. These efforts have resulted in wide range of research body but currently there is no comprehensive overview exists. This paper surveys the tools and techniques which rely only on data mining methods to determine patterns from source code in context of programming, bug detection, maintenance, program understanding and software reuse. The work provides comparison and evaluation of the current state-of-the-art source code mining tools and techniques, and organizes the large amount of information into a coherent conceptual way. Thus the survey provides researchers with a concise overview of source code mining techniques and assists practitioners the selection of appropriate techniques for their work. The result of this review shows existing studies focus on one specific pattern being mined from source code such as special kind of bug detection. Thus, there is a need of multiple tools to test and find potential information from software which increase cost and time of development. Hence there is a strong need of tool which helps in developing quality software by automatically detecting different kind of bugs and generates relevant API code automatically to help in decreasing overall software development time. © 2013-IOS Press and the authors. All rights reserved.";"API usage, bug detection, copy-paste code, data mining, patterns, programming rule, Source code mining"
"Senseney J., Bokinsky A., Cheng R., McCreedy E., McAuliffe M.J.";"Java multi-histogram volume rendering framework for medical images";"This work extends the multi-histogram volume rendering framework proposed by Kniss et al. [1] to provide rendering results based on the impression of overlaid triangles on a graph of image intensity versus gradient magnitude. The developed method of volume rendering allows for greater emphasis to boundary visualization while avoiding issues common in medical image acquisition. For example, partial voluming effects in computed tomography and intensity inhomogeneity of similar tissue types in magnetic resonance imaging introduce pixel values that will not reflect differing tissue types when a standard transfer function is applied to an intensity histogram. This new framework uses developing technology to improve upon the Kniss multi-histogram framework by using Java, the GPU, and MIPAV, an open-source medical image processing application, to allow multi-histogram techniques to be widely disseminated. The OpenGL view aligned texture rendering approach suffered from performance setbacks, inaccessibility, and usability problems. Rendering results can now be interactively compared with other rendering frameworks, surfaces can now be extracted for use in other programs, and file formats that are widely used in the field of biomedical imaging can be visualized using this multi-histogram approach. OpenCL and GLSL are used to produce this new multi-histogram approach, leveraging texture memory on the graphics processing unit of desktops to provide a new interactive method for visualizing biomedical images. Performance results for this method are generated and qualitative rendering results are compared. The resulting framework provides the opportunity for further applications in medical imaging, both in volume rendering and in generic image processing. © 2013 SPIE.";"GPU, Multi-histogram, Rendering"
"Hofmeyr S., Colmenares J.A., Iancu C., Kubiatowicz J.";"Juggle: Addressing extrinsic load imbalances in SPMD applications on multicore computers";"We investigate proactive dynamic load balancing on multicore systems, in which threads are continually migrated to reduce the impact of processor/thread mismatches. Our goal is to enhance the flexibility of the SPMD-style programming model and enable SPMD applications to run efficiently in multiprogrammed environments. We present Juggle, a practical decentralized, user-space implementation of a proactive load balancer that emphasizes portability and usability. In this paper we assume perfect intrinsic load balance and focus on extrinsic imbalances caused by OS noise, multiprogramming and mismatches of threads to hardware parallelism. Juggle shows performance improvements of up to 80 % over static load balancing for oversubscribed UPC, OpenMP, and pthreads benchmarks. We also show that Juggle is effective in unpredictable, multiprogrammed environments, with up to a 50 % performance improvement over the Linux load balancer and a 25 % reduction in performance variation. We analyze the impact of Juggle on parallel applications and derive lower bounds and approximations for thread completion times. We show that results from Juggle closely match theoretical predictions across a variety of architectures, including NUMA and hyper-threaded systems. © 2012 Springer Science + Business Media, LLC (outside the USA).";"Multicore, Operating system, Parallel programming, Proactive load balancing, Single-program multiple-data parallelism"
"Aigner W., Hoffmann S., Rind A.";"EvalBench: A software library for visualization evaluation";"It is generally acknowledged in visualization research that it is necessary to evaluate visualization artifacts in order to provide empirical evidence on their effectiveness and efficiency as well as their usability and utility. However, the difficulties of conducting such evaluations still remain an issue. Apart from the required know-how to appropriately design and conduct user studies, the necessary implementation effort for evaluation features in visualization software is a considerable obstacle. To mitigate this, we present EvalBench, an easy-to-use, flexible, and reusable software library for visualization evaluation written in Java. We describe its design choices and basic abstractions of our conceptual architecture and demonstrate its applicability by a number of case studies. EvalBench reduces implementation effort for evaluation features and makes conducting user studies easier. It can be used and integrated with third-party visualization prototypes that need to be evaluated via loose coupling. EvalBench supports both, quantitative and qualitative evaluation methods such as controlled experiments, interaction logging, laboratory questionnaires, heuristic evaluations, and insight diaries. © 2013 The Author(s) Computer Graphics Forum © 2013 The Eurographics Association and Blackwell Publishing Ltd."
"Businge J., Serebrenik A., Van Den Brand M.";"Analyzing the eclipse API usage: Putting the developer in the loop";"Eclipse guidelines distinguish between two types of interfaces provided to third-party developers, i.e., APIs and non-APIs. APIs are stable and supported, while non-APIs are unstable, unsupported and discouraged as they are subject to arbitrary change or removal without notice. In our previous work, we found that despite the discouragement of Eclipse, the use of non-APIs in Eclipse third-party plug-ins (ETPs) is not uncommon. Furthermore, we found that these non-APIs are the main cause of ETP incompatibilities in forthcoming releases of the Eclipse. In the current work we conducted a survey aiming at understanding why do the ETP developers use non-APIs. We have observed that developers with a level of education of up to master degree have a tendency not to read product manuals/guidelines. Furthermore, while for less experienced developers instability of the non-APIs overshadows their benefits, more experienced developers prefer to enjoy the benefits of non-APIs despite the instability problem. Finally, we have observed that there are no significant differences between Open Source and commercial Eclipse products in terms of awareness of Eclipse guidelines and interfaces, Eclipse product size and updating of Eclipse product in the new SDK releases. © 2013 IEEE.";"APIs, Developers, Eclipse, non-APIs, Survey"
"Robillard M.P., Bodden E., Kawrykow D., Mezini M., Ratchford T.";"Automated API property inference techniques";"Frameworks and libraries offer reusable and customizable functionality through Application Programming Interfaces (APIs). Correctly using large and sophisticated APIs can represent a challenge due to hidden assumptions and requirements. Numerous approaches have been developed to infer properties of APIs, intended to guide their use by developers. With each approach come new definitions of API properties, new techniques for inferring these properties, and new ways to assess their correctness and usefulness. This paper provides a comprehensive survey of over a decade of research on automated property inference for APIs. Our survey provides a synthesis of this complex technical field along different dimensions of analysis: properties inferred, mining techniques, and empirical results. In particular, we derive a classification and organization of over 60 techniques into five different categories based on the type of API property inferred: unordered usage patterns, sequential usage patterns, behavioral specifications, migration mappings, and general information. © 1976-2012 IEEE.";"API evolution, API property, API usage pattern, data mining, interface, pattern mining, programming rules, protocols, specifications"
"Othman A.T., Khan S., Nauman M., Musa S.";"Towards a high-level trusted computing API for android software stack";"Smartphone platforms are fast becoming the de-facto method of online communication. Android is one of the most promising smartphone platforms with backing of both the finances of industry leaders and the technical skills and expertise of the open source community. These two factors combined with the usability of application design on the Android platform has propelled the platform in the fore-front of technological innovations. However, along with this wide acceptance by the community come large risks associated with privacy, security and trust. Users share very sensitive data of a very personal nature on their smartphones. Protection of this data is of immense importance if the adoption of smartphones is to be continued. Similar threats on the pc have been countered using the concepts of Trusted Computing - a highly flexible trust mechanism with strong security properties. The Android platform has yet to see any Trusted Computing applications primarily because of the difficulty in adopting the relatively new paradigm of security. In this paper, we present the design of a high-level api that allows existing Android developers to adopt Trusted Computing and use it in their applications without having to learn the intricate details of how Trusted Computing works. The api will help the developers to increase the security of their applications and the data that they consume. Copyright © 2013 ACM.";"Android, Mobile platforms, Security, Trusted computing"
"Parashar H.J., Sachdeva S., Batra S.";"Enhancing access to standardized clinical application for mobile interfaces";"As Electronic Health Records (EHRs) become more prevalent in health care, research is needed to understand the efficacy within clinical contexts for a standard based health application. The current research explores 'Opereffa' to be used for handheld moveable devices. Opereffa stands for openEHR REFerence Framework and Application. It is a project for creating an open source clinical application, which will be driven by the Clinical Review Board of openEHR [2]. It is based on openEHR standard which combines structure of archetypes and terminology codes. This is the first effort for its exploration on mobile devices. The aim is to generate an application programming interface for Android based mobile for its testing on a sample set of archetypes. Later, we will extend this research to other mobile operating systems. The study has been done for increasing the usability and reach ability of EHRs. It enhances data sharing through mobile for standardized EHRs (through use of archetypes). © 2013 Springer-Verlag Berlin Heidelberg.";"Clinical Application, Electronic health records, Healthcare, Mobile application, Mobile interface, User Interaction"
"Scheller T., Kühn E.";"Influence of code completion methods on the usability of APIs";"Code completion is an important feature in modern IDEs, helping programmers to find needed classes and methods in external APIs. A code completion mechanism defines the way APIs are presented to the programmer and thereby has a strong influence on their usability. In this paper, we present a study that evaluates the code completion mechanisms of popular Java and .Net IDEs. It shows that there are significant differences between them, and that with a good code completion mechanism, programmers more often find the most optimal methods and overloads, reducing the complexity of the resulting code and improving overall performance. Based on the results we present suggestions to improve the usability of APIs.";"Application programming interfaces, Code completion, Human computer interaction, Programming tools and languages"
"Fischer J.E., Ramchurn S.D., Osborne M.A., Parson O., Huynh T.D., Alam M., Pantidi N., Moran S., Bachour K., Reece S., Costanza E., Rodden T., Jennings N.R.";"Recommending energy tariffs and load shifting based on smart household usage profiling";"We present a system and study of personalized energy-related recommendation. AgentSwitch utilizes electricity usage data collected from users' households over a period of time to realize a range of smart energy-related recommendations on energy tariffs, load detection and usage shifting. The web service is driven by a third party real-time energy tariff API (uSwitch), an energy data store, a set of algorithms for usage prediction, and appliance-level load disaggregation. We present the system design and user evaluation consisting of interviews and interface walkthroughs. We recruited participants from a previous study during which three months of their household's energy use was recorded to evaluate personalized recommendations in AgentSwitch. Our contributions are a) a systems architecture for personalized energy services, and b) findings from the evaluation that reveal challenges in designing energy-related recommender systems. In response to the challenges we formulate design recommendations to mitigate barriers to switching tariffs, to incentivize load shifting, and to automate energy management. Copyright © 2013 ACM.";"Demand response, Energy tariffs, Load shifting, Personalization, Recommender systems, Smart grid"
"Earls J.C., Eddy J.A., Funk C.C., Ko Y., Magis A.T., Price N.D.";"AUREA: An open-source software system for accurate and user-friendly identification of relative expression molecular signatures";"Background: Public databases such as the NCBI Gene Expression Omnibus contain extensive and exponentially increasing amounts of high-throughput data that can be applied to molecular phenotype characterization. Collectively, these data can be analyzed for such purposes as disease diagnosis or phenotype classification. One family of algorithms that has proven useful for disease classification is based on relative expression analysis and includes the Top-Scoring Pair (TSP), k-Top-Scoring Pairs (k-TSP), Top-Scoring Triplet (TST) and Differential Rank Conservation (DIRAC) algorithms. These relative expression analysis algorithms hold significant advantages for identifying interpretable molecular signatures for disease classification, and have been implemented previously on a variety of computational platforms with varying degrees of usability. To increase the user-base and maximize the utility of these methods, we developed the program AUREA (Adaptive Unified Relative Expression Analyzer)-a cross-platform tool that has a consistent application programming interface (API), an easy-to-use graphical user interface (GUI), fast running times and automated parameter discovery.Results: Herein, we describe AUREA, an efficient, cohesive, and user-friendly open-source software system that comprises a suite of methods for relative expression analysis. AUREA incorporates existing methods, while extending their capabilities and bringing uniformity to their interfaces. We demonstrate that combining these algorithms and adaptively tuning parameters on the training sets makes these algorithms more consistent in their performance and demonstrate the effectiveness of our adaptive parameter tuner by comparing accuracy across diverse datasets.Conclusions: We have integrated several relative expression analysis algorithms and provided a unified interface for their implementation while making data acquisition, parameter fixing, data merging, and results analysis 'point-and-click' simple. The unified interface and the adaptive parameter tuning of AUREA provide an effective framework in which to investigate the massive amounts of publically available data by both 'in silico' and 'bench' scientists. AUREA can be found at http://price.systemsbiology.net/AUREA/. © 2013 Earls et al, licensee BioMed Central Ltd."
"Ameddah H., Assas M.";"Three-dimensional (3D) bio-cad modeling of human knee";"In the past three decades, the fast growing technology of Computer-Aided Design and Computer-Aided Manufac- turing (CAD/CAM) has been continuously developed and applied to many fields in engineering, manufacturing, entertainment, and medicine. While maturing in some of the fields, CAD/CAM is still in developing stages in the medical and prototyping arena. Medical images (X-ray, CT, MR) of human organs are widely used in the everyday clinical praxis. A deeper insight of the anatomical properties can be obtained by building a three dimensional computer model from the images. In order to properly evaluate the 2D images and also the 3D objects engineers need efficient and robust graphical and geometrical tools. The purpose of this paper was to establish a procedure for attaining 3D solid models of the human knee. Solid models of the distal end of the femur and the tibial plateau were created to approximate the human knee (tibio-femoral joint). To create these models, points taken from magnetic resonance images (MRI) were first processing by methods for edge detect- ing using Matlab toolbox image processing and then converted to a point cloud in each cross section. From here, B-spline was created points in each cross section. Finally, these B-spline were lofted together to form a 3D solid model. The results of this paper are the first to develop image processing 3D visualization in Solidworks Application Programming Interface (API) using Visual Basic Language. The system performance is tested using MRI data, and 3D physical models Knee for MRP are created directly from Solidworks. © 2013 American Scientific Publishers All rights reserved.";"CAD modeling, Edge detection, Knee, MRI"
"Mendez D., Baudry B., Monperrus M.";"Empirical evidence of large-scale diversity in API usage of object-oriented software";"In this paper, we study how object-oriented classes are used across thousands of software packages. We concentrate on ""usage diversity"", defined as the different statically observable combinations of methods called on the same object. We present empirical evidence that there is a significant usage diversity for many classes. For instance, we observe in our dataset that Java's String is used in 2460 manners. We discuss the reasons of this observed diversity and the consequences on software engineering knowledge and research. © 2013 IEEE."
"[No author name available]";"IEEE 13th International Working Conference on Source Code Analysis and Manipulation, SCAM 2013";"The proceedings contain 24 papers. The topics discussed include: empirical investigation of SEA-based dependence cluster properties, characterization and assessment of the Linux configuration complexity, criticality of defects in cyclic dependent components, code clustering workbench, empirical evidence of large-scale diversity in API usage of object-oriented software, aspectual source code analysis with GASR, driving a sound static software analyzer with branch-and-bound, PtrTracker: pragmatic pointer analysis, tracing with minimal number of probes, a state alteration and inspection-based interactive debugger, Proteum/FL: a mutation-based fault localization Tool, Gecos: an extensible source-to-source compiler for embedded hardware, review efforts reduction by partitioning of static analysis warnings, determining coupling in JavaScript using object type inference, MetricMiner: supporting researchers in mining software repositories, and fix-it: an extensible code auto-fix component in review Bot."
"Lord P.";"The Semantic Web takes wing: Programming ontologies with Tawny-OWL";"The Tawny-OWL library provides a fully-programmatic environment for ontology building, it enables the use of a rich set of tools for ontology development by recasting development as a form of programming. It is built in Clojure - a modern Lisp dialect, and is backed by the OWL API. Used simply, it has a similar syntax to OWL Manchester syntax, but it provides arbitrary extensibility and abstraction. It builds on existing facilities for Clojure, which provides a rich and modern programming tool chain, for versioning, distributed development, build, testing and continuous integration. In this paper, we describe the library, this environment and the its potential implications for the ontology development process."
"Rabkin A., Reiss C., Katz R., Patterson D.";"Using clouds for MapReduce measurement assignments";"We describe our experiences teaching MapReduce in a large undergraduate lecture course using public cloud services and the standard Hadoop API. Using the standard API, students directly experienced the quality of industrial big-data tools. Using the cloud, every student could carry out scalability benchmarking assignments on realistic hardware, which would have been impossible otherwise. Over two semesters, over 500 students took our course. We believe this is the first large-scale demonstration that it is feasible to use pay-as-you-go billing in the cloud for a large undergraduate course. Modest instructor effort was sufficient to prevent students from overspending. Average per-pupil expenses in the Cloud were under $45. Students were excited by the assignment: 90% said they thought it should be retained in future course offerings. © 2013 ACM.";"Cloud computing, Education, MapReduce"
"Khan M.A., Muhammad S., Muhammad T.";"Runtime invocation analysis of API objects in large code base";"Software systems use several third party libraries via their available interfaces popularly known as the application programming interface (API). The runtime usage of the API in an object-oriented software system can be defined by several characteristics including the type and number of API objects created, the methods invoked on those objects, and the source code locations from where the objects were created or invoked during their lifetime. These characteristics can be used to identify the source code locations exhibiting different types of runtime behavior which can be used for program comprehension, debugging, performance monitoring and fault detection. In this paper, we define object invocation model based on above-mentioned characteristics. We also propose an implementation framework that can be used to extract key model parameters from any source code. The Java Collections API is one of the most widely used Java APIs. We demonstrate effectiveness of our proposed approach by analyzing object invocation model for Java Collection API in a large open source project. © 2013 IEEE.";"api invocation analysis, api usage analysis, bytecode instrumentation, Java Collection API analysis, object invocation model, program comprehension, runtime program analysis"
"Lawall J.L., Brunel J., Palix N., Hansen R.R., Stuart H., Muller G.";"WYSIWIB: Exploiting fine-grained program structure in a scriptable API-usage protocol-finding process";"Bug-finding tools rely on specifications of what is correct or incorrect code. As it is difficult for a tool developer or user to anticipate all possible specifications, strategies for inferring specifications have been proposed. These strategies obtain probable specifications by observing common characteristics of code or execution traces, typically focusing on sequences of function calls. To counter the observed high rate of false positives, heuristics have been proposed for ranking or pruning the results. These heuristics, however, can result in false negatives, especially for rarely used functions. In this paper, we propose an alternate approach to specification inference, in which the user guides the inference process using patterns of code that reflect the user's understanding of the conventions and design of the targeted software project. We focus on specifications describing the correct usage of API functions, which we refer to as API protocols. Our approach builds on the Coccinelle program matching and transformation tool, which allows a user to construct patterns that reflect the structure of the code to be matched. We evaluate our approach on the source code of the Linux kernel, which defines a very large number of API functions with varying properties. Linux is also critical software, implying that fixing even bugs involving rarely used protocols is essential. In our experiments, we use our approach to find over 3000 potential API protocols, with an estimated false positive rate of under 15% and use these protocols to find over 360 bugs in the use of API functions. © 2012 John Wiley & Sons, Ltd.";"bug finding, Linux, program analysis"
"Hoxha J., Maleshkova M., Korevaar P.";"Knowledge discovery meets linked APIs";"Knowledge Discovery and Data Mining (KDD) is a very wellestablished research field with useful techniques that explore patterns and regularities in large relational, structured and unstructured datasets. Theoretical and practical development in this field have led to useful and scalable solutions for the tasks of pattern mining, clustering, graph mining, and predictions. In this paper, we demonstrate that these approaches represent great potential to solve a series of problems and make further optimizations in the setting of Web APIs, which have been significantly increasing recently. In particular, approaches integrating Web APIs and Linked Data, also referred to as Linked APIs, provide novel opportunities for the application of synergy approaches with KDD methods. We give insights on several aspects that can be covered through such synergy approach, then focus, specifically, on the problem of API usage mining via statistical relational learning.We propose a Hidden Relational Model, which explores the usage of Web APIs to enable analysis and prediction. The benefit of such model lies on its ability to capture the relational structure of API requests. This approach might help not only to gain insights about the usage of the APIs, but most importantly to make active predictions on which APIs to link together for creating useful mashups, or facilitating API composition. Copyright © 2013 for the individual papers by the papers' authors."
"Agarwal D., Prasad S.K.";"Azure BOT: A framework for bag-of-tasks applications on the azure cloud platform";"Windows Azure is an emerging cloud platform that provides application developers with APIs to write scientific and commercial applications. However, the steep learning curve to understand the unique architecture of the cloud platforms in general and continuously changing Azure APIs specifically, make it difficult for the application developers to write cloud based applications. During our extensive experience with Azure cloud platform over the past few years, we have identified the need of a framework to abstract the complexities of working with the Azure cloud platform. Such a framework is essential for adoption of cloud technologies. Therefore, we have created AzureBOT-A framework for the Azure cloud platform to write bag-of-tasks class of distributed applications. Azure provides a straightforward and general interface that permits developers to concentrate on their application logic rather than cloud interaction. While we have implemented AzureBOT on Azure cloud platform, our framework design is generic to most of the cloud platforms. In this paper, we present the detailed design of our framework's internal architecture, the APIs in brief, and the usability of our framework. We also discuss the implementation of two different applications and their scalability results over 100Azure worker processors. © 2013 IEEE.";"Azure Cloud, Bag-of-tasks, cloud computing, Cloud framework"
"Ghosh S., Liao T., Calandra H., Chapman B.M.";"Performance of CPU/GPU compiler directives on ISO/TTI kernels";"GPUs are slowly becoming ubiquitous devices in High Performance Computing, as their capabilities to enhance the performance per watt of compute intensive algorithms as compared to multicore CPUs have been identified. The primary shortcoming of a GPU is usability, since vendor specific APIs are quite different from existing programming languages, and it requires a substantial knowledge of the device and programming interface to optimize applications. Hence, lately a growing number of higher level programming models are targeting GPUs to alleviate this problem. The ultimate goal for a high-level model is to expose an easy-to-use interface for the user to offload compute intensive portions of code (kernels) to the GPU, and tune the code according to the target accelerator to maximize overall performance with a reduced development effort. In this paper, we share our experiences of three of the notable high-level directive based GPU programming models—PGI, CAPS and OpenACC (from CAPS and PGI) on an Nvidia M2090 GPU. We analyze their performance and programmability against Isotropic (ISO)/Tilted Transversely Isotropic (TTI) finite difference kernels, which are primary components in the Reverse Time Migration (RTM) application used by oil and gas exploration for seismic imaging of the sub-surface. When ported to a single GPU using the mentioned directives, we observe an average 1.5–1.8x improvement in performance for both ISO and TTI kernels, when compared with optimized multi-threaded CPU implementations using OpenMP. © 2013, Springer-Verlag Wien.";"Accelerator directives, Finite difference discretization, GPU, ISO, OpenACC, OpenMP, Performance, RTM, TTI"
"Störrle H.";"Improving the usability of OCL as an ad-hoc model querying language";"The OCL is often perceived as di-cult to learn and use. In previous research, we have defined experimental query languages exhibiting higher levels of usability than OCL. However, none of these alternatives can rival OCL in terms of adoption and support. In an attempt to leverage the lessons learned from our research and make it accessible to the OCL community, we propose the OCL Query API (OQAPI), a library of query-predicates to improve the user-friendliness of OCL for ad-hoc querying. The usability of OQAPI is studied using controlled experiments. We find considerable evidence to support our claim that OQAPI facilitates user querying using OCL."
"Cao Y., Hua Y., Zhao J., Guo S.";"Design and implementation of surrounding transaction plotting and management system based on Google map API";"With China's rapid economic development and comprehensive national strength growing, Border work has become a long-term and important task in China's diplomatic work. How to implement rapid plotting, real-time sharing and mapping surrounding affairs has taken great significance for government policy makers and diplomatic staff. However, at present the already exists Boundary information system are mainly have problems of Geospatial data update is heavily workload, plotting tools are in a state of serious lack of, Geographic events are difficult to share, this phenomenon has seriously hampered the smooth development of the border task. The development and progress of Geographic information system technology especially the development of Web GIS offers the possibility to solve the above problems, this paper adopts four layers of B/S architecture, with the support of Google maps service, uses the free API which is offered by Google maps and its features of openness, ease of use, sharing characteristics, highresolution images to design and implement the surrounding transaction plotting and management system based on the web development technology of ASP.NET, C#, Ajax. The system can provide decision support for government policy makers as well as diplomatic staff's real-time plotting and sharing of surrounding information. The practice has proved that the system has good usability and strong real-time.";"Architecture, Borderlands, Database, Decision Support, GIS, Internet/Web, Mapping, Real-time"
"Szydzik T., Nunez A., De Paepe L., Albani L.";"Contributions to visualization algorithm enabling GPU-accelerated image displaying for dual panel high dynamic range LCD display";"High dynamic range displays based on dual panel LCD are a viable option for building a low-cost solution for providing high bit depth visualization systems. One of the factors limiting the usability of this type of displays are the computation requirements of the algorithm necessary for correct visualization using the two stacked panels. In this work we present the methodology and the results of mapping this algorithm on a CPU+GPU platform using the OpenCL 1.1 API. Visualization of a 2048×2048 image when executed on a CPU+GPU (AMD Radeon V7800) platform is performed up to 7.6 times faster then when only the CPU is used. The first results are promising and encourage the use of GPUs (or APUs) for acceleration of this kind of processing. © 2013 University of Trieste and University of Zagreb.";"Dual-panel displays, GPU, Medicine, OpenCL, Optimization methods, Parallel computing, Visualization"
"Burns C., Ferreira J., Hellmann T.D., Maurer F.";"Usable results from the field of API usability: A systematic mapping and further analysis";"Modern software development often involves the use of complex, reusable components called Application Programming Interfaces (APIs). Developers use APIs to complete tasks they could not otherwise accomplish in a reasonable time. These components are now vital to mainstream software development. But as APIs have become more important, understanding how to make them more usable is becoming a significant research question. To assess the current state of research in the field, we conducted a systematic mapping. A total of 28 papers were reviewed and categorized based on their research type and on the evaluation method employed by its authors. We extended the analysis of a subset of the papers we reviewed beyond the usual limits of a systematic map in order to more closely examine details of their evaluations - such as their structure and validity - and to summarize their recommendations. Based on these results, common problems in the field are discussed and future research directions are suggested. © 2012 IEEE.";"API usability, application programming interface, meta-analysis, systematic map, systematic review"
"Munir M.B., Mushtaq A.";"A framework for extending usability engineering: API usability essentials: Extending usability via component-based platform";"Application Programming Interface (API) in software development acts as an important milestone for software productions. It is believed that API usability impacts upon ease-in-use, operationability and acceptability among its audience. Likewise, an ever increasing need for extending and integrating Usability Engineering (UE) has become vital for the success of software products. Earlier researches within this domain do not address API's usability via a component-based framework approach. The proposed framework emphasizes on consolidated formulation of various usability and quality models to derive chunks of dimensional variables. Further the paper highlights API usability practices and heuristics applied in API development process and discusses API product's artifacts component to be used in deriving further product-related components to support enhancing usability. © 2012 IEEE.";"API Usability, Component-Aided Usability, Extending Usability, Model Consolidation, Usability Engineering (UE) and Software Engineering (SE) Integration"
"Thung F., Lo D., Jiang L.";"Detecting similar applications with collaborative tagging";"Detecting similar applications are useful for various purposes ranging from program comprehension, rapid prototyping, plagiarism detection, and many more. McMillan et al. have proposed a solution to detect similar applications based on common Java API usage patterns. Recently, collaborative tagging has impacted software development practices. Various sites allow users to give various tags to software systems. In this study, we would like to complement the study by McMillan et al. by leveraging another source of information aside from API usage patterns, namely software tags. We have performed a user study involving several participants and the results show that collaborative tagging is a promising source of information useful for detecting similar software applications. © 2012 IEEE."
"Dai S., Wei T., Zou W.";"DroidLogger: Reveal suspicious behavior of Android applications via instrumentation";"As the mobile devices increased rapidly in recent years, mobile malware is becoming a severe threat to users. Traditional malware detection uses signature-based methods, but these methods can be evaded by obfuscation or polymorphism. So the behavior-based detection techniques were proposed recently. To capture the apps' behavior, previous works either use OS level tool such as strace to capture system call, or intercept high level API by modifying the virtual machine. However, the information retrieved from the former method is too difficult to understand the program's behavior, and the technique used in latter method requires to modify the emulator, which it is not compatible when the Android version upgrade. In this paper, we proposed a new light-weight method to understand the applications' behavior by logging program's API and corresponding arguments. We build the logging system DroidLogger, which instruments the logging code into the application binary, and prints out the API usage information at run time. We analyzed several malware and show DroidLogger can reveal the malicious behavior effectively. © 2012 AICIT.";"Android, Behavior, Instrumentation, Malware Detection, Suspicious API"
"Raemaekers S., Van Deursen A., Visser J.";"Measuring software library stability through historical version analysis";"Backward compatibility is a major concern for any library developer. In this paper, we evaluate how stable a set of frequently used third-party libraries is in terms of method removals, implementation change, the ratio of change in old methods to change in new ones and the percentage of new methods in each snapshot. We provide a motivating example of a commercial company which demonstrates several issues associated with the usage of third-party libraries. To obtain dependencies from software systems we developed a framework which extracts dependencies from Maven build files and which analyzes system and library code. We propose four metrics which provide different insights in the implementation and interface stability of a library. The usage frequency of library methods is utilized as a weight in the final metric and is obtained from a dataset of more than 2300 snapshots of 140 industrial Java systems. We finally describe three scenarios and an example of the application of our metrics. © 2012 IEEE.";"API Stability, API Usage, Software Reuse, Third-party Libraries"
"Tapia B., Torres R., Astudillo H., Ortega P.";"Recommending APIs for mashup completion using association rules mined from real usage data";"Mashups are becoming the de facto approach to build customer-oriented Web applications, by combining several Web APIs into a single lightweight, rich, customized Web front-end. To help mashup builders to choose among a plethora of available APIs to assemble in their mashups, some existing recommendation techniques rank candidate APIs using popularity (a social measure) or keyword-based measures (whether semantic or unverified tags). This article proposes to use information on co-usage of APIs in previous mash ups to suggest likely candidate APIs, and introduces a global measure which improves on earlier local co-API measures. The gCAR (global Co-utilization API Ranking) is calculated using association rules inferred from historical API usage data. The MashupRECO tool combines gCAR and a keywordbased measure, to avoid the 'cold-start' problem for new or unused APIs. Evaluation of MashupRECO versus the keyword search of the well-known ProgrammableWeb catalog show that the tool reduces the search time for comparable degree of completeness. © 2011 IEEE.";"Web mashup, Web API, recommender system, association rules, frequent itemsets"
"Groce A., Fern A., Pinto J., Bauer T., Alipour A., Erwig M., Lopez C.";"Lightweight automated testing with adaptation-based programming";"This paper considers the problem of testing a container class or other modestly-complex API-based software system. Past experimental evaluations have shown that for many such modules, random testing and shape abstraction based model checking are effective. These approaches have proven attractive due to a combination of minimal requirements for tool/language support, extremely high usability, and low overhead. These ""lightweight"" methods are therefore available for almost any programming language or environment, in contrast to model checkers and concolic testers. Unfortunately, for the cases where random testing and shape abstraction perform poorly, there have been few alternatives available with such wide applicability. This paper presents a generalizable approach based on reinforcement learning (RL), using adaptation-based programming (ABP) as an interface to make RL-based testing (almost) as easy to apply and adaptable to new languages and environments as random testing. We show how learned tests differ from random ones, and propose a model for why RL works in this unusual (by RL standards) setting, in the context of a detailed large-scale experimental evaluation of lightweight automated testing methods. © 2012 IEEE.";"Reinforcement learning, Software testing"
"Andersch M., Chi C.C., Juurlink B.";"Using OpenMP superscalar for parallelization of embedded and consumer applications";"In the past years, research and industry have introduced several parallel programming models to simplify the development of parallel applications. A popular class among these models are task-based programming models which proclaim ease-of-use, portability, and high performance. A novel model in this class, OpenMP Superscalar, combines advanced features such as automated runtime dependency resolution, while maintaining simple pragma-based programming for C/C++. OpenMP Superscalar has proven to be effective in leveraging parallelism in HPC workloads. Embedded and consumer applications, however, are currently still mainly parallelized using traditional thread-based programming models. In this work, we investigate how effective OpenMP Superscalar is for embedded and consumer applications in terms of usability and performance. To determine the usability of OmpSs, we show in detail how to implement complex parallelization strategies such as ones used in parallel H.264 decoding. To evaluate the performance we created a collection of ten embedded and consumer benchmarks parallelized in both OmpSs and Pthreads. © 2012 IEEE."
"Keller R., Brinkmann S., Gracia J., Niethammer C.";"Temanejo: Debugging of thread-based task-parallel programs in StarSS";"To make use of manycore processors and even accelerators, several parallel programming paradigms exist, such as OpenMP, CAPS HMPP and the StarSs programming model. All of these programming models provide the means for programmers to express parallelism in the source code, identifying tasks and for all but OpenMP the dependency between those, allowing the compiler and the runtime to schedule tasks onto multiple concurrent executing entities, like threads in a many-core systems.While the programmermay have a good overview of which parts of the code may be run independently as separate tasks on a fine granular level, the overall execution behavior may not be obvious at first. This paper describes the usability features of the newly developed Temanejo debugger. © Springer-Verlag Berlin Heidelberg 2012."
"Jacob F., Gray J., Carver J.C., Mernik M., Bangalore P.";"PPModel: A modeling tool for source code maintenance and optimization of parallel programs";"As the computation power in desktops advances, parallel programming has emerged as one of the essential skills needed by next generation software engineers. However, programs written in popular parallel programming paradigms have a substantial amount of sequential code mixed with the parallel code. Several such versions supporting different platforms are necessary to find the optimum version of the program for the available resources and problem size. As revealed by our study on benchmark programs, sequential code is often duplicated in these versions. This can affect code comprehensibility and re-usability of the software. In this paper, we discuss a framework named PPModel, which is designed and implemented to free programmers from these scenarios. Using PPModel, a programmer can separate parallel blocks in a program, map these blocks to various platforms, and re-execute the entire program.We provide a graphical modeling tool (PPModel) intended for Eclipse users and a Domain-Specific Language (tPPModel) for non-Eclipse users to facilitate the separation, the mapping, and the re-execution. This is illustrated with a case study from a benchmark program, which involves re-targeting a parallel block to CUDA and another parallel block to OpenMP. The modified program gave almost 5× performance gain compared to the sequential counterpart, and 1.5× gain compared to the existing OpenMP version. © Springer Science+Business Media, LLC 2012.";"CUDA, DSL, OpenMP, PPModel, TPPModel"
"Ghosh S., Liao T., Calandra H., Chapman B.M.";"Experiences with OpenMP, PGI, HMPP and OpenACC directives on ISO/TTI kernels";"GPUs are slowly becoming ubiquitous devices in High Performance Computing, as their capabilities to enhance the performance per watt of compute intensive algorithms as compared to multicore CPUs have been identified. The primary shortcoming of a GPU is usability, since vendor specific APIs are quite different from existing programming languages, and it requires a substantial knowledge of the device and programming interface to optimize applications. Hence, lately a growing num- ber of higher level programming models are targeting GPUs to alleviate this problem. The ultimate goal for a high-level model is to expose an easy-to-use interface for the user to offload compute intensive portions of code (kernels) to the GPU, and tune the code according to the target accelerator to maximize overall performance with a reduced development effort. In this paper, we share our experiences of three of the notable high-level directive based GPU programming models - PGI, CAPS and OpenACC (from CAPS and PGI) on an Nvidia M2090 GPU. We analyze their performance and programmability against Isotropic (ISO)/Tilted Transversely Isotropic (TTI) finite differ- ence kernels, which are primary components in the Reverse Time Migration (RTM) application used by oil and gas exploration for seismic imaging of the sub-surface. When ported to a single GPU using the mentioned directives, we observe an average 1.5-1.8x improvement in performance for both ISO and TTI kernels, when compared with optimized multi-threaded CPU implementations using OpenMP. © 2012 IEEE.";"CAPS, Finite Difference Stencils, GPGPU, HMPP, ISO, OpenACC, OpenMP, PGI, RTM, TTI"
"Martioli E., Teeple D., Manset N., Devost D., Withington K., Venne A., Tannock M.";"Open source pipeline for ESPaDOnS reduction and analysis";"OPERA is a Canada-France-Hawaii Telescope (CFHT) open source collaborative software project currently under development for an ESPaDOnS echelle spectro-polarimetric image reduction pipeline. OPERA is designed to be fully automated, performing calibrations and reduction, producing one-dimensional intensity and polarimetric spectra. The calibrations are performed on two-dimensional images. Spectra are extracted using an optimal extraction algorithm. While primarily designed for CFHT ESPaDOnS data, the pipeline is being written to be extensible to other echelle spectrographs. A primary design goal is to make use of fast, modern object-oriented technologies. Processing is controlled by a harness, which manages a set of processing modules, that make use of a collection of native OPERA software libraries and standard external software libraries. The harness and modules are completely parametrized by site configuration and instrument parameters. The software is open-ended, permitting users of OPERA to extend the pipeline capabilities. All these features have been designed to provide a portable infrastructure that facilitates collaborative development, code re-usability and extensibility. OPERA is free software with support for both GNU/Linux and MacOSX platforms. The pipeline is hosted on SourceForge under the name ""opera-pipeline"". This article concentrates on the design and software development of OPERA, whereas a forthcoming paper will present the details of the scientific methods employed by OPERA. © 2012 SPIE.";"CFHT, Data reduction, Echelle spectroscopy, ESPaDOnS, Open source, OPERA, Spectropolarimetry"
"Kotowski D., Stacey D.A.";"Ontology Library: A new approach for storing, searching and discovering ontologies";"The backbone of semantic web technologies is the ontology. This is a powerful structure, which allows for the capture, reasoning and storing of expert knowledge across various domains. Ideally these structures should be developed and implemented by experts in a set domain as well as designed with re-usability in mind. However, often due to the lack of availability and difficulties of discovering ontologies, these structures are repeatedly recreated. Current methods for storing, discovering and sharing ontologies employ similar techniques as to those used for software source code or static web pages. These are exposed to the limitation inherent with keyword-based searches, such as ambiguity with the keywords themselves and therefore, the most relevant ontology may not be discovered. This paper will examine some of the existing techniques used for the storing and sharing of ontologies. It will offer a contrasting method analogous to software libraries to develop a standard to store, share, discover, and distribute common ontologies.";"Knowledge engineering, Knowledge sharing, Ontology, Ontology library, Ontology repository, Ontology reuse"
"Spycher N., Portmann E.";"Customized mashups for improved reputation visualization";"This document describes a possible use for the YouReputation API. A mashup combining the YouReputation and the Flickr APIs attempts to improve the visualization of reputation. First, this paper gives an introduction to Web services and APIs and further explains the developed prototype. This paper introduces an API that can be easily combined with other APIs to improve the representation of reputation terms and therefore enhance usability and design. © 2012 IEEE."
"Zeidler C., Müller J., Lutteroth C., Weber G.";"Comparing the usability of grid-bag and constraint-based layouts";"While the usability of GUI design methods has been studied in general, the usability of layout specification methods is largely unexplored. In this paper we provide an empirical comparison of two popular GUI layout models, grid-bag layout and constraint-based layout. While the grid-bag layout is a powerful layout model, the constraint-based layout is able to generate even more general and flexible layout configurations. We performed a controlled experiment with postgraduate students of Computer Science and Software Engineering, measuring efficiency, accuracy and preference for typical layout specification and editing tasks. The results show significant differences between both layout models: the initial specification of GUIs is faster with a grid-bag layout whereas editing of existing complex layouts is faster and more accurate with a constraint-based layout. The study shows that constraint-based layout, although it may seem more complicated at first glance, can compete with and in some cases even outperform more conventional techniques in terms of their usability. © 2012 ACM.";"API, empiric evaluation, layout, usability"
"Podziewski A., Litwiniuk K., Legierski J.";"E-health oriented application for mobile phones";"This paper presents the idea of using mobile operators APIs with an e-health usage scenario. Since numerous elderly people are going missing every year, proposed emergency location service presents a way in which mobile operators' networks, the Internet and possibilities given by rapid improvement of phones' functionalities can converge in order to relieve the problem. The description of presented solution is supplemented with sets of accuracy measurements and usability tests, conducted during test deployment. The results confirm usability potential of the service, giving green light for further research and development. Still, in order to make the service reliable, the algorithms used to determine location and detect falls need to be improved. The article presents a method, which may be used to improve the location accuracy.";"API exposure, E-health, SDP, Service delivery platform, Telco 2.0"
"[No author name available]";"Proceedings of the 1st ACM SIGSPATIAL International Workshop on Mobile Geographic Information Systems, MobiGIS 2012 - In Conjunction with the 20th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems, GIS 2012";"The proceedings contain 14 papers. The topics discussed include: interactive traffic-aware route search on smartphones, trafficpulse : a mobile GISystem for transportation, improving unreliable mobile GIS with swarm-based particle filters, mining future spatiotemporal events and their sentiment from online news articles for location-aware recommendation system, evaluation of fine-granular GPS tracking on smartphones, duking it out at the smartphone mobile app mapping API corral: apple, google, and the competition, SALS: semantics-aware location sharing based on cloaking zone in mobile social networks, when and where next: individual mobility prediction, heuristics & usability of virtual attack points for pedestrian navigation: user study using paper-prototyping, a comparison of first- and second-order HMMs in the task of predicting the next locations of mobile individuals, and uncaught signal imputation for accuracy enhancement of WLAN-based positioning systems."
"Mishne A., Shoham S., Yahav E.";"Typestate-based semantic code search over partial programs";"We present a novel code search approach for answering queries focused on API-usage with code showing how the API should be used. To construct a search index, we develop new techniques for statically mining and consolidating temporal API specifications from code snippets. In contrast to existing semanticbased techniques, our approach handles partial programs in the form of code snippets. Handling snippets allows us to consume code from various sources such as parts of open source projects, educational resources (e.g. tutorials), and expert code sites. To handle code snippets, our approach (i) extracts a possibly partial temporal specification from each snippet using a relatively precise static analysis tracking a generalized notion of typestate, and (ii) consolidates the partial temporal specifications, combining consistent partial information to yield consolidated temporal specifications, each of which captures a full(er) usage scenario. To answer a search query, we define a notion of relaxed inclusion matching a query against temporal specifications and their corresponding code snippets. We have implemented our approach in a tool called PRIME and applied it to search for API usage of several challenging APIs. PRIME was able to analyze and consolidate thousands of snippets per tested API, and our results indicate that the combination of a relatively precise analysis and consolidation allowed PRIME to answer challenging queries effectively.";"Code Search Engine, Ranking Code Samples, Specification Mining, Static Analysis, Typestate"
"Mayer C., Hanenberg S., Robbes R., Tanter É., Stefik A.";"An empirical study of the influence of static type systems on the usability of undocumented software";"Although the study of static and dynamic type systems plays a major role in research, relatively little is known about the impact of type systems on software development. Perhaps one of the more common arguments for static type systems in languages such as Java or C++ is that they require developers to annotate their code with type names, which is thus claimed to improve the documentation of software. In contrast, one common argument against static type systems is that they decrease flexibility, which may make them harder to use. While these arguments are found in the literature, rigorous empirical evidence is lacking. We report on a controlled experiment where 27 subjects performed programming tasks on an undocumented API with a static type system (requiring type annotations) as well as a dynamic type system (which does not). Our results show that for some tasks, programmers had faster completion times using a static type system, while for others, the opposite held. We conduct an exploratory study to try and theorize why.";"Empirical research, Programming languages, Type systems"
"[No author name available]";"Human-Centered Software Engineering - 4th International Conference, HCSE 2012, Proceedings";"The proceedings contain 28 papers. The topics discussed include: a compositional model for gesture definition, a development process for usable large scale interactive critical systems: application to satellite ground segments, agile user experience development in a large software organization: good expertise but limited impact, smartphone applications usability evaluation: a hybrid model and its implementation, methods towards API usability: a structural analysis of usability problem categories, putting dementia into context: a selective literature review of assistive applications for users with dementia and their caregivers, puzzle: a visual-based environment for end user development in touch-based mobile phones, towards conflict management in user interface composition driven by business needs, a model for assessing organizational learning in software development organizations, and a personality based design approach using subgroup discovery."
"Grill T., Polacek O., Tscheligi M.";"Methods towards API usability: A structural analysis of usability problem categories";"The usability of Application Programming Interfaces (APIs) is one of the main factors defining the success of a software based framework. Research in the area of human computer interaction (HCI) currently mainly focuses on end-user usability and only little research has been done regarding the usability of APIs. In this paper, we present a methodology on how to use and combine HCI methods with the goal to evaluate the usability of APIs. The methodology consist of three phases - a heuristic evaluation, a developer workshop and interviews. We setup a case-study according to the methodology, in which we are evaluating the usability of a service-oriented framework API. The goal was to explore different HCI methods and compare the applicability of such methods to find usability problems in an API. The case-study combined qualitative and quantitative methods in order to investigate the usability and intuitiveness of the API itself. It allowed us to identify relevant problem areas for usability related issues that could be mapped to specific types of HCI methods. Examples for this are e.g. structural problems, which are identified mainly in inspection methods, while problems regarding errors and exception handling are mainly identified during the hands-on example part of the developer workshops conducted. The resulting problem areas allow us to develop a first classification of API related usability problems that are making the relevancy of usability issues for APIs more explicit and applicable. © 2012 Springer-Verlag.";"API, Contextual Interaction Framework, HCI, Usability"
"Lee M., Jo H., Choi D.H.";"Towards high performance and usability programming model for heterogeneous HPC platforms";"Latest High Performance Computing (HPC) platforms are built with heterogeneous chips such as multicore microprocessors and multicore GPUs (Graphic Processing units), thus they are commonly called as Heterogeneous High Performance Computing (HPC) platforms. Various programming models have been developed and proposed for heterogeneous platforms. However, their wide adoption in the user community is predicted to be limited, because of low performance, low usability due to revealing architectural details in the program which burdens the programmers, and most importantly the limited SIMD execution model which relies on the GPU for most of the computations in the program which can limit the performance. Thus a more general programming model beyond SIMD which is easy to use and leads to high performance needs to be developed. In this paper, we propose methods to achieve this goal by considering all types of parallelism according to Flynn's classification (SIMD, MIMD, MISD). Our proposed methods incorporate these parallelisms in the existing high usability programming models and can lead to significant performance improvements. © 2012 AICIT.";"CUDA, Heterogenesou HP platformC, OpenACC, OpenMP, programming model"
"Farhadi-Niaki F., GhasemAghaei R., Arya A.";"Empirical study of a vision-based depth-sensitive human-computer interaction system";"This paper proposes the results of a user study on vision-based depth-sensitive input system for performing typical desktop tasks through arm gestures. We have developed a vision-based HCI prototype to be used for our comprehensive usability study. Using the Kinect 3D camera and OpenNI software library we implemented our system with high stability and efficiency by decreasing the ambient disturbing factors such as noise or light condition dependency. In our prototype, we designed a capable algorithm using NITE toolkit to recognize arm gestures. Finally, through a comprehensive user experiment we compared our natural arm gestures to the conventional input devices (mouse/keyboard), for simple and complicated tasks, and in two different situations (small and big-screen displays) for precision, efficiency, ease-of-use, pleasantness, fatigue, naturalness, and overall satisfaction to verify the following hypothesis: on a WIMP user interface, the gesture-based input is superior to mouse/keyboard when using big-screen. Our empirical investigation also proves that gestures are more natural and pleasant to be used than mouse/keyboard. However, arm gestures can cause more fatigue than mouse. Copyright 2012 ACM.";"3D, Gesture interaction, HCI, Usability, Vision"
"Selmeci A., Orosz T.";"SAP remote communications";"SAP implemented a very deep level synchronous connection type based on industry standards, but early enough, in the first releases SAP enhanced this to Remote Function Call protocol and technology. The Remote Function Call technology opened the system to other SAP systems or external applications. Remote function call (RFC) is the fundamental technique for many different communication approaches within SAP solutions. Our document tries to uncover the different capabilities and usability of the SAP communication types like CPI-C, RFC, Q-API, tRFC, etc. In our study we figured out that main points of remote communication usage in a heterogeneous environment where SAP also in place are the business level communication from other SAP system or external application via business application programming interface (BAPI), and the loosely coupled distributed system environment, the ALE (application link enabling) communications based on RFCs. ©2012 IEEE.";"BAPI, CPI-C, ERP, QAPI, Remote communication, RFC"
"Mishne A., Shoham S., Yahav E.";"Typestate-based semantic code search over partial programs";"We present a novel code search approach for answering queries focused on API-usage with code showing how the API should be used. To construct a search index, we develop new techniques for statically mining and consolidating temporal API specifications from code snippets. In contrast to existing semanticbased techniques, our approach handles partial programs in the form of code snippets. Handling snippets allows us to consume code from various sources such as parts of open source projects, educational resources (e.g. tutorials), and expert code sites. To handle code snippets, our approach (i) extracts a possibly partial temporal specification from each snippet using a relatively precise static analysis tracking a generalized notion of typestate, and (ii) consolidates the partial temporal specifications, combining consistent partial information to yield consolidated temporal specifications, each of which captures a full(er) usage scenario. To answer a search query, we define a notion of relaxed inclusion matching a query against temporal specifications and their corresponding code snippets. We have implemented our approach in a tool called PRIME and applied it to search for API usage of several challenging APIs. PRIME was able to analyze and consolidate thousands of snippets per tested API, and our results indicate that the combination of a relatively precise analysis and consolidation allowed PRIME to answer challenging queries effectively. Copyright © 2012 ACM.";"Code Search Engine, Ranking Code Samples, Specification Mining, Static Analysis, Typestate"
"Lee M., Jo H., Choi D.H.";"Towards high performance and usability programming methodology for heterogeneous HPC architectures";"Various programming models have been developed and proposed for the latest heterogeneous High Performance Computing (HPC) platforms built using heterogeneous chips such as multicore microprocessors and multicore GPUs (Graphic Processing units). However, their wide adoption in the user community is predicted to be limited, because of low performance, low usability due to revealing architectural details in the program which burdens the programmers, and most importantly the limited SIMD execution model using the GPU as the main computation engine which can limit the performance in non-SIMD friendly applications. A more general programming methodology which is easy to use and leads to high performance by incorporating parallelism beyond SIMD needs to be developed. In this paper, we propose methods to achieve this goal in two ways. First, we leverage existing highly usable parallel programming models such as OpenMP and OpenACC which is recently released to become a new standard API for accelerator programming including GPUs. Second, we consider parallelism other than SIMD (MIMD, MISD) in the heterogeneous parallel program to further the performance beyond what users can currently achieve using existing proprietary APIs such as CUDA. Our proposed methodolody can thus lead to high usability and high performance for programs parallelized on heterogeneous HPC platforms.";"Heterogeneous HPC architecture, OpenACC, OpenMP, Programming methodology"
"Mayer C., Hanenberg S., Robbes R., Tanter E., Stefik A.";"An empirical study of the influence of static type systems on the usability of undocumented software";"Although the study of static and dynamic type systems plays a major role in research, relatively little is known about the impact of type systems on software development. Perhaps one of the more common arguments for static type systems in languages such as Java or C++ is that they require developers to annotate their code with type names, which is thus claimed to improve the documentation of software. In contrast, one common argument against static type systems is that they decrease flexibility, which may make them harder to use. While these arguments are found in the literature, rigorous empirical evidence is lacking. We report on a controlled experiment where 27 subjects performed programming tasks on an undocumented API with a static type system (requiring type annotations) as well as a dynamic type system (which does not). Our results show that for some tasks, programmers had faster completion times using a static type system, while for others, the opposite held. We conduct an exploratory study to try and theorize why. Copyright © 2012 ACM.";"Empirical research, Programming languages, Type systems"
"Mishima H., Aerts J., Katayama T., Bonnal R.J.P., Yoshiura K.-I.";"The Ruby UCSC API: Accessing the UCSC genome database using Ruby";"Background: The University of California, Santa Cruz (UCSC) genome database is among the most used sources of genomic annotation in human and other organisms. The database offers an excellent web-based graphical user interface (the UCSC genome browser) and several means for programmatic queries. A simple application programming interface (API) in a scripting language aimed at the biologist was however not yet available. Here, we present the Ruby UCSC API, a library to access the UCSC genome database using Ruby.Results: The API is designed as a BioRuby plug-in and built on the ActiveRecord 3 framework for the object-relational mapping, making writing SQL statements unnecessary. The current version of the API supports databases of all organisms in the UCSC genome database including human, mammals, vertebrates, deuterostomes, insects, nematodes, and yeast.The API uses the bin index-if available-when querying for genomic intervals. The API also supports genomic sequence queries using locally downloaded *.2bit files that are not stored in the official MySQL database. The API is implemented in pure Ruby and is therefore available in different environments and with different Ruby interpreters (including JRuby).Conclusions: Assisted by the straightforward object-oriented design of Ruby and ActiveRecord, the Ruby UCSC API will facilitate biologists to query the UCSC genome database programmatically. The API is available through the RubyGem system. Source code and documentation are available at https://github.com/misshie/bioruby-ucsc-api/ under the Ruby license. Feedback and help is provided via the website at http://rubyucscapi.userecho.com/. © 2012 Mishima et al., licensee BioMed Central Ltd."
"Rupakheti C.R., Hou D.";"Evaluating forum discussions to inform the design of an API critic";"Learning to use a software framework and its API (Application Programming Interfaces) can be a major endeavor for novices. To help, we have built a critic to advise the use of an API based on the formal semantics of the API. Specifically, the critic offers advice when the symbolic state of the API client code triggers any API usage rules. To assess to what extent our critic can help solve practical API usage problems and what kinds of API usage rules can be formulated, we manually analyzed 150 discussion threads from the Java Swing forum. We categorize the discussion threads according to how they can be helped by the critic. We find that API problems of the same nature appear repeatedly in the forum, and that API problems of the same nature can be addressed by implementing a new API usage rule for the critic. We characterize the set of discovered API usage rules as a whole. Unlike past empirical studies that focus on answering why frameworks and APIs are hard to learn, ours is the first designed to produce systematic data that have been directly used to build an API support tool. © 2012 IEEE.";"APIs, AWT/Swing, Critic, Java, Online Forum Discussions, Software Frameworks, Symbolic Execution"
"Rupakheti C.R., Hou D.";"CriticAL: A critic for APIs and libraries";"It is well-known that APIs can be hard to learn and use. Although search tools can help find related code examples, API novices still face other significant challenges such as evaluating the relevance of the search results. To help address the broad problems of finding, understanding, and debugging API-based solutions, we have built a critic system that offers recommendations, explanations, and criticisms for API client code. Our critic takes API usage rules as input, performs symbolic execution to check that the client code has followed these rules properly, and generates advice as output to help improve the client code. We demonstrate our critic by applying it to a real-world example derived from the Java Swing Forum. © 2012 IEEE.";"API, AWT/Swing, Critic, Symbolic Execution"
"Andersch M., Chi C.C., Juurlink B.";"Programming parallel embedded and consumer applications in OpenMP superscalar";"In this paper, we evaluate the performance and usability of the parallel programming model OpenMP Superscalar (OmpSs), apply it to 10 different benchmarks and compare its performance with corresponding POSIX threads implementations. Copyright © 2012 ACM.";"Consumer, Embedded, OmpSs, OpenMP superscalar"
"Uddin G., Dagenais B., Robillard M.P.";"Temporal analysis of API usage concepts";"Software reuse through Application Programming Interfaces (APIs) is an integral part of software development. The functionality offered by an API is not always accessed uniformly throughout the lifetime of a client program. We propose Temporal API Usage Pattern Mining to detect API usage patterns in terms of their time of introduction into client programs. We detect concepts as distinct groups of API functionality from the change history of a client program. We locate those concepts in the client change history and detect temporal usage patterns, where a pattern contains a set of concepts that were added into the client program in a specific temporal order. We investigated the properties of temporal API usage patterns through a multiple-case study of three APIs and their use in up to 19 client software projects. Our technique was able to detect a number of valuable patterns in two out of three of the APIs investigated. Further investigation showed some patterns to be relatively consistent between clients, produced by multiple developers, and not trivially derivable from program structure or API documentation. © 2012 IEEE.";"API Usability, API Usage, Mining Software Repositories, Software Reuse, Usage Pattern"
"Nguyen A.T., Nguyen T.T., Nguyen H.A., Tamrawi A., Nguyen H.V., Al-Kofahi J., Nguyen T.N.";"Graph-based pattern-oriented, context-sensitive source code completion";"Code completion helps improve developers' programming productivity. However, the current support for code completion is limited to context-free code templates or a single method call of the variable on focus. Using software libraries for development, developers often repeat API usages for certain tasks. Thus, a code completion tool could make use of API usage patterns. In this paper, we introduce GraPacc, a graph-based, pattern-oriented, context-sensitive code completion approach that is based on a database of such patterns. GraPacc represents and manages the API usage patterns of multiple variables, methods, and control structures via graph-based models. It extracts the context-sensitive features from the code under editing, e.g. the API elements on focus and their relations to other code elements. Those features are used to search and rank the patterns that are most fitted with the current code. When a pattern is selected, the current code will be completed via a novel graph-based code completion algorithm. Empirical evaluation on several real-world systems shows that GraPacc has a high level of accuracy in code completion. © 2012 IEEE.";"API usage pattern, pattern-based code completion"
"Nguyen A.T., Nguyen H.A., Nguyen T.T., Nguyen T.N.";"GraPacc: A graph-based pattern-oriented, context-sensitive code completion tool";"Code completion tool plays an important role in daily development activities. It helps developers by auto-completing tedious and detailed code during an editing session. However, existing code completion tools are limited to recommending only context-free code templates and a single method call of the variable under editing. We introduce GraPacc, an advanced, context-sensitive code completion tool that is based on frequent API usage patterns. It extracts the context-sensitive features from the code under editing, for example, the API elements on focus and the current editing point, and their relations to other code elements. It then ranks the relevant API usage patterns and auto-completes the current code with the proper elements according to the chosen pattern. © 2012 IEEE.";"Pattern-oriented Code Completion, Usage Pattern"
"Zhang C., Yang J., Zhang Y., Fan J., Zhang X., Zhao J., Ou P.";"Automatic parameter recommendation for practical API usage";"Programmers extensively use application programming interfaces (APIs) to leverage existing libraries and frameworks. However, correctly and efficiently choosing and using APIs from unfamiliar libraries and frameworks is still a non-trivial task. Programmers often need to ruminate on API documentations (that are often incomplete) or inspect code examples (that are often absent) to learn API usage patterns. Recently, various techniques have been proposed to alleviate this problem by creating API summarizations, mining code examples, or showing common API call sequences. However, few techniques focus on recommending API parameters. In this paper, we propose an automated technique, called Precise, to address this problem. Differing from common code completion systems, Precise mines existing code bases, uses an abstract usage instance representation for each API usage example, and then builds a parameter usage database. Upon a request, Precise queries the database for abstract usage instances in similar contexts and generates parameter candidates by concretizing the instances adaptively. The experimental results show that our technique is more general and applicable than existing code completion systems, specially, 64% of the parameter recommendations are useful and 53% of the recommendations are exactly the same as the actual parameters needed. We have also performed a user study to show our technique is useful in practice. © 2012 IEEE.";"API, argument, code completion, parameter, recommendation"
"Pradel M., Jaspan C., Aldrich J., Gross T.R.";"Statically checking API protocol conformance with mined multi-object specifications";"Programmers using an API often must follow protocols that specify when it is legal to call particular methods. Several techniques have been proposed to find violations of such protocols based on mined specifications. However, existing techniques either focus on single-object protocols or on particular kinds of bugs, such as missing method calls. There is no practical technique to find multi-object protocol bugs without a priori known specifications. In this paper, we combine a dynamic analysis that infers multi-object protocols and a static checker of API usage constraints into a fully automatic protocol conformance checker. The combined system statically detects illegal uses of an API without human-written specifications. Our approach finds 41 bugs and code smells in mature, real-world Java programs with a true positive rate of 51%. Furthermore, we show that the analysis reveals bugs not found by state of the art approaches. © 2012 IEEE.";"Specification mining, Static analysis, Typestate"
"Buse R.P.L., Weimer W.";"Synthesizing API usage examples";"Key program interfaces are sometimes documented with usage examples: concrete code snippets that characterize common use cases for a particular data type. While such documentation is known to be of great utility, it is burdensome to create and can be incomplete, out of date, or not representative of actual practice. We present an automatic technique for mining and synthesizing succinct and representative human-readable documentation of program interfaces. Our algorithm is based on a combination of path sensitive dataflow analysis, clustering, and pattern abstraction. It produces output in the form of well-typed program snippets which document initialization, method calls, assignments, looping constructs, and exception handling. In a human study involving over 150 participants, 82% of our generated examples were found to be at least as good at human-written instances and 94% were strictly preferred to state of the art code search. © 2012 IEEE."
"Cuibus M., Potolea R.";"Adaptable swarm intelligence framework";"Modern software systems must be continuously adapted to current performance and usability requirements. Indicators like overhead, computational complexity, parameter tuning, or ease of design and implementation are getting increasingly harder to accomplish due to constant increase in system dimensions like code size, API (Application Programming Interface), deployment size, component communication, network lag etc. Furthermore, many entities rely on classic, highly deterministic algorithms that are little or not capable of changing strategies on the fly. Lately, bio-inspired algorithms have successfully tackled this problem with significant, positive results. We propose a framework that may prove useful in obtaining better performance by automatically selecting and combining the best swarm intelligence algorithms with the best parameter selection. Copyright 2012 ACM.";"Adaptable, Ant colony optimization, Framework, Genetic algorithms, Swarm intelligence"
"Schreckling D., Posegga J., Hausknecht D.";"Constroid: Data-centric access control for android";"We introduce Constroid, a data-centric security policy management framework for Android. It defines a new middleware which allows the developer to specify well defined data items of fine granularity. For these data items, Constroid administrates security policies which are based on the usage control model. They can only be modified by the user of an application not by the applications itself. We use Con-stroid's middle-ware to protect the security policies, ensure consistency between a data item and its corresponding security policy, and describe how our prototype implementation can enforce a subset of possible usage control policies. In this way, our contribution shows how we overcome the rigid API-driven approach to security in Android. The structure and implementation of our framework is presented and discussed in terms of security, performance, and usability. © 2012 ACM.";"access control, Android, applied security, privacy, usage control"
"Wu Y., Shao P.";"Middleware-based distributed data acquisition and control in smart home networks";"For each of the networking techniques widely adopted in the field of home appliance control has its strength and weakness, it is more desirable to use multiple network technologies at the same time. Multi-platform smart home system would be an objective existence. In general point to point method, with the increasing of underlying hardware units and upper applications, the complexity of the central control unit will increase linearly. By using a universal home control middleware adapter, we decouple the application layer from the hardware layer, and make it possible to enable distributed data acquisition and control in a multi-platform smart home system. Many validated methods efficient to implement distributed data acquisition and control are discussed under this architecture, like using a timer or special thread with the unified API of the middleware adapter, redefinition callback or delegation functions for one type of the application interface, or using middleware integrated database to directly save the collected data. For each of these discussed methods, higher quality and usability both of devices and user interfaces, higher performance, lower production costs and loose-coupled hardware networks of different technologies are concerned. © 2012 Springer-Verlag GmbH."
"Tan S.H., Marinov D., Tan L., Leavens G.T.";"@tComment: Testing javadoc comments to detect comment-code inconsistencies";"Code comments are important artifacts in software. Javadoc comments are widely used in Java for API specifications. API developers write Javadoc comments, and API users read these comments to understand the API, e.g., reading a Javadoc comment for a method instead of reading the method body. An inconsistency between the Javadoc comment and body for a method indicates either a fault in the body or, effectively, a fault in the comment that can mislead the method callers to introduce faults in their code. We present a novel approach, called @TCOMMENT, for testing Javadoc comments, specifically method properties about null values and related exceptions. Our approach consists of two components. The first component takes as input source files for a Java project and automatically analyzes the English text in Javadoc comments to infer a set of likely properties for a method in the files. The second component generates random tests for these methods, checks the inferred properties, and reports inconsistencies. We evaluated @TCOMMENT on seven open-source projects and found 29 inconsistencies between Javadoc comments and method bodies. We reported 16 of these inconsistencies, and 5 have already been confirmed and fixed by the developers. © 2012 IEEE.";"comment analysis, random testing, test generation"
"Jin H., Kellogg M., Mehrotra P.";"Using compiler directives for accelerating CFD applications on GPUs";"As the current trend of parallel systems is towards a cluster of multi-core nodes enhanced with accelerators, software development for such systems has become a major challenge. Both low-level and high-level programming models have been developed to address complex hierarchical structures at different hardware levels and to ease the programming effort. However, achieving the desired performance goal is still not a simple task. In this study, we describe our experience with using the accelerator directives developed by the Portland Group to port a computational fluid dynamics (CFD) application benchmark to a general-purpose GPU platform. Our work focuses on the usability of this approach and examines the programming effort and achieved performance on two Nvidia GPU-based systems. The study shows very promising results in terms of programmability as well as performance when compared to other approaches such as the CUDA programming model. © 2012 Springer-Verlag.";"Accelerator Directives, GPU Programming, Performance Evaluation"
"Gruetz R., Focke N.K., Hoheisel A., Krefting D., Loehnhardt B., Viezens F., Dickmann F.";"Enabling parallel computing of a brain connectivity map using the MediGRID-infrastructure and FSL";"The non-invasive method to track fibers of the human brain by analyzing diffusion weighted magnetic resonance images improves research of human brain structures and becomes therefore increasingly important. With fiber tracking, a connectivity map which depicts the degree of connectivity of the single voxels can be generated and used to improve knowledge about the human brain. Several tools exist to produce connectivity maps. One of them is part of the FMRIB Software Library (FSL) and free for non-commercial purposes. Due to long and therefore impracticable computing time on small computer cluster solutions, a GUI and the necessary software were implemented for the German MediGRID infrastructure. This was achieved by using wrapper scripts and a workflow for the Generic Workflow Execution Service (GWES). The solution is about 15 times faster than a small local cluster installation, depending on the number of employed MediGRID resources. This enables processing of connectivity maps for practical use in biomedical research. By using the D-Grid infrastructure, this solution is also suitable for small institutes without compute center capacities. For usability reasons, the GUI ConBrain was developed. © 2012 IEEE.";"Brain connectivity map, FSL, GWES, HEALTHGRID, MRI, Tractography, XML"
"Lo D., Ramalingam G., Ranganath V.-P., Vaswani K.";"Mining quantified temporal rules: Formalism, algorithms, and evaluation";"Libraries usually impose constraints on how clients should use them. Often these constraints are not well-documented. In this paper, we address the problem of recovering such constraints automatically, a problem referred to as specification mining. Given some client programs that use a given library, we identify constraints on the library usage that are (almost) satisfied by the given set of clients. The class of rules we target for mining combines simple binary temporal operators with state predicates (composed of equality constraints) and quantification. This is a simple yet expressive subclass of temporal properties (LTL formulae) that allows us to capture many common API usage rules. We focus on recovering rules from execution traces and apply classical data mining concepts to be robust against bugs (API usage rule violations) in clients. We present new algorithms for mining rules from execution traces. We show how a propositional rule mining algorithm can be generalized to treat quantification and state predicates in a unified way. Our approach enables the miner to be complete (i.e. , mine all rules within the targeted class that are satisfied by the given traces) while avoiding an exponential blowup. We have implemented these algorithms and used them to mine API usage rules for several Windows APIs. Our experiments show the efficiency and effectiveness of our approach. © 2010 Elsevier B.V. All rights reserved.";"Dynamic analysis, Quantification, Reverse engineering, Specification mining, Temporal rules"
"Maia R., Cerqueira R., De Souza C.S., Guisasola-Gorham T.";"A qualitative human-centric evaluation of flexibility in middleware implementations";"Today middleware is much more powerful, more reliable and faster than it used to be. Nevertheless, for the application developer, the complexity of using middleware platforms has increased accordingly. The volume and variety of application contexts that current middleware technologies have to support require that developers be able to anticipate the widest possible range of execution environments, desired and undesired effects of different programming strategies, handling procedures for runtime errors, and so on. This paper shows how a generic framework designed to evaluate the usability of notations (the Cognitive Dimensions of Notations Framework, or CDN) has been instantiated and used to analyze the cognitive challenges involved in adapting middleware platforms. This human-centric perspective allowed us to achieve novel results compared to existing middleware evaluation research, typically centered around system performance metrics. The focus of our study is on the process of adapting middleware implementations, rather than in the end product of this activity. Our main contributions are twofold. First, we describe a qualitative CDN-based method to analyze the cognitive effort made by programmers while adapting middleware implementations. And second, we show how two platforms designed for flexibility have been compared, suggesting that certain programming language design features might be particularly helpful for developers. © 2011 Springer Science+Business Media, LLC.";"API evaluation, Cognitive Dimensions of Notations, Middleware evaluation, Programmer experience, Qualitative methods"
"Scheller T., Kuhn E.";"Influencing factors on the usability of API classes and methods";"Usability is an important quality attribute for APIs. To create APIs with good usability, appropriate measurement methods are needed. But currently available methods are cost- and time-expensive and the results are not objective and therefore hard to quantify. API design guidelines give a good overview about important usability factors, but lack a scientific basis. When looking at scientific API usability studies, only a very small area of API design has been researched yet. Existing results don't give enough basis for a good API usability measurement method. In this paper we identify influencing usability factors for the two most common concepts of APIs: classes and methods. We therefore conduct a study with 20 programmers and 2 different API variants and evaluate how differences between the APIs influence usability when instantiating classes and calling methods. The results build a basis for API usability measurement methods and should help design more usable APIs. © 2012 IEEE.";"API Design, API Usability, Usability Measurement, Usability Studies"
"Bauer V., Heinemann L.";"Understanding API usage to support informed decision making in software maintenance";"Reuse of third-party libraries promises significant productivity improvements in software development. However, dependencies on external libraries and their APIs also introduce risks to a project and impact strategic decisions during development and maintenance. Informed decision making therefore requires a thorough understanding of the extent and nature of dependencies on external APIs. As realistically sized applications are often heavily entangled with various external APIs, gaining this understanding is infeasible with manual inspections only. To address this, we present an automated approach to analyze the dependencies of software projects on external APIs. The approach is supported by a static analysis tool featuring a visualization of the analysis results. We evaluate the approach as well as the tooling on multiple open source Java systems. © 2012 IEEE.";"API, Library, Software maintenance, Software reuse"
"Mühlberg J.T., Lüttgen G.";"Verifying compiled file system code";"This article presents a case study on retrospective verification of the Linux Virtual File System (VFS), which is aimed at checking violations of API usage rules and memory properties. Since VFS maintains dynamic data structures and is written in a mixture of C and inlined assembly, modern software model checkers cannot be applied. Our case study centres around our novel automated software verification tool, the SOCA Verifier, which symbolically executes and analyses compiled code.We describe how this verifier deals with complex features such as memory access, pointer aliasing and computed jumps in the VFS implementation, while reducing manual modelling to a minimum. Our results show that the SOCA Verifier is capable of analysing the complex Linux VFS implementation reliably and efficiently, thereby going beyond traditional testing tools and into niches that current software model checkers do not reach. This testifies to the SOCA Verifier's suitability as an effective and efficient bug-finding tool during the development of operating system components. © 2011 BCS.";"Case study, Linux virtual file system, Model checking, Object code analysis, Symbolic execution"
"Alcock S., Lorier P., Nelson R.";"Libtrace: A packet capture and analysis library";"This paper introduces libtrace, an open-source software li- brary for reading and writing network packet traces. Lib- trace offers performance and usability enhancements com- pared to other libraries that are currently used. We de- scribe the main features of libtrace and demonstrate how the libtrace programming API enables users to easily develop portable trace analysis tools without needing to consider the details of the capture format, file compression or inter- mediate protocol headers. We compare the performance of libtrace against other trace processing libraries to show that libtrace offers the best compromise between development ef- fort and program run time. As a result, we conclude that libtrace is a valuable contribution to the passive measure- ment community that will aid the development of better and more reliable trace analysis and network monitoring tools.";"Packet Capture, Protocol De-coding, Trace Analysis"
"Edwards H.C., Sunderland D.";"Kokkos Array performance-portable manycore programming model";"Large, complex scientific and engineering application code have a significant investment in computational kernels which implement their mathematical models. Porting these computational kernels to multicore-CPU and manycore-accelerator (e.g., NVIDIA® GPU) devices is a major challenge given the diverse programming models, application programming interfaces (APIs), and performance requirements. The Kokkos Array programming model provides library-based approach for implementing computational kernels that are performance-portable to multicore-CPU and manycore-accelerator devices. This programming model is based upon three fundamental concepts: (1) manycore compute devices each with its own memory space, (2) data parallel computational kernels, and (3) multidimensional arrays. Performance-portability is achieved by decoupling computational kernels from device-specific data access performance requirements (e.g., NVIDIA coalesced memory access) through an intuitive multidimensional array API. The Kokkos Array API uses C++ template meta-programming to, at compile time, transparently insert device-optimal data access maps into computational kernels. With this programming model computational kernels can be written once and, without modification, performance-portably compiled to multicore-CPU and manycore-accelerator devices. © 2012 ACM.";"GPU, manycore, mini-application, multicore, multidimensional array"
"Andersch M., Chi C.C., Juurlink B.";"Programming parallel embedded and consumer applications in openmp superscalar";"In this paper, we evaluate the performance and usability of the parallel programming model OpenMP Superscalar (OMPSS), apply it to 10 different benchmarks and compare its performance with corresponding POSIX threads implementations.";"Consumer, Embedded, OMPSS, OpenMP superscalar"
"Kim I.-H., Jeong G.-M., Park E.-C., Chung K.-D.";"A WPAN platform design in mobile phone considering application development and usability";"In this paper, we propose a WPAN (Wireless Personal Area Network) platform for converged network services integrating a cellular network and a WPAN. We mainly focus on an easy-to-develop and easy-to-use WPAN platform for wireless communication services using both networks. The proposed WPAN platform consists of a WPAN handset platform, a WPAN connection scheme, and a WPAN server platform. The WPAN handset platform provides abstract WPAN API (Application Programming Interface) set and application management module. Using the WPAN connection scheme, the user can enjoy converged network services in a convenient way. The WPAN server platform manages the overall services and digital devices that are connected to the handset. Compared to the existing WPAN related platform, we consider the need for the integrated service components allowing for the development of WPAN applications in the handset and their convenience for the user. Also, illustrative services and devices are implemented using the proposed method, which show the applicability of the proposed WPAN platform. © 2006-2012 by CCC Publications.";"API abstraction, Connection scheme, Converged network, Mobile game, Platform, Server structure, Wpan"
"Akbar R.J., Omori T., Maruyama K.";"Detecting API usage patterns from software repositories using method categorization";"Developers often have difficulties using APIs. To aid developers in efficiently using APIs, API usage patterns can be extracted from source code stored in software repositories. Previous approaches have mined repositories to extract API usage patterns by simply applying a data mining technique to the collection of method invocations of API objects. However, respective roles of invoked methods within API objects are not considered in these approaches. This paper proposes an improved approach that extracts API usage patterns at a higher-level abstraction rather than mining the actual method invocations. Our approach embraces a multilevel sequential mining technique and uses categorization of method invocations to define their concept hierarchy. In the categorization, the method invocations are categorized based on their roles. The extracted API usage patterns represent recurring usages of API objects. Therefore, they are useful to recommend typical usages of APIs. The experimental results show that our approach is practical to discover patterns that reveal characteristics of usages. © 2012 The authors and IOS Press. All rights reserved.";"API usage patterns, categorization, Mining software repositories"
"[No author name available]";"4th International Conference on Human-Centered Software Engineering, HCSE 2016";"The proceedings contain 28 papers. The special focus in this conference is on Human-Centered Software Engineering. The topics include: Human factors engineering as the methodological Babel fish, translating user needs into software design, improving software effort estimation using an expert-centred approach, a compositional model for gesture definition, a development process for usable large scale interactive critical systems, agile user experience development in a large software organization, Smartphone applications usability evaluation, methods towards API usability, a structural analysis of usability problem categories, requirements sensemaking using concept maps, towards conflict management in user interface composition driven by business needs, a model for assessing organizational learning in software development organizations, a personality based design approach using subgroup discovery, assessing use complexity of software, support for the application of creativity techniques in requirements engineering, exploring local cultural perspectives in user interface development in an Indian offshoring context, improving support for visual task modelling, lessons learned from evaluating the usability of mobile spreadsheet applications, ProtoTask, new task model simulator, the usage of usability techniques in scrum projects, visualizing sensor data and graphical controls based environment for user interface evaluation."
"Wang L., Zou Y., Fang L., Xie B., Yang F.";"An exploratory study of API usage examples on the web";"Usage examples are helpful for programmers learning to use APIs from third-party frameworks or libraries. There are lots of usage examples scattered in web pages on the Web, such as tutorials, blogs, and forums. A few researches have proposed approaches to leveraging these usage examples to improve programming. However, due to the lack of comprehensive understanding on the current situation of usage examples on the web, the work is still at the very beginning. Many concerns are reserved, for instance, how many usage examples can be found on the Web? how well do such examples support programmers on earth? what factors have impact on these examples' usability? In this paper, we conducted an exploratory study of usage examples on the web, including their distribution, characteristics like content style, correctness, and complexity, as well as their correlations. Through the study, we obtain some insight of how to facilitate utilization of usage examples on the web and what mechanisms could be provided. Possible research directions and problems are proposed at the end. © 2012 IEEE.";"API, empirical study, usage examples, web search"
"Saulnier A., Courounet P., Viaud M.L.";"How to increase the role of users in evaluating the quality of use of a system [Comment accroître le rôle des utilisateurs dans l'évaluation de la qualité d'utilisation d'un système]";"This paper presents criteria and methods which were used to evaluate the usability of several professional services within the European project ASSETS. A unified approach of user-centered method is proposed to test services at various stages of development according to their GUI or API access. The notion of perceived usability and utility are introduced to increase the user involvement in the evaluation process. In our professional context, we tried to highlight the relevance of the perceived quality of the results. © 2012 ACM 978-1-4503-1846-4/12/10 ...$15.00.";"Evaluation, ISO 9126, ISO 9241, Perceived utility, Quality of use, Usability"
"Kosec G., Trobec R.";"A parallel meshless numerical approach for the solution of transport phenomena";"The application of the local meshless numerical method (LRBFCM) for solving a system of coupled partial differential equations (PDE) is explored. The numerical approach is tested on the natural convection based fluid flow problems. The fluid flow part of the solution procedure is coupled locally despite its global nature. Such an approach makes the computations convenient for an implementation on parallel computers. In this paper, the OpenMP based parallelization of the proposed numerical approach is demonstrated. On two cores, a superlinear speedup of 2.5 is confirmed by the performance analysis. The parallelization performance is explored for the classical de Vahl Davis natural convection case. The usability of the meshless numerical framework is demonstrated on highly non-linear and coupled case of solidification of binary alloy, where energy and solute transport govern double natural convection in a domain filled with porous media and free fluid with moving interphases. © Civil-Comp Press, 2012.";"Convective-diffusive problems, De vahl davis, Fluid flow, Lrbfcm, Meshfree, Natural convection, Porous, Solidification"
"Cortez R., Vazhenin A., Brine J.";"Wikipedia miner engine: A re-usable e-learning service based on a virtual MVC design pattern";"E-Learning platforms are evolving from monolithic applications with a rigid structure that did not allowed for the exchange of tools or components to applications incorporating service orientation concepts as well as facilitating the dynamic discovery and assembling of e-learning services. Accordingly, the usage of support materials to provide additional guidance to students facilitates the comprehension of learning tasks. Wikipedia is one of the richest sources of human knowledge, encompassing a vast range of topics of all kinds of information, and content, which is in constant change due to its collaborative dynamic nature. The Wikipedia Miner provides a code that can parse a given document identifying main topics and link them to corresponding articles or short definitions from the Wikipedia content. In this paper, we discuss the realization of a reusable Wikipedia Miner service for the e-Learning Computational Cloud (eLC2) Platform designed with the J2EE technology and Service-Oriented (V-MVC) model excluding a direct link between the Model and the View. This allows enhancing the Controller as a middleware, removing the dependency and acting as a single point of contact. In the V-MVC design pattern, the Controller is modeled by the compound design pattern of the Enterprise Service Bus (ESB) supporting higher privacy of the business logic and higher re-usability Architecture standards. The eLC2 is also based on an original Virtual Model-View-Controller of application components. In this framework, Wikipedia Miner services were prototyped as an Application Engine that wraps the logic of the Wikipedia Miner API in order to re-use it for different types of applications. Particularly, we are focusing on two applications in order to demonstrate the usability of the proposed approach. The first application is the WikiGloss tool, which is based on a glossing approach to help learners of English-as-second-language with an extensive reading task. The second application is an Intelligent Hints service for a Task Management Environment which provides explanatory links from relevant Wikipedia articles related to topics of the e-Learning task. This allows re-use of the same problems in different task type modes such as lectures, exercises, and quizzes. © 2012 The authors and IOS Press. All rights reserved.";"Design Patterns, E-Learning, Service Oriented Architecture (SOA), Web services"
"De Luca V., Epicoco I., Lezzi D., Aloisio G.";"GRB-WAPI, a RESTful framework for grid portals";"Nowadays grid portals are characterized by various and different features and are implemented in very differing programming languages and technologies, still having many structural aspects in common. This paper describes a RESTful Web API, named GRB-WAPI, specifically developed for grid computing that encapsulates all grid control and computation logic need to build a grid portal. Through the adoption of this API a portal developer does not have to deal with grid technical details focusing just on the high level design of her system and on some other aspects that concern presentation, such as portal usability and functionality. The idea of developing a traditional library has been discarded in order to free portal developers from a particular implementation technology. Thanks to this choice the portal presentation logic can be implemented in any web technology and can be deployed on a different server. Traditional Web Services and SOAP protocol approach has been discarded in order to adopt a RESTful approach to make the Web APIs lighter and also to take advantage of some other aspects illustrated in the paper. © 2012 Published by Elsevier Ltd.";"Grid portals, Grid problem solving environment, REST, Web API"
"Alnusair A., Zhao T.";"Retrieving reusable software components using enhanced representation of domain knowledge";"This paper describes an ontology-based approach for identifying and retrieving relevant software components in large reuse libraries. Since it is usually difficult to precisely identify exact matches without considering domain knowledge, we exploit the use of domain-specific ontologies to enrich a knowledge base initially populated with multi-faceted ontological descriptions of API components. In addition to pure semantic-based search, this enriched knowledge base supports signature-based search, keyword search, and blended search. However, our experiments show evidence that only semantic search that is backed by reasoning services enables intelligent matchmaking and yields improved precision. Based on a usability case study, we further argue that semantic search is indeed usable and practical. © 2012 Springer-Verlag/Wien."
"Steiner T., Verborgh R., Vallés J.G., Van De Walle R.";"Adding meaning to facebook microposts via a mash-up API and tracking its data provenance";"The social networking website Facebook offers to its users a feature called ""status updates"" (or just ""status""), which allows users to create microposts directed to all their contacts, or a subset thereof. Readers can respond to microposts, or in addition to that also click a ""Like"" button to show their appreciation for a certain micropost. Adding semantic meaning in the sense of unambiguous intended ideas to such microposts can, for example, be achieved via Natural Language Processing (NLP). Therefore, we have implemented a RESTful mash-up NLP API, which is based on a combination of several third party NLP APIs in order to retrieve more accurate results in the sense of emergence. In consequence, our API uses third party APIs opaquely in the background in order to deliver its output. In this paper, we describe how one can keep track of provenance, and credit back the contributions of each single API to the combined result of all APIs. In addition to that, we show how the existence of provenance metadata can help understand the way a combined result is formed, and optimize the result combination process. Therefore, we use the HTTP Vocabulary in RDF and the Provenance Vocabulary. The main contribution of our work is a description of how provenance metadata can be automatically added to the output of mash-up APIs like the one presented here. © 2011 IEEE."
"Khatoon S., Li G., Ashfaq R.M.";"A Framework for automatically mining source code";"Mining source code by using different data mining techniques to extract the informative patterns like programming rules, variable correlation, code clones and frequent API usage is an active area of research. However, no practical framework for integrating these tasks has been attempted. To achieve this objective an integrated framework is designed that can detect different types of bugs to achieve software quality and assist developer in reusing API libraries for rapid software development. Proposed framework automatically extracts large variety of programming patterns and finds the locations where the extracted patterns are violated. Violated patterns are reported as programming rule violation, copy paste code related bugs and inconsistent variable update bugs. Although, the bugs are different but the framework can detect these bugs in one pass and produces higher quality software systems within budget. The framework also helps in code reusing by suggesting the programmer how to write API code to facilitate rapid software development. Proposed framework is validated by developing a prototype that developed in C# (MS Visual Studio, 2008) and evaluated on large application like ERP. Results shows proposed technique greatly reduced time and cost of manually checking defects from source code by programmers. © 2011 Academic Journals Inc.";"API usage, Constraint-based mining, Copy-paste code, Programming rule, Source code mining"
"Zibran M.F., Eishita F.Z., Roy C.K.";"Useful, but usable? Factors affecting the usability of APIs";"Software development today has been largely dependent on the use of API libraries, frameworks, and reusable components. However, the API usability issues often increase the development cost (e.g., time, effort) and lower code quality. In this regard, we study 1,513 bug-posts across five different bug repositories, using both qualitative and quantitative analysis. We identify the API usability issues that are reflected in the bug-posts from the API users, and distinguish relative significance of the usability factors. Moreover, from the lessons learned by manual investigation of the bug-posts, we provide further insight into the most frequent API usability issues. © 2011 IEEE.";"API, Application Programming Interface, Usability"
"Brunet J., Serey D., Figueiredo J.";"Structural conformance checking with design tests: An evaluation of usability and calability";"Verifying whether a software meets its functional requirements plays an important role in software development. However, this activity is necessary, but not sufficient to assure software quality. It is also important to check whether the code meets its design specification. Although there exists substantial tool support to assure that a software does what it is supposed to do, verifying whether it conforms to its design remains as an almost completely manual activity. In a previous work, we proposed design tests - test-like programs that automatically check implementations against design rules. Design test is an application of the concept of test to design conformance checking. To support design tests for Java projects, we developed DesignWizard, an API that allows developers to write and execute design tests using the popular JUnit testing framework. In this work, we present a study on the usability and scalability of DesignWizard to support structural conformance checking through design tests. We conducted a qualitative usability evaluation of DesignWizard using the Think Aloud Protocol for APIs. In the experiment, we challenged eleven developers to compose design tests for an open-source software project. We observed that the API meets most developers' expectations and that they had no difficulties to code design rules as design tests. To assess its scalability, we evaluated DesignWizard's use of CPU time and memory consumption. The study indicates that both are linear functions of the size of software under verification. © 2011 IEEE.";"design test, strucutural conformance checking"
"Scheller T., Kühn E.";"Measurable concepts for the usability of software components";"While usability has proven to be an important software quality attribute, its application to APIs is still rather uncommon. Available methods for measuring software usability show significant disadvantages when applied to APIs, like the need for test users and experienced evaluators. This makes it difficult to evaluate the usability of software components, as well as to compare different software components. An API usability measurement method is needed that is both machine-computable and objective. This paper takes a first step in the direction of such a measure by identifying measurable concepts for the usability of software components, and validating these concepts against existing studies and guidelines for usability and API design. © 2011 IEEE."
"Ko A.J., Riche Y.";"The role of conceptual knowledge in API usability";"While many studies have investigated the challenges that developers face in finding and using API documentation, few have considered the role of developers' conceptual knowledge in these tasks. We designed a study in which developers were asked to explore the feasibility of two requirements concerning networking protocols and application platforms that most participants were unfamiliar with, observing the effect that a lack of conceptual knowledge had on their use of documentation. Our results show that without conceptual knowledge, developers struggled to formulate effective queries and to evaluate the relevance or meaning of content they found. Our results suggest that API documentation should not only include detailed examples of API use, but also thorough introductions to the concepts, standards, and ideas manifested in an API's data structures and functionality. © 2011 IEEE.";"API usability, documentation, feasibility"
"Uddin G., Dagenais B., Robillard M.P.";"Analyzing temporal API usage patterns";"Software reuse through Application Programming Interfaces (APIs) is an integral part of software development. As developers write client programs, their understanding and usage of APIs change over time. Can we learn from long-term changes in how developers work with APIs in the lifetime of a client program? We propose Temporal API Usage Mining to detect significant changes in API usage. We describe a framework to extract detailed models representing addition and removal of calls to API methods over the change history of a client program. We apply machine learning technique to these models to semi-automatically infer temporal API usage patterns, i.e., coherent addition of API calls at different phases in the life-cycle of the client program. © 2011 IEEE.";"API Usability, API Usage, Mining Software Repositories, Software Reuse, Usage Pattern"
"Mar L.W., Wu Y.-C., Jiau H.C.";"Recommending proper API code examples for documentation purpose";"Code examples are important resources for expressing correct application programming interface (API) usages. However, many framework and library APIs fail in offering sufficient code examples in corresponding API documentations. This is because constructing proper code examples for documentation purpose takes significant developers' efforts. To reduce such effort, this work proposes a methodology, PropER-Doc, that recommends proper code examples for documentation purpose. PropER-Doc accepts queries from API developers and utilizes code search engines (CSEs) to collect corresponding code example candidates. The structural and conceptual links between API elements are captured from the API implementation and available API documents to guide candidate recommendation. During recommendation, PropER-Doc groups collected candidates based on involved API types for distinguishing different API usages. To assist API developers in selecting proper candidates, a diagrammatic presentation and three code example appropriateness metrics are also developed in PropER-Doc. Two case studies on Eclipse JDT framework are conducted to confirm the effectiveness of PropER-Doc. © 2011 IEEE.";"API usage, Code example, Documentation, Framework"
"Prajapati H.B., Vij S.K.";"Analytical study of parallel and distributed image processing";"The available literature on parallel and distributed image processing is scattered and not organized for use to beginners. Thus, there is a need of concise understanding of parallel and distributed image processing area. In this paper, we present analysis of parallel and distributed image processing with comprehensive details, so that it becomes very useful to beginners and to those who are new to parallel or distributed image processing field. We present the outcome of our study of parallel and distributed image processing with emphasis on mechanisms, tools/technology/API used, application domains, and ongoing research work. We examine the research issues in parallel and distributed image processing. We also identify some future research directions for distributed image processing. This study provides concise understanding of the parallel and distributed image processing area to the beginners. © 2011 IEEE.";"Data Parallelism, Distributed Image Processing, Distributed Image Processing Systems, Parallel Image Processing, Parallel Image Processing Tools, Task Parallelism"
"Zhong H., Zhang L., Xie T., Mei H.";"Inferring specifications for resources from natural language API documentation";"Many software libraries, especially those commercial ones, provide API documentation in natural languages to describe correct API usages. However, developers may still write code that is inconsistent with API documentation, partially because many developers are reluctant to carefully read API documentation as shown by existing research. As these inconsistencies may indicate defects, researchers have proposed various detection approaches, and these approaches need many known specifications. As it is tedious to write specifications manually for all APIs, various approaches have been proposed to mine specifications automatically. In the literature, most existing mining approaches rely on analyzing client code, so these mining approaches would fail to mine specifications when client code is not sufficient. Instead of analyzing client code, we propose an approach, called Doc2Spec, that infers resource specifications from API documentation in natural languages. We evaluated our approach on the Javadocs of five libraries. The results show that our approach performs well on real scale libraries, and infers various specifications with relatively high precisions, recalls, and F-scores. We further used inferred specifications to detect defects in open source projects. The results show that specifications inferred by Doc2Spec are useful to detect real defects in existing projects. © Springer Science+Business Media, LLC 2011.";"API documentation, Inferring specifications"
"Wang L., Fang L., Wang L., Li G., Xie B., Yang F.";"APIExample: An effective web search based usage example recommendation system for java APIs";"Programmers often learn how to use an API by studying its usage examples. There are many usage examples scattered in web pages on the Internet. However, it often takes programmers much effort to find out the desired examples from a large number of web pages by web search. This paper proposes a tool named APIExample that can extract usage examples for java APIs from web pages on the Internet and recommend them to programmers. Given a java API, the tool collects its related web pages from the Internet, extracts java code snippets and their surrounding descriptive texts embedded in the pages, then assembles them into usage examples for programmers. Furthermore, in order to help programmers capture more kinds of usages of the target API by browsing fewer examples, our tool clusters and ranks the listed examples based on the target API's usage. Besides, as a practical tool, APIExample provides multiple aspects of frequently-used information about using the target API in a concise user interface with friendly user experience. Two kinds of user-interaction style, a web search portal and an Eclipse plug-in, are now both publicly available. © 2011 IEEE.";"API, recommendation, usage example, web search"
"Lu H.K.";"Accessing cloud through API in a more secure and usable way";"A common method for accessing and managing cloud computing resources is through an Application Programming Interface (API). Each API request from an application must include a client authentication to the cloud service, which proves the possession of a secret key. Securing such keys is critical to the confidentiality, integrity, and availability of the data and services hosted in the cloud. Currently users manually handle these keys, a process that is neither secure nor user-friendly. Where to store the keys and how to access them are still security challenges especially for those applications that reside in the cloud themselves. Furthermore, keys are in clear text at least in a computer's memory. Attackers can find ways to recover them. This paper presents a solution to these problems by using portable security devices. The device securely exchanges keys with the cloud serve, securely stores the keys, and performs cryptographic computations using these keys for the client authentication. The user must have the device and authenticate to it in order use it. The solution enables a two-factor hierarchical security protection of the cloud computing resources. It not only enhances the security but also improves the usability. Copyright © 2011 SciTePress."
"Huang P.-Y., Jan J.-F.";"Comparison of Google maps API and openlayers for WebGIS development";"Many free, open source, web based, Geographic Information Systems (GIS) are shown to be an efficient and inexpensive way to disseminate feature rich and theme orientated map presentations. With web 2.0 technologies to creatively craft web user interfaces coupled with a strong versatile spatial processing backend, the end result of these freeware products are just as compelling to use in predefined use cases as any marketed brands. Putting aside the spatial analytical functionality, the tools to render maps and information ultimately determines the success of any GIS products. There are several free rendering software libraries for developers of WebGIS systems to choose from and the most popularly implemented are Google Maps API and OpenLayers. Both are JavaScript technologies that work seamlessly within the web browsers and can display layers of information at the users' discretion. But which technology should one use? For this report, we will compare and discuss the limitations and usability of these two technologies, and try to identify their usable domains.";"Google maps API, Open source, OpenLayers, WebGIS"
"Hosogai E., Mukai T., Jung S., Kowase Y., Bossard A., Xu Y., Ishikawa M., Kaneko K.";"A multilingual chat system with image presentation for detecting mistranslation";"We have designed and developed a multilingual chat system, MCHI (Multilingual Chat with Hint Images), which is based on machine translation and equipped with a presentation function of images related to the contents of the messages by utterers so that listeners are able to notice mistranslation. MCHI accepts English, French, Chinese, Japanese, Korean and Vietnamese languages. It uses the Google API to retrieve related images from the image posting site Flickr. As a result of evaluation experiment, we have observed that participants detected the mismatch of a translated message with its related image. According to the answers of participants for a questionnaire, it turned out that the usability of the MCHI system is good enough though the related images are not satisfactory.";"Image retrieval, Keywords, Machine translation, Morphological analysis"
"Stefik A., Siebert S., Stefik M., Slattery K.";"An empirical comparison of the accuracy rates of novices using the quorum, perl, and randomo programming languages";"We present here an empirical study comparing the accuracy rates of novices writing software in three programming languages: Quorum, Perl, and Randomo. The first language, Quorum, we call an evidence-based programming language, where the syntax, semantics, and API designs change in correspondence to the latest academic research and literature on programming language usability. Second, while Perl is well known, we call Randomo a Placebo-language, where some of the syntax was chosen with a random number generator and the ASCII table. We compared novices that were programming for the first time using each of these languages, testing how accurately they could write simple programs using common program constructs (e.g., loops, conditionals, functions, variables, parameters). Results showed that while Quorum users were afforded significantly greater accuracy compared to those using Perl and Randomo, Perl users were unable to write programs more accurately than those using a language designed by chance. © 2011 ACM.";"comprehension, intuitiveness, language reductionism, programming languages"
"Kocur L.A., Glotzbach R.J., Schulze D.G., Miller C.C.";"Work in progress - Development and integration of an online soil mapping Web application";"Mapping technologies are abundant on the Web as well as through boxed software, however, the ability to overlay ones own maps onto the surface in order to provide enriched detail is not found in most typical software. ""Integrating Spatial Educational Experiences (Isee) into Crop, Soil, and Environmental Science Curricula"" is a USDA-funded project focused on making soil data in the form of maps more accessible and easy-to-use for undergraduate students. The current solution integrates the Google Earth API, GeoWebCache, PHP, MySQL, and JavaScript in the form of a website. Although the differences in GIS software usability are generally unknown, the Isee prototype may serve as a viable model of an approach applicable at other universities. The purpose of the research is to collect quantitative data to determine if differences in software with various interfaces influence a student's satisfaction and performance. The ""Isee"" website will be among the compared software, in which students will attempt to answer questions based on the information they can find with the software. The researcher will record performance data quantitatively throughout the session. Afterwards, students will report preferences and perceptions in a survey. © 2011 IEEE.";"E-learning, Geovisualization, Soil science, Usability"
"Hosogai E., Mukai T., Jung S., Kowase Y., Bossard A., Xu Y., Ishikawa M., Kaneko K.";"A multilingual chat system with image presentation for detecting mistranslation";"We have designed and developed a multilingual chat system, MCHI (Multilingual Chat with Hint Images), which is based on machine translation and equipped with a presentation function of images related to the contents of the messages by utterers so that listeners are able to notice the mistranslation. MCHI accepts English, French, Chinese, Japanese, and Korean languages. It uses Google API to retrieve related images from the image posting site Flickr. As a result of evaluation experiment, we have observed that participants detected the mismatch of a translated message with its related image. According to the answers of participants for a question in a questionnaire, it turned out that the usability of the MCHI system is good enough though the related images are not satisfactory.";"Image retrieval, Keywords, Machine translation, Morphological analysis"
"Khan R.H., Ylitalo J., Ahmed A.S.";"OpenID authentication as a service in OpenStack";"The evolution of cloud computing is driving the next generation of internet services. OpenStack is one of the largest open-source cloud computing middleware development communities. Currently, OpenStack supports platform specific signatures and tokens for user authentication. In this paper, we aim to introduce a cloud platform independent, flexible, and decentralized authentication mechanism, using OpenID as an open-source authentication mechanism in OpenStack. OpenID allows a decentralized framework for user authentication. It has its own advantages for web services, which include improvements in usability and seamless Single-Sign-On experience for the users. This paper presents the OpenlD-Authentication-as-a-Service APIs in OpenStack for front-end GUI servers, and performs the authentication in the back-end at a single Policy Decision Point (PDP). Our implementation allows users to use their OpenID Identifiers from standard OpenTD providers and log into the Dashboard/Django-Nova graphical interface of OpenStack. © 2011 IEEE.";"Authentication, EC2API, OpenID, OpenStack, OS-API, Security"
"Dentler K., Cornet R., Ten Teije A., De Keizer N.";"Comparison of reasoners for large ontologies in the OWL 2 EL profile";"This paper provides a survey to and a comparison of state-of-the-art Semantic Web reasoners that succeed in classifying large ontologies expressed in the tractable OWL 2 EL profile. Reasoners are characterized along several dimensions: The first dimension comprises underlying reasoning characteristics, such as the employed reasoning method and its correctness as well as the expressivity and worst-case computational complexity of its supported language and whether the reasoner supports incremental classification, rules, justifications for inconsistent concepts and ABox reasoning tasks. The second dimension is practical usability: whether the reasoner implements the OWL API and can be used via OWLlink, whether it is available as Protégé plugin, on which platforms it runs, whether its source is open or closed and which license it comes with. The last dimension contains performance indicators that can be evaluated empirically, such as classification, concept satisfiability, subsumption checking and consistency checking performance as well as required heap space and practical correctness, which is determined by comparing the computed concept hierarchies with each other. For the very large ontology SNOMED CT, which is released both in stated and inferred form, we test whether the computed concept hierarchies are correct by comparing them to the inferred form of the official distribution. The reasoners are categorized along the defined characteristics and benchmarked against well-known biomedical ontologies. The main conclusion from this study is that reasoners vary significantly with regard to all included characteristics, and therefore a critical assessment and evaluation of requirements is needed before selecting a reasoner for a real-life application. © 2011 - IOS Press and the authors. All rights reserved.";"Biomedical ontologies, DL reasoners, OWL 2 EL, Semantic Web, SNOMED CT"
"Park P., Jung J., Huh B.";"Development of CAN-1394 automotive gateway system using designed modular software stack";"Recently, software diversity and reuse issues in automotive embedded software development have rapidly increased due to newly released technologies and its standardization. The modular design of software is essential to enhance software re-usability and portability. In this paper, we present a CAN-1394 Automotive gateway system implementation using modular designs of software stacks. We first study and summarize key specifications and their relationships in 1394 Automotive software stack development. Then, we present our modular implementation of software and hardware, which includes 1394 Automotive core stack components such as a communication driver and API library. In addition, we highlight essential functions of the implemented gateway for the 1394 Automotive backbone network and the CAN based in-vehicle network in detail. © 2011 IEEE.";"1394 automotive, CAN-1394 auto gateway, IDB-1394, IEEE 1394, Vehicle interface"
"Budnik L., Krawczyk H.";"Dynamic analysis of enterprise business scenarios";"DIES system for designing and improving enterprise business scenarios is proposed. Such scenarios are executed and monitored in an SOA environment. Many metrics are gathered, and strong/weak aspects are pointed out. DIES allows the improvement of a scenario's performance, quality, and usability. Due to technology-agnostic API the system supports any extensible business scenario technology, and it utilizes WS-BPEL standard and Apache ODE as its execution engine. A representative case study is considered, and evaluation and modification of the scenario is discussed. © 2011 IEEE.";"Business processes, Electronic enterprise, Metrics analysis, Quality improvement, Quality monitoring, WS-BPEL"
"Tseng L.C.-H.";"Developer-friendly annotation-based HTML-to-XML transformation technology";"Nowadays, the amount of information accessible on the web is huge. Although web users today expect a more integrated way to access information on the web, it is still rather difficult to ""integrate"" information from different web sites since most web pages are authored in HTML format, which is actually a presentation-oriented language and is usually considered unstructured. Today, there are many research works aiming at extracting information from web pages. Existing works typically transform the extracting results into structured or semi-structured data formats, thus other applications can further process the results to discover more useful information. Nevertheless, the unstructured nature of HTML makes the transformation process complex and can hardly be widely adopted. In this paper, an annotation-based HTML-to-XML ransformation technology is proposed. The mechanism is developed with both usability and simplicity in mind. With the proposed mechanism, ordinary web site developers simply add annotations to their web pages. Annotated web pages can then be processed by our software libraries and transformed into XML documents, which are machine-understandable. Software agents thus can be developed based on our technology. © 2011 ACM.";"annotation, information extraction, mashup, xml"
"De Vocht L., Softic S., Ebner M., Mühlburger H.";"Semantically driven social data aggregation interfaces for research 2.0";"We propose a framework to address an important issue in the context of the ongoing adoption of the ""Web 2.0"" in science and research, often referred to as ""Science 2.0"" or ""Research 2.0"". A growing number of people are linked via acquaintances and online social networks such as Twitter1allows indirect access to a huge amount of ideas. These ideas are contained in a massive human information flow [35]. That users of these networks produce relevant data is being shown in many studies [1][2][28][36]. The problem however lies in discovering and verifying such a stream of unstructured data items. Another related problem is locating an expert that could provide an answer to a very specific research question. We are using semantic technologies (RDF2,SPARQL3), common vocabularies(SIOC4, FOAF5,SWRC6) and Linked Data (DBpedia 7, GeoNames8, CoLinDa9) [3][4][5] to extract and mine the data about scientific events out of context of microblogs. Hereby we are identifying persons and organization related to them based on entities of time, place and topic. The framework provides an API that allows quick access to the information that is analyzed by our system. As a proof-of-concept we explain, implement and evaluate such a researcher profiling use case. It involves the development of a framework that focuses on the proposition of researches based on topics and conferences they have in common. This framework provides an API that allows quick access to the analyzed information. A demonstration application: ""Researcher Affinity Browser"" shows how the API supports developers to build rich internet applications for Research 2.0. This application also introduces the concept ""affinity"" that exposes the implicit proximity between entities and users based on the content users produced. The usability of a demonstration application and the usefulness of the framework itself are investigated with an explicit evaluation questionnaire. This user feedback led to important conclusions about successful achievements and opportunities to further improve this effort.";"Linked data, Microblogs, Profiling, Research 2.0, Science 2.0, Semantic, Social media, Twitter, Web 2.0, Web mining"
"Khatoon S., Mahmood A., Li G.";"An evaluation of source code mining techniques";"This paper reviews the tools and techniques which rely only on data mining methods to determine patterns from source code such as programming rules, copy paste code segments, and API usage. The work provides comparison and evaluation of the current state-of-the-art in source code mining techniques. Furthermore it identifies the essential strengths and weaknesses of individual tools and techniques to make an evaluation indicative of future potential. The pervious related works only focus on one specific pattern being mined such as special kind of bug detection. Thus, there is a need of multiple tools to test and find potential information from software which increase cost and time of development. Hence there is a strong need of tool which helps in developing quality software by automatically detecting different kind of bugs in one pass and also provides code reusability for the developers. © 2011 IEEE.";"API usage, Copy-paste code, literature review, Programming rule, Source code mining"
"Kawagoi K., Tominaga H.";"Library management system in a laboratory scale cooperated with book seller sites";"A laboratory in an engineering college possesses many books about technology and science. While members in the laboratory mainly use the books, outside students sometimes borrow them. Members must manage the collection by oneself. We propose a library management system for a laboratory scale. The system cooperates with some book seller sites. It reads an ISBN of a book by a barcode reader to acquire the information by Amazon Web service. It adopts an IC chip reader for user check with a student card. The system offers purchase helping functions. It gathers book requests of members and tells a teacher to buy by a cart method of API. It applies adequate lending rules according to access permission. We also consider learning support functions, especially for books about information engineering. A user who have read a book submits his comment for understanding. He may upload his program as sample of practice. The following users can access restrictively for the educational purpose. We developed a prototype of the system, which has some database and basic functions. We carried out an experiment of user operation for usability evaluation to get some ideas for improvement. © 2011 IEEE.";"Laboratory groupware, Learning support, Library management system, Web-based system"
"Thamrin N.M., Ahmad I., Hani M.K.";"A secure field programmable gate array based System-on-Chip for Telemedicine application";"In Telemedicine, confidential information is transferred through an unsecure channel from one party to another. In this paper, a field programmable gate array (FPGA) based approach to protect the data in the Telemedicine system, the mySECURE II is developed. There are two security schemes on a crypto System-on-Chip (SoC) proposed in this paper namely hybrid encryption scheme and Rivest-Shamir-Adleman (RSA) based digital signature scheme. It focuses on the development of 128-bit Advanced Encryption Standard (AES) subsystem, 2048-bit RSA crypto subsystem and Secure Hash Algorithm (SHA-1) crypto subsystem. In AES encryption and RSA crypto subsystems, the strength of these cryptosystems relies on keys. Therefore, a hybrid random number generator (RNG) is designed to provide on-chip key generation operation in this work. The crypto SOC is designed using hardware-software codesign technique. The hardware subsystems design are implemented on Altera Stratix 1S40F780C5 FPGA development board and integrated with Nios II processor to form a complete cryptosystem in System of Programmable Chip (SoPC) environment. The software design consists of the development of device drivers for hardware subsystem communication, and implementation of Cryptographic Service Provider (CSP), serves as the Application Programming Interface (API) in host PC. As a result, a prototype has been developed to test the functionality of the crypto hardware subsystem as well as the usability of the CSP. © 2011 IEEE.";"Cryptographic system, Information security, Telemedicine"
"Hou D., Li L.";"Obstacles in using frameworks and APIs: An exploratory study of programmers' newsgroup discussions";"Large software frameworks and APIs can be hard to learn and use, impeding software productivity. But what are the specific challenges that programmers actually face when using frameworks and APIs in practice? What makes APIs hard to use, and what can be done to alleviate the problems associated with API usability and learnability? To explore these questions, we conducted an exploratory study in which we manually analyzed a set of newsgroup discussions about specific challenges that programmers had about a software framework. Based on this set of data, we identified several categories of obstacles in using APIs. We discussed what could be done to help overcome these obstacles. © 2011 IEEE.";"APIs, AWT/Swing, Case Studies, Frameworks, Usability"
"Pankratius V., Knittel F., Masing L., Walser M.";"OpenMPspy: Leveraging quality assurance for parallel software";"OpenMP is widely used in practice to create parallel software, however, software quality assurance tool support is still immature. OpenMPspy introduces a new approach, with a short-term and a long-term perspective, to aid software engineers write better parallel programs in OpenMP. On the one hand, OpenMPspy acts like an online-debugger that statically detects problems with incorrect construct usage and which reports problems while programmers are typing code in Eclipse. We detect simple slips as well as more complex anti-patterns that can lead to correctness problems and performance problems. In addition, OpenMPspy can aggregate statistics about OpenMP language usage and bug patterns from many projects. Insights generated from such data help OpenMP language designers improve the usability of constructs and reduce error potential, thus enhancing parallel software quality in the long run. Using OpenMPspy, this paper presents one of the first detailed empirical studies of over 40 programs with more than 4 million lines of code, which shows how OpenMP constructs are actually used in practice. Our results reveal that constructs believed to be frequently used are actually rarely used. Our insights give OpenMP language and compiler designers a clearer picture on where to focus the efforts for future improvements. © 2011 Springer-Verlag."
"Zhang H., Wu G., Chow K., Yu Z., Xing X.";"Detecting resource leaks through dynamical mining of resource usage patterns";"Resource management is crucial to software productions. Resources must be carefully acquired and released, or a resource leak might occur. For open source projects, resource leaks can be easily introduced during code check-in, and it is laborious to review, identify, report, and fix such leaks. Recently, there has been a growing interest in data mining API usage patterns to discover potential bugs such as resource leaks. However, the usage patterns mined are specific to a certain library, which cannot be applied to detect bugs in other libraries. In this paper, we present an idea called MODE, Mine Once, Detect Everywhere, to address the universality of such patterns, and use them to detect potential resource leaks automatically before code check-in. We propose an efficient algorithm to record the most valuable API calls that are related to resource usage during program execution, and mine resource usage patterns from the traces with a sequence miner. To verify the effectiveness of the patterns, experiments are given to use them to detect real resource leaks in large open source projects. © 2011 IEEE.";"Data Mining, Dynamical Analysis, Resource Leak Detection"
"Ameddah H., Assas M.";"Bio-CAD reverse engineering of free-form surfaces by planar contours";"In this paper, an interactive application tool has been developed for creating 3D models of anatomical organs and other body structures from 2D medical imaging data. 3D models are generated by using reverse engineering algorithm and Planar Contour method by SolidWorks developed in Visual Basic Language. The research includes transferring Computed Tomography (CT) and Magnetic Resonance Imaging (MRI) images into digital matrixes, entering digital matrixes into SolidWorks environment, building feature library for 3D reconstruction, creating medical rapid prototyping models. 3D reconstruction is created by edge configuration generation and triangulated cube configuration generation in capturing section contour points from medical image per slice, creating B-spline curve with the control points in each layer, producing solid model construction in Planar Contours method. Medical rapid prototyping models are performed in SolidWorks. The results of this paper are to develop image processing 3D visualization in SolidWorks Application Programming Interface (API) using Visual Basic Language. The results reveal that the accuracy of 3D reconstruction is acceptable. © 2011 CAD Solutions, LLC.";"Nurbs, Point cloud processing, Reverse engineering"
"Benmerar T.Z., Boumghar F.O.";"Toward a cloud architecture for medical imagery grid applications: The Acigna-G project";"Acigna-G is a new Grid Computing platform we propose, for hosting and interacting with GNU/Linux Grid applications through a web portal, without or with a minimal API use. It aims to provide a convenient Cloud Service for Medical Imagery Grid applications. It extends our GIC architecture with an implementation of a light version of the Virtually-distribution Parallel Architecture and the Multi-level Services architecture that permit the deployment of distributed Grid applications onto our platform. We propose these architecture as solutions to achieve both the convenience of PaaS Cloud services and the richness of Grid applications. We show how we deploy a MAS segmentation algorithm for Medical Imagery onto our Acigna-G platform. © 2011 IEEE."
"Hofmeyr S., Colmenares J.A., Iancu C., Kubiatowicz J.";"Juggle: Proactive load balancing on multicore computers";"We investigate proactive dynamic load balancing on multicore systems, in which threads are continually migrated to reduce the impact of processor/thread mismatches to enhance the flexibility of the SPMD-style programming model, and enable SPMD applications to run efficiently in multiprogrammed environments. We present Juggle, a practical decentralized, user-space implementation of a proactive load balancer that emphasizes portability and usability. Juggle shows performance improvements of up to 80% over static balancing for UPC, OpenMP, and pthreads benchmarks. We analyze the impact of Juggle on parallel applications and derive lower bounds and approximations for thread completion times. We show that results from Juggle closely match theoretical predictions across a variety of architectures, including NUMA and hyper-threaded systems. We also show that Juggle is effective in multiprogrammed environments with unpredictable interference from unrelated external applications. © 2011 ACM.";"operating systems, parallel programming, proactive load balancing"
"Dross C., Filliâtre J.-C., Moy Y.";"Correct code containing containers";"For critical software development, containers such as lists, vectors, sets or maps are an attractive alternative to ad-hoc data structures based on pointers. As standards like DO-178C put formal verification and testing on an equal footing, it is important to give users the ability to apply both to the verification of code using containers. In this paper, we present a definition of containers whose aim is to facilitate their use in certified software, using modern proof technology and novel specification languages. Correct usage of containers and user-provided correctness properties can be checked either by execution during testing or by formal proof with an automatic prover. We present a formal semantics for containers and an axiomatization of this semantics targeted at automatic provers. We have proved in Coq that the formal semantics is consistent and that the axiomatization thereof is correct. © 2011 Springer-Verlag Berlin Heidelberg.";"annotations, API usage verification, automatic provers, axiomatization, Containers, iterators, SMT, verification by contracts"
"Lämmel R., Pek E., Starek J.";"Large-scale, AST-based API-usage analysis of open-source Java projects";"Research on API migration and language conversion can be informed by empirical data about API usage. For instance, such data may help with designing and defending mapping rules for API migration in terms of relevance and applicability. We describe an approach to large-scale API-usage analysis of open-source Java projects, which we also instantiate for the Source-Forge open-source repository in a certain way. Our approach covers checkout, building, tagging with metadata, fact extraction, analysis, and synthesis with a large degree of automation. Fact extraction relies on resolved (type-checked) ASTs. We describe a few examples of API-usage analysis, they are motivated by API migration. These examples are concerned with analysing API footprint (such as the numbers of distinct APIs used in a project), API coverage (such as the percentage of methods of an API used in a corpus), and framework-like vs. class-library-like usage. © 2011 ACM."
"De Luca V., Epicoco I., Lezzi D., Aloisio G.";"A web API framework for developing grid portals";"In this paper we describe a grid problem solving environment we developed for financial applications. We based its development on a portlet framework we have specifically developed and on a set of Web APIs that encapsulate all grid control and computation logic. Even though nowadays grid portals are characterized by various and different features and are implemented in very differing programming languages and technologies, we thought that they have many structural aspects in common. For this reason we decided to design and implement a set of Grid specific Web APIs, that we called GRB WAPI. Through them, a portal developer will not have to deal with grid technical details and will be able to manage a high level design. A portal developer will be able to concentrate on some other aspects that concern presentation, such as portal usability and functionality. We discarded the idea of developing a traditional library in order to free portal developers from a particular implementation technology. Thanks to this choice the portal presentation logic can be implemented in any web technology and can be on a different server. © 2011 Published by Elsevier Ltd.";"Grid portals, Grid problem solving environment, Portlet, REST, Web API"
"Gerken J., Jetter H.-C., Zöllner M., Mader M., Reiterer H.";"The concept maps method as a tool to evaluate the usability of APIs";"Application programming interfaces (APIs) are the interfaces to existing code structures, such as widgets, frameworks, or toolkits. Therefore, they very much do have an impact on the quality of the resulting system. So, ensuring that developers can make the most out of them is an important challenge. However standard usability evaluation methods as known from HCI have limitations in grasping the interaction between developer and API as most IDEs (essentially the GUI) capture only part of it. In this paper we present the Concept Map method to study the usability of an API over time. This allows us to elicit the mental model of a programmer when using an API and thereby identify usability issues and learning barriers and their development over time. Copyright 2011 ACM.";"Api usability, Concept maps, Evaluation method, Longitudinal"
"Hsu S.-K., Lin S.-J.";"MACs: Mining API code snippets for code reuse";"We apply data mining to source code projects to guide developers through related API usage patterns: ""Developers who code the program statement also code."" Given a set of source code files, the mined association rules suggest related code snippets to form the components of object-oriented programs. The mined sequential rules predict likely additional API sequences within a method. After an initial program statement is given, our MACs prototype can correctly predict useful related API code snippets. In our evaluation, we present two studies investigating the usefulness of MACs in software development tasks. One study evaluated the utility of MACs's association pattern recommendations. The other evaluated usefulness of sequential pattern recommendations, and both drew from a sample of eight source code projects from SourceForge.net. Our experimental evaluation shows that MACs has significant potential to assist developers, especially API newcomers, and provides an alternative method for code reuse. © 2010 Elsevier Ltd. All rights reserved.";"API usage pattern, Code reuse, Mining software repositories"
"Devriese D., Piessens F.";"Information flow enforcement in monadic libraries";"In various scenarios, there is a need to expose a certain API to client programs which are not fully trusted. In cases where the client programs need access to sensitive data, confidentiality can be enforced using an information flow policy. This is a general and powerful type of policy that has been widely studied and implemented. Previous work has shown how information flow policy enforcement can be implemented in a lightweight fashion in the form of a library. However, these approaches all suffer from a number of limitations. Often, the policy and its enforcement are not cleanly separated from the underlying API, and the user of the API is exposed to a strongly and unnaturally modified interface. Some of the approaches are limited to functional APIs and have difficulty handling imperative features like I/O and mutable state variables. In addition, this previous work uses classic static information flow enforcement techniques, and does not consider more recent dynamic information flow enforcement techniques. In this paper, we show that information flow policies can be enforced on imperative-style monadic APIs in a modular and reasonably general way with only a minor impact on the interface provided to API users. The main idea of this paper is that we implement the policy enforcement in a monad transformer while the underlying monadic API remains unaware and unmodified. The policy is specified through the lifting of underlying monad operations. We show the generality of our approach by presenting implementations of three important information flow enforcement techniques, including a purely dynamic, a purely static and a hybrid technique. Two of the techniques require the use of a generalisation of the Monad type class, but impact on the API interface stays limited. We show that our technique lends itself to formal reasoning by sketching a proof that our implementation of the static technique is faithful to the original presentation. Finally, we discuss fundamental limitations of our approach and how it fits in general information flow enforcement theory. © 2011 ACM.";"Information flow enforcement, Monad transformer, Monads, Parameterised monads"
"Membarth R., Hannig F., Teich J., Körner M., Eckert W.";"Frameworks for multi-core architectures: A comprehensive evaluation using 2D/3D image registration";"The development of standard processors changed in the last years moving from bigger, more complex, and faster cores to putting several more simple cores onto one chip. This changed also the way programs are written in order to leverage the processing power of multiple cores of the same processor. In the beginning, programmers had to divide and distribute the work by hand to the available cores and to manage threads in order to use more than one core. Today, several frameworks exist to relieve the programmer from such tasks. In this paper, we present five such frameworks for parallelization on shared memory multi-core architectures, namely OpenMP, Cilk++, Threading Building Blocks, RapidMind, and OpenCL. To evaluate these frameworks, a real world application from medical imaging is investigated, the 2D/3D image registration. In an empirical study, a fine-grained data parallel and a coarse-grained task parallel parallelization approach are used to evaluate and estimate different aspects like usability, performance, and overhead of each framework. © 2011 Springer-Verlag.";"2D/3D Image Registration, Cilk++, Evaluation, Frameworks, Medical Imaging, OpenCL, OpenMP, Parallelization, RapidMind, Threading Building Blocks"
"Leal J.P., Dias H.";"A framework to develop meta web interfaces";"Web interfaces are used nowadays for virtually every kind of computer application. The proliferation of web interfaces created the need to collect and analyze data on how users interact with them. Many web applications used for this purpose rely on what can be called a meta web interface. Meta web interfaces are used for different purposes but they share a set of common features: a web interface based on the subject interface with a second layer interface for collecting data, a central repository for persisting the collected data, and an API for retrieving aggregated data on user interaction. This paper describes Z-Web - a framework for developing meta web interfaces that provides these three features. To create a second layer in the meta web interface a Z-Web server is placed as a proxy between the web client and the subject web server and injects modifications while forwarding HTTP requests. These modifications are typically JavaScript libraries that collect and store data related to user interaction. The framework caches the pages it proxies and provides persistent storage for the collected data. An application interface (API) makes this data available to client application supported by Z-Web. This paper presents an overview of Z-Web, with the general architecture of a web application based on this framework, and describes the design and implementation issues of its main components. Two systems developed with Z-Web are also presented to evaluate the applicability of the framework and its overhead when compared with similar systems.";"Digital media, Usability, User interaction data collection, Web adaption, Web frameworks"
"Iwai G., Kawai Y., Sasaki T., Watase Y.";"SAGA-based user environment for distributed computing resources: A universal grid solution over multi-middleware infrastructures";"This paper demonstrates practical applications based on SAGA -A Simple API for Grid Applications- for distributed computing resources over multi-middleware infrastructures. SAGA provides a high-level programming interface that bridges between applications and Grids as well as local schedulers such as PBS. At the Computing Research Center of KEK, we are playing a role to support not only on-site users, but also domestic university groups in the High Energy and Nuclear Physics (HENP) community. In order to provide a more effective and practical client environment to users, we have developed Grid-adaptive applications based on SAGA as a part of activity in the REsources liNKage for E-scIence (RENKEI) for the general purpose e-Infrastructure using National Research Grid Initiative (NAREGI) middleware. We present the technical details for the user environment demonstrator and discuss the usability by real HENP applications.";"Multi-middleware interface, SAGA"
"Nguyen H.A., Nguyen T.T., Wilson Jr. G., Nguyen A.T., Kim M., Nguyen T.N.";"A graph-based approach to API usage adaptation";"Reusing existing library components is essential for reducing the cost of software development and maintenance. When library components evolve to accommodate new feature requests, to fix bugs, or to meet new standards, the clients of software libraries often need to make corresponding changes to correctly use the updated libraries. Existing API usage adaptation techniques support simple adaptation such as replacing the target of calls to a deprecated API, however, cannot handle complex adaptations such as creating a new object to be passed to a different API method, or adding an exception handling logic that surrounds the updated API method calls. This paper presents LIBSYNC that guides developers in adapting API usage code by learning complex API usage adaptation patterns from other clients that already migrated to a new library version (and also from the API usages within the library's test code). LIBSYNC uses several graph-based techniques (1) to identify changes to API declarations by comparing two library versions, (2) to extract associated API usage skeletons before and after library migration, and (3) to compare the extracted API usage skeletons to recover API usage adaptation patterns. Using the learned adaptation patterns, LIBSYNC recommends the locations and edit operations for adapting API usages. The evaluation of LIBSYNC on real-world software systems shows that it is highly correct and useful with a precision of 100% and a recall of 91%. © 2010 ACM.";"API evolution, API usage adaptation, API usage model, Program differencing, Software evolution"
"Nasehi S.M., Maurer F.";"Unit tests as API usage examples";"t This study aims to find out if API unit tests can provide good usage examples, and if so, what prevents developers from finding and using those examples. The results of an experiment we performed with two groups of developers showed that unit tests can be very helpful, especially when the task is complicated and involves multiple classes and methods. Well-written tests proved to be a good source of examples, but finding the relevant examples using the standard tools might be very difficult. We propose to supplement the standard API documentation with relevant examples taken from the unit tests. To further improve the learnability of the API, presentation of the documentation and examples has to be tailored in a way that separates or hides advanced usage scenarios from the commonly used ones. © 2010 IEEE.";"API, Code example, Documentation, Unit test, Usability"
"Pradel M., Bichsel P., Gross T.R.";"A framework for the evaluation of specification miners based on finite state machines";"Software maintenance tasks, such as testing and program understanding, can benefit from formal specifications that describe how a program should use an API. Recently, there has been increasing interest in specification miners that automatically extract finite state specifications of method ordering constraints from existing software. However, comparing different mining approaches is difficult, because no common ground to evaluate the effectiveness of specification miners has been established yet. We present a framework for evaluating to which extent specification miners find valid finite state descriptions of API usage constraints. The framework helps in creating reference specifications and includes metrics to compare mined specifications to the reference specifications. The metrics are tailored for evaluating specification miners and account for imprecision and incompleteness in mined specifications. We use the framework to compare the effectiveness of three mining approaches and to show their respective benefits. © 2010 IEEE.";"Metrics/measurement, Mining, Requirements/specifications"
"Kawai Y., Iwai G., Sasaki T., Watase Y.";"SAGA-based file access application over multi-filesystem middleware";"This paper describes practical file access applications based on SAGA -A Simple API for Grid Applications- for distributed storage resources over multi-file-system middleware. SAGA provides a high-level programming interface to bridge between network file-system middleware as well as accessing a local file-system. The Computing Research Center of KEK uses many data files from physics experiments. For example, large numbers of bubble chamber image files are shared between KEK and King's College in UK. Our research problem involves displaying a single bubble chamber image file that is divided and stored in the different kinds of file-systems. We use the two types of file-systems that are iRODS -The Integrated Rule-Oriented Data System- and Gfarm -Grid Data Farm-. To access the middleware, we are developing the SAGA adaptors for the iRODS and Gfarm file-systems. We present the technical details for the user environments and show the usability with real bubble chamber image files. Copyright 2010 ACM.";"Grid middleware, Multi file system, SAGA"
"Wu Y.-C., Mar L.W., Jiau H.C.";"CoDocent: Support API usage with code example and API documentation";"API documentation and code example are two major resources to support API usage. To find the best way to use APIs within specific programming tasks, an effective strategy to link related APIs becomes critical. Currently, many code search engines have been proposed to solve this issue. Through those search results, programmers must manually traverse across all API documents to learn the referred API calls. To ensure the productivity in the style of programming with APIs, this work provides CoDocent to help programmers review code examples found by search engines. For each found code example, CoDocent can automatically link related API documents to provide diagrams as abstractions to reflect the semantics of API calls. Two evaluations are conducted to show the effectiveness of CoDocent in investigating and adapting API calls from code examples. © 2010 IEEE.";"API documentation, Code example, Programming with APIs"
"Bajracharya S.K., Ossher J., Lopes C.V.";"Leveraging usage similarity for effective retrieval of examples in code repositories";"Developers often learn to use APIs (Application Programming Interfaces) by looking at existing examples of API usage. Code repositories contain many instances of such usage of APIs. However, conventional information retrieval techniques fail to perform well in retrieving API usage examples from code repositories. This paper presents Structural Semantic Indexing (SSI), a technique to associate words to source code entities based on similarities of API usage. The heuristic behind this technique is that entities (classes, methods, etc.) that show similar uses of APIs are semantically related because they do similar things. We evaluate the effectiveness of SSI in code retrieval by comparing three SSI based retrieval schemes with two conventional baseline schemes. We evaluate the performance of the retrieval schemes by running a set of 20 candidate queries against a repository containing 222,397 source code entities from 346 jars belonging to the Eclipse framework. The results of the evaluation show that SSI is effective in improving the retrieval of examples in code repositories. © 2010 ACM.";"api usage, code search, software information retrieval, ssi, structural semantic indexing"
"Zeller A.";"Learning from 6,000 projects: Mining models in the large";"Models-abstract and simple descriptions of some artifact-are the backbone of all software engineering activities While writing models is hard, existing code can serve as a source for abstract descriptions of how software behaves. To infer correct usage, code analysis needs usage examples, though, the more, the better. We have built a lightweight parser that efficiently extracts API usage models from source code-models that can then be used to detect anomalies. Applied on the 200 million lines of code of the Gentoo Linux distribution, we would extract more than 15 million API constraints, encoding and abstracting the ""wisdom of Linux code"" © 2010 IEEE."
"Lozano A., Kellens A., Mens K., Arevalo G.";"Mining source code for structural regularities";"During software development, design rules and contracts in the source code are often encoded through regularities, such as API usage protocols, coding idioms and naming conventions. The structural regularities that govern a program can aid in comprehension and maintenance of the application, but are often implicit or undocumented. Tool support for extracting these regularities from the source code can provide developers useful insights. But building such tool support is not trivial, in particular, because the informal nature of regularities results in frequent deviations and exceptions to these regularities. We propose an automated approach, based on association rule mining, to discover the structural regularities that govern the source code of a software system. We chose this technique because of its resilience to exceptions. In general, tool support for mining regularities tends to discover a huge amount of rules, making interpretation of the results hard and time-consuming. To ease the interpretation, we reduce the results to a minimal canonical form, and group them to obtain a more rational description of the discovered regularities. As an initial feasibility study of our approach, we applied it on two open-source systems, namely IntensiVE (Smalltalk) and FreeCol (Java). © 2010 IEEE."
"O'Callaghan P.";"The API walkthrough method: A lightweight method for getting early feedback about an API";"We propose a method for evaluating the usability of an Application Programming Interface (API) in the context of MATLAB, a high-level programming language. The primary goal is to evaluate whether the participant can develop an accurate mental model of the API based on the code alone. Like traditional usability testing, this method takes place in a lab setting with a facilitator and observers, and a single participant is exposed to a prototype. Unlike traditional usability testing, the prototype is a static text document containing a series of programmatic statements. Rather than performing a task, the participant ""walks through"" the code line by line in an attempt to gain understanding of the system. Using standard usability testing protocols, the facilitators are able to assess whether the participant understands the API, as well as gather preference data between two designs. © 2010 ACM.";"API, API evaluation, API usability, Programming interface, Programming languages, Usability, Usability testing"
"Zibin Y.";"Jury API: Secure client-side-only multiplayer gaming API";"Multiplayer gaming platforms (such as Come2Play, Skype, Nonoba, Oberon) offer game developers an API to develop new games. Having a secure API is critical to prevent hackers from unlawfully winning a game. Until today, to have a secure API, a developer had to write a server-side extension that determines the game outcome. However, a server-side extension is cumbersome to write (because you have to master two programming languages: for the client- and server-side), error-prone, hard to debug, and risky for the gaming platform that runs 3rd party code on its servers. This paper presents the first Secure client-side-only API (for short JuryAPI), i.e., the API is secure (the game outcome cannot be changed by hackers) and the API uses only client-side code (without any server-side extensions). JuryAPI mimics real-life games in which each player verifies that other players follow the game rules. In case of disagreement among the players, the server convenes a jury that finds the hacker. Using JuryAPI, one can develop secure multiplayer games using only client-side code, without using any server-side extensions. JuryAPI is an open-source standard developed by the multiplayer gaming company Come2Play, with an open-source flash emulator1. Come2Play freely hosts 3 rd party flash games and shares the revenues with the game developers."
"Jung G., Lee B.";"Analysis on social network adoption according to the change of network topology: The impact of ""Open API"" to adoption of facebook";"A social network service is one of the most prospering social media in the Web 2.0 era. In SNSs, a massive number of people make online friends and share their interests. In May 2007, Facebook made an announcement of ""Open API"" policy, which allows a third-party to create applications in Facebook. After ""Open API,"" users of Facebook can utilize various interactions other than just messaging. This led to radical increase in user growth of Facebook and threatened Myspace, which was the top SNS at that time. This innovative move gathered an interest of how ""Open API"" affects interactions in social networks. The main objective of our research is to analyze the relationship between the growth of social network adoption and network topology. For this issue, our study conducts both analytical and empirical models. First of all, we adopt the concept of Metcalfe's and Reed's law to model the growth pattern of social network under duopoly competition of two SNSs. Then we apply the growth functions to the empirical analysis. We collect web traffic data of Facebook and Myspace from Alexa and test the structural change after the adoption of ""Open API"" policy. The result of the analytical model shows that social network adoption follows a quadratic growth under Metcalfe's law and an exponential growth under Reed's law. The result also shows the conditions for a SNS to take all new adopters in the market. If the SNS follows Reed's law, it can absorb all new adopters even if that particular SNS is a newcomer in the market. The empirical result confirms that there exists a significant difference in the growth pattern between, before and after ""Open API."" This implies that ""Open API"" transformed Facebook one-to-one communication network into a group forming network. Eventually, this transition increases potential connectivity in social network and leads to exponential growth of social network adoption. Copyright 2012 ACM.";"Network adoption, Network value, Social network"
"Suikkola V.";"Open exposure of telco capabilities: Identification of critical success factors for location-based services in open telco";"As of late, open exposure of telco capabilities has been a target of interest - much due to the success of open application programming interfaces on the Internet services market. Due to the innate ability of the mobile networks to know its users' locations, the location-based services market is an especially interesting area from the operator point of view. Operators could possibly create success in this market by implementing the Open Telco framework, however, key service areas and critical success factors have not been identified yet. This paper reviews the existing literature on Open Telco, location-based services, and network-based positioning technologies and identifies the key location-based service application areas for network-based positioning. Based on this analysis, we present a list of critical success factors for location-based services in Open Telco. The findings indicate that the key application areas in network-positioning based location-based services are social networking, information, and productivity services. The critical success factors were found to be standard interfaces, operator cooperation, and the handling of privacy, security, as well as usability issues with location-based services. © 2010 IEEE.";"Location-based services, Open API, Open telco framework, Positioning technologies"
"Ramkumar S., Kumar S., Shiroor R.";"Process centric guidance and tools for next generation network services API design";"The growth in the number and variety of Network Application Programming Interfaces (APIs) like location, messaging, entertainment, personal storage and computing available to developers today and their rapid evolution has led to increased complexity of use in terms of adoption and keeping up with the incremental changes. Operators thus face an increasing need to roll out new Network Service APIs effectively and seamlessly. Well designed APIs not only make user adoption easier but also increase the probability that the user of the API will choose the Network Services API over other competing APIs in areas where standards are not available. The success Network Services APIs will to a large extent drive the external business case for Service Delivery Platforms in IMS in terms of ease of creation of new services leveraging operator services and capabilities. There is a lack of process centric guidance targeted at all important stakeholders like architects, designers, testers, the governance bodies and marketing personnel for the design of effective Network Services APIs which can help alignment with initiatives like SOA. This paper attempts to remedy the same by providing process centric and empirically grounded guidance for their creation and usage based on the practitioner engagements with leading operators and provides tools for automation. ©2010 IEEE.";"Guidance, IMS, Network services API design, Process centric, SDP, Service oriented computing, SOA, SOAP, Standards, Strategy, Tools, Usability, Web services REST, WSDL"
"[No author name available]";"Evaluation and Usability of Programming Languages and Tools, PLATEAU'10";"The proceedings contain 8 papers. The topics discussed include: using CogTool to model programming tasks, user evaluation of correctness conditions: a case study of cooperability, the API walkthrough method, toward transforming freely available source code into usable learning materials for end-users, staking claims: a history of programming language design claims and evidence, hard-to-answer questions about code, comparing the usability of library vs. language approaches to task parallelism, and GoHotDraw: evaluating the go programming language with design patterns."
"[No author name available]";"2010 6th Central and Eastern European Software Engineering Conference, CEE-SECR 2010";"The proceedings contain 36 papers. The topics discussed include: adaptation of SCRUM methodology to company business processes, automating programming via concept mining, probabilistic reasoning over semantic knowledge base of SE domain, clone detection: why, what and how?, comparison of two models of success prediction in software development projects, conceptual models of heterogeneous data representation, defect detection for multithreaded programs with semaphore-based synchronization, effective communications for small outsourcing software-engineering projects, expert system for software source code quality analysis, header-driven generation of sanity API tests for shared libraries, implementation by capture with executable UML, implementing usability methods into CMMI-compliant software development process, integrating quality, quality in use, actual usability and user experience, and interactive 3D scene modeling and visualization system."
"Carstoiu B., Carstoiu D.";"Web4Desktop, a framework for improving the usability of web applications";"The cloud computing model leads to the increased penetration of the web applications in the office environment. Designed in many cases to replace traditional desktop software, web applications still lack many of the valuable features present on the desktop that increase usability and productivity. Due to the highly isolated design of the browser, it is currently impossible for web applications to communicate with desktop environment, which usually means sending messages or receiving event notifications. This is often required in order to let the person using the application know about the important events happening in the minimized browser window. By contrast traditional applications can take the control of the desktop at any time. The paper introduces the Web4Desktop framework, a browser/client based architecture designed to overcome these limitations by proving a secure infrastructure that allows web applications to communicate with any desktop software implementing the Web4Desktop API. The framework can be utilized to add desktop integration to existing web applications, a step that requires only minimal changes in the web application's code and greatly improve the user experience because these applications will start to behave more like desktop software. © 2010 Springer-Verlag.";"browser plug-in, business and office software, Cloud computing, Java Script, web applications, web security, web usability"
"Maaser M., Ortmann S.";"Remote medical treatment at home using the Java Mobile Sensor API";"Since wireless sensor networks are successfully deployed in real life scenarios, applications in medical health-care, structural control, homeland security etc. become feasible. In those envisioned applications, easy maintenance and usability become crucial to staff members, e.g., to doctors or nurses. Not only for widespread distribution of hundreds of sensors, but also in tele-medical applications, remotely-controlled sensing and maintenance without direct access to sensors is required. For this purpose we present a middleware abstraction based on the standard Java Mobile Sensor API (JSR-256). It allows transparent access to sensor measurements, sensor information and maintenance data, which appear as local sensor resources to the user even if the sensors are connected via network. Hence, the user neither requires technical skills nor location information to request sensor data. This paper gives an architectural and functional overview of our middleware within the context of telemedicine. We demonstrate how our middleware approach supports patient monitoring for pre- and post-operative treatment at home. ©2010 IEEE."
"Harris W.";"Functional programming at Freebase";"Freebase is a community-built, online database of facts and information, developed by Metaweb Technologies in San Francisco, California [1]. Freebase uses a proprietary graph database technology to store and query a network of over 12 million interrelated topics involving several hundred million individual graph relations. Third-party applications are free to query and update the Freebase database, and do so using the Metaweb Query Language, MQL [2]. MQL queries are expressed with a JSON-based template language which makes them easy to integrate into web applications, particularly the client-side portion which is processed with JavaScript?. Metaweb's first-generation MQL implementation was written as a Python-based middle-tier application that dynamically translates JSON-based queries into a low-level proprietary graph query language and networking protocol [3]. The low-level query language was designed for efficiency rather than for direct usability, and significant effort is required to translate between the two languages. Analysis of the entire Freebase application stack has revealed that as much time was being spent in the MQL query and result translation process as was being spent actually resolving the low-level graph queries. Much of this was attributed to the memory-intensive architecture of the translator, but a large portion was attributed to overhead inherent in the Python 2.6 runtime. We have undertaken developing a second-generation MQL translator written in Ocaml and drawing on a number of pure functional techniques. The core language translation process is expressed in terms of embedded language that implements the graph query protocol. This embedded language is used for both for static queries, e.g. for schema lookups, and for expressing the dynamic translation of MQL queries. The translator operates as a server and uses Lwt (Lightweight Threads library [4]) to interleave both client and graph database requests. A web services API and monitoring console have been developed using the Ocsigen web server and associated Eliom infrastructure [5]. The performance of our reimplemented MQL translator service is very encouraging. One process can sustain over an order of magnitude more simultaneous MQL requests, and service each request in a small fraction of the time consumed by the Python implementation. Moreover, due to the asynchronous nature of the underlying Lwt I/O subsystem, a single processor core can handle several times the capacity of an entire multi-core server machine running the former Apache/WSGI/Python [6] infrastructure. In addition to describing the MQL translator system, I would like to discuss the underlying mechanism by which it batches fragments of I/O requests together into single larger protocol messages, thereby minimizing communication overhead with the underlying graph database. This technique closely resembles monads typically used in functional programming, but also provides some of the benefits of 'arrows' [7]. © 2010 ACM."
"Beach A., Gartrell M., Han R.";"q-Anon: Rethinking anonymity for social networks";"This paper proposes that social network data should be assumed public but treated private. Assuming this rather confusing requirement means that anonymity models such as k-anonymity cannot be applied to the most common form of private data release on the internet, social network APIs. An alternative anonymity model, q-Anon, is presented, which measures the probability of an attacker logically deducing previously unknown information from a social network API while assuming the data being protected may already be public information. Finally, the feasibility of such an approach is evaluated suggesting that a social network site such as Facebook could practically implement an anonymous API using q-Anon, providing its users with an anonymous option to the current application model. © 2010 IEEE."
"Andrews K., Lessacher M.";"Liquid diagrams: Information visualisation gadgets";"Information visualisation techniques have sometimes been slow to diffuse into more widespread public use. Recent advances in cloud computing have opened up opportunities to bring information visualisation to the masses in ways previously not possible. Liquid diagrams are a suite of information visualisation gadgets written in Flex, which visualise live data contained in Google Docs spreadsheets through the Google Visualization API. Users can interactively configure the visualisation and any changes in the online spreadsheet data are reflected immediately in the display. In contrast to other solutions, liquid diagrams gadgets specifically support the printing and export of both vector (SVG) and raster (PNG) graphics versions of the visualisations, allowing users to construct and export high-quality diagrams for inclusion into other works. The suite of visualisation gadgets currently available includes: area charts, bar charts, heat maps (choropleths), line charts, pie charts, treemaps, and parallel coordinates plots. Star plots and voronoi treemaps are coming soon. © 2010 IEEE."
"Den Burger M., Jacobs C., Kielmann T., Merzky A., Weidner O., Kaiser H.";"What is the price of simplicity? A cross-platform evaluation of the SAGA API";"The abundance of middleware to access grids and clouds and their often complex APIs hinders ease of programming and portability. The Open Grid Forum (OGF) has therefore initiated the development and standardization of SAGA: a Simple API for Grid Applications. SAGA provides a simple yet powerful API with high-level constructs that abstract from the details of the underlying infrastructure. In this paper we investigate the price that possibly comes with such an API. We discuss the effects on expressiveness and ease of programming, and analyze the performance overhead of three different SAGA implementations (written in Java, Python, and C++) on various middleware. We conclude that SAGA is a good pragmatic approach to make grids easily accessible. The API considerably improves usability and uniformity, but offers a compromise between expressiveness and runtime dependencies. The overall performance of the tested implementations is acceptable, but the strict API semantics require various runtime checks that occasionally cause significant overhead, depending on the underlying infrastructure. © 2010 Springer-Verlag."
"Mileva Y.M., Dallmeier V., Zeller A.";"Mining API popularity";"When designing a piece of software, one frequently must choose between multiple external libraries that provide similar services. Which library is the best one to use? We mined hundreds of open source projects and their external dependencies in order to observe the popularity of their APIs and to give recommendations of the kind: ""Projects are moving away from this API element. Consider a change."" Such wisdom of the crowds can provide valuable information to both the API users and the API producers. © 2010 Springer-Verlag."
"Kim J., Lee S., Hwang S.-W., Kim S.";"Towards an intelligent code search engine";"Software developers increasingly rely on information from the Web, such as documents or code examples on Applica tion Programming Interfaces (APIs), to facilitate their devel opment processes. However, API documents of ten do not in clude enough information for developers to fully understand the API usages, while searching for good code examples re quires non-trivial effort. To address this problem, we propose a novel code search engine, combining the strength of browsing documents and searching for code examples, by returning documents embed ded with high-quality code example summaries mined from the Web. Our evaluation results show that our approach pro vides code examples with high precision and boosts program mer productivity. Copyright © 2010, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved."
"Nguyen H.A., Nguyen T.T., Wilson Jr. G., Nguyen A.T., Kim M., Nguyen T.N.";"A graph-based approach to API usage adaptation";"Reusing existing library components is essential for reducing the cost of software development and maintenance. When library components evolve to accommodate new feature requests, to fix bugs, or to meet new standards, the clients of software libraries often need to make corresponding changes to correctly use the updated libraries. Existing API usage adaptation techniques support simple adaptation such as replacing the target of calls to a deprecated API, however, cannot handle complex adaptations such as creating a new object to be passed to a different API method, or adding an exception handling logic that surrounds the updated API method calls. This paper presents LibSync that guides developers in adapting API usage code by learning complex API usage adaptation patterns from other clients that already migrated to a new library version (and also from the API usages within the library's test code). LibSync uses several graph-based techniques (1) to identify changes to API declarations by comparing two library versions, (2) to extract associated API usage skeletons before and after library migration, and (3) to compare the extracted API usage skeletons to recover API usage adaptation patterns. Using the learned adaptation patterns, LibSync recommends the locations and edit operations for adapting API usages. The evaluation of LibSync on real-world software systems shows that it is highly correct and useful with a precision of 100% and a recall of 91%. Copyright © 2010 ACM.";"API evolution, API usage adaptation, API usage model, Program differencing, Software evolution"
"Hsu S.-K., Lin S.-J.";"Mining source codes to guide software development";"The reuse of software library and application framework is an important activity for rapid software development. However, due to rapid software changes, software libraries and application frameworks are usually not well-documented. To deal with this issue, we have developed a tool, named MACs, that provides developers with efficient and effective access to the API pattern databases for a software development project that are form by relevant source files. After an initial program statement is given, our MACs prototype can correctly predict useful relevant API code snippets. In our evaluation, we present a study investigating the usefulness of MACs in software development tasks. Our experimental evaluation shows that MACs has significant potential to assist developers, especially project newcomers, and provides a reuse method for code reuse from relevant source codes files. © 2010 Springer-Verlag Berlin Heidelberg.";"API usage pattern, Code reuse, Mining source code"
"Zhang D.-H., Xie B., Chen H.-J., Lv Y., Yu L.";"Using geodata and geoprocessing web services in embedded device";"Using XML web services in embedded system could be able to use the existing geodata and geoprocessing services through wired/wireless network. However, the processing and memory limitations of embedded devices exacerbate the problem in the area of complexity, constraints, and the verbosity of the protocols used in XML web services effect the usability of XML. This paper presents a GPS navigation system, which accesses OGC-compliant geodata and geoprocessing services using gSOAP toolkit. This system composes of hardware platform, embedded operation system and software system. Our experimental result shows gSOAP could provides transparent SOAP API allows embedded system using XML web services. © 2010 IEEE.";"Embedded device, gSOAP, OGC-compliant services, XML web service"
"Gimblett A., Thimbleby H.";"User interface model discovery: Towards a generic approach";"UI model discovery is a lightweight formal method in which a model of an interactive system is automatically discovered by exploring the system's state space, simulating the actions of a user, such models are then amenable to automatic analysis targetting structural usability concerns. This paper specifies UI model discovery in some detail, providing a formal, generic and language-neutral API and discovery algorithm. The technique has been implemented in prototype systems on several programming platforms, yielding valuable usability insights. The API described here supports further development of these ideas in a systematic manner. © 2010 ACM.";"Discovery tools, Interaction programming, Reverse engineering, Structural usability"
"[No author name available]";"2010 ICSE Workshop on Search-Driven Development: Users, Infrastructure, Tools and Evaluation, SUITE 2010";"The proceedings contain 12 papers. The topics discussed include: towards integrating e-mail communication in the IDE, searching API usage examples in code repositories with sourcerer API search, behavior model based component search: an initial assessment, enhancing static source code search with dynamic data, facilitating the comparison of software retrieval systems through a reference reuse collection, more archetypal usage scenarios for software search engines, immediate search in the IDE as an example of socio-technical congruence in search-driven development, searching across paths, towards query formulation and visualization of structural search results, searching and using external types in an extensible software development environment, a trustability metric for code search based on developer karma, and fostering synergies - how semantic web technology could influence software repositories."
"Bajracharya S., Ossher J., Lopes C.";"Searching API usage examples in code repositories with sourcerer API search";"We present Sourcerer API Search (SAS), a search interface to find API usage examples in large code repositories. SAS facilitates finding API usage examples by providing three unique features: (i) code snippets view for each result that shows the portions of code where APIs are used, (ii) Tag-cloud view of popular words to facilitate query reformulation, and (iii) filtering results using APIs to narrow search results. Furthermore, SAS uses a code index where each code entity is indexed with terms not only found in the entity but also in other entities having similar API usage. These features make SAS a novel search interface to find API usage examples in code repositories. © 2010 ACM.";"API search, exploratory code search, search driven development, search user interface, software information retrieval"
"Kim I., Lee D., Lee J., Rim K.";"Extended authorization mechanism in OSGi";"As ubiquitous computing technology evolves, open API that is a solution to interconnect heterogeneous devices and services in a more fluid manner has emerged. Among open API solutions, OSGi is a Java-based service platform that is widely used in the service gateway of home network. In home network environments, the user authentication and authorization associated user's information and usability may be important security issue. Although the current OSGi support RBAC-based authorization, it does not support various facilities in the RBAC model. The access control mechanisms for OSGi proposed so far focus on supporting the RBAC conventions with the basic form of role-user-permission mappings. However, these are difficult to support efficient access control. We propose the extended access control mechanism that includes the concepts of relative role and delegate class. We explain the proposed access control mechanism with an example of developing a simple set-top box control service. ©2010 IEEE.";"Authorization, Component, OSGi, RBAC"
"Lawall J., Laurie B., Hansen R.R., Palix N., Muller G.";"Finding error handling bugs in OpenSSL using Coccinelle";"OpenSSL is a library providing various functionalities relating to secure network communication. Detecting and fixing bugs in OpenSSL code is thus essential, particularly when such bugs can lead to malicious attacks. In previous work, we have proposed a methodology for finding API usage protocols in Linux kernel code using the program matching and transformation engine Coccinelle. In this work, we report on our experience in applying this methodology to OpenSSL, focusing on API usage protocols related to error handling. We have detected over 30 bugs in a recent OpenSSL snapshot, and in many cases it was possible to correct the bugs automatically. Our patches correcting these bugs have been accepted by the OpenSSL developers. This work furthermore confirms the applicability of our methodology to user-level code. © 2010 IEEE.";"Bug finding, Coccinelle, OpenSSL"
"Farooq U., Welicki L., Zirkler D.";"API usability peer reviews: A method for evaluating the usability of application programming interfaces";"We describe a usability inspection method to evaluate Application Programming Interfaces (APIs). We found the method useful as it identified usability defects in Microsoft's .NET Framework, of which 59% were new and 21% were fixed. Based on a comparison of usability defects identified between API usability peer reviews and API usability tests, API usability tests were found to expose design issues related to actually using an API whereas API usability peer reviews were found to expose the design rationale of an API. We reflect on the efficiency and productivity of each method: each API usability test is equivalent to 16 API usability peer reviews with the former having a 2.5x productivity advantage. We discuss how API usability peer reviews can be used in conjunction with API usability tests to increase usability coverage on APIs. © 2010 ACM.";"api usability, software bugs, usability breakdowns, usability evaluation method (uem), usability inspection"
"Eisenberg D.S., Stylos J., Myers B.A.";"Apatite: A new interface for exploring APIs";"We present Apatite, a new tool that aids users in learning and understanding a complex API by visualizing the common associations between its various components. Current object-oriented API documentation is usually navigated in a fixed tree structure, starting with a package and then filtering by a specific class. For large APIs, this scheme is overly restrictive, because it prevents users from locating a particular action without first knowing which class it belongs to. Apatite's design instead enables users to search across any level of an API's hierarchy. This is made possible by the introduction of a novel interaction technique that presents popular items from multiple categories simultaneously, determining their relevance by approximating the strength of their association using search engine data. The design of Apatite was refined through iterative usability testing, and it has been released publicly as a web application. © 2010 ACM.";"api documentation, browsing, search tools, visualizations, web applications"
"Sales L., Teófilo H., Mendonça N.C.";"G2CL: A generic group communication layer for clustered applications";"Generic group communication frameworks offer several benefits to developers of clustered applications, including better software modularity and greater flexibility in selecting a particular group communication system. However, current generic frameworks only support a very limited set of group communication primitives, which has hampered their adoption by many ""real-world"" clustered applications that require higher-level group communication services, such as state transfer, distributed data structures and replicated method invocation. This paper describes the design, implementation and initial evaluation of G2CL, a Generic Group Communication Layer that offers a set of commonly used high-level group communication services implemented on top of an existing generic framework. Compared to current group communication solutions, G2CL offers two main contributions: (i) its services can be configured to run over any group communication system supported by the underlying generic framework, and (ii) it implements the same service API used by JGroups, a popular group communication toolkit, which may reduce its learning curve and make the task of migrating to G2CL particularly attractive for JGroups users. © 2010 Springer-Verlag Berlin Heidelberg."
"Liao Z., Duan X., Lu J., Yue X., Liu W., He Q.";"The mobile LBS positioning solution based on NRTK and Windows Mobile";"In order to meet the requirements of Location-based Service (LBS), there are many proposed positioning solutions that may be able to provide LBS support, such as GPS, Mobile Phone Location, RFID, and so on. With the most widely recognized system being the Global Positioning System (GPS) and Windows Mobile 5.0 system characteristics, this paper first provides three kinds method, i.e. invoking Win32 API, using Ports namespace and calling GPS Intermediate Driver, to receive GPS raw data on Windows Mobile devices. Since internet-based GPS VRS RTK workstation can provide real-time streaming of differential GPS corrections. The following text introduces a high precision Net-based RTK (NRTK) mobile positioning solution which is mainly equipped with a Windows Mobile 5.0 device and an Ashtech Z-Xtreme receiver. With it a rover-side (NtripClient) firstly connects to an NtripCaster which is a part of a VRS workstation, via GPRS /CDMA, using the IP and specified listening Port of the Tongji VRS workstation. Then the rover-side transmits NMEA GGA strings after the HTTP request to the NtripCaster. With that the Windows Mobile device continuously receives RTCM data back from the NtripCaster and instantly sends them out into the Ashtech Z-Xtreme receiver. Finally, the Ashtech Z-Xtreme receiver will work out vector solution information of the rover-side. Thus, this paper provides a multimode mobile LBS positioning solution based on NRTK and Windows Mobile 5.0. © 2010 Copyright SPIE - The International Society for Optical Engineering.";"GPS VRS RTK, location-based service, NTRIP, Windows Mobile"
"Gerken J., Jetter H.-C., Reiterer H.";"Using concept maps to evaluate the usability of APIs";"Application programming interfaces (APIs) are the interfaces to existing code structures, such as widgets, frameworks, or toolkits. Therefore, they very much do have an impact on the quality of the resulting system. So ensuring that developers can make the most out of them is an important challenge. However standard usability evaluation methods as known from HCI have limitations in grasping the interaction between developer and API - the GUI, which makes this interaction obvious, is missing. In this paper we present a longitudinal approach using concept maps and a question diary to make this interaction visible and study the usability of an API over time. © 2010 Copyright is held by the author/owner(s).";"API usability, Concept maps, Longitudinal evaluation"
"Zhou J., Ji Y., Zhao D., Liu J.";"Using AOP to ensure component interactions in component-based software";"Component-based software development (CBSD) has been got considerable adoption in software industry, but it is still lack of language support to ensure proper interactions among components, i.e. modularity assurance, which usually causes the software hard to maintain and evolve because of the improper dependencies among the components. In this paper, we propose an AOP approach to ensure that the interactions among components are strictly conformed to the sated API usage policies of the components. Also, by using AOP, we can separate the constraints violation checking code from the normal functional code via the so called aspects, thus improving the software quality by separation of concern. Experiment using AspectJ as the AOP implementation technique shows that the performance is comparable to the non embedded code. ©2010 IEEE.";"Aspect-oriented programming, Component coupling, Component-based development, Constraints violation"
"Jugel U.";"Generating smart wrapper libraries for arbitrary APIs";"Library design is language design [1]. The development of a smart program library is very similar to the creation of a domain specific language (DSL). Both are currently created in an ad-hoc manner; taking account of best practices and software patterns. Creating new languages and the tools needed to integrate them can be very cumbersome. We propose a reproducible, model-driven methodology to add automation to the DSL-creation process. Our novel approach presents an easy way to design and generate smart, API-wrapping libraries, similar to internal DSLs. These libraries increase the usability of an existing API and can be easily integrated into existing software development tool chains. To generate these DSLs, we propose an enhanced code generation that applies usability-enhancing software patterns. Our current generator leverages the Expression Builder pattern, which is described in detail. We validate our methodology and our enhanced code generation by applying it to Java APIs resulting in smart Java libraries that we call ""dotLings"". © 2010 Springer-Verlag.";"API-usability, Code generation, Domain specific languages, Language integration, Model-driven"
"Resseguie D., Fairgrieve S.";"Unifying isolated sensor systems using web 2.0 and open standards";"Oak Ridge National Laboratory has developed the Sensorpedia program that enables individuals, communities, and enterprises to share, find, and use sensor data online. Sensorpedia networks users based on mutual sensor information interests in place of networking them based on mutual personal interests. The program applies several design principles common to many popular Web 2.0 sites. It is a Web-based application consisting of a Google Maps interface where users can search and explore published sensor data. The interface is designed to be simple and intuitive to use for gathering and exchanging important data online. The Sensorpedia API uses Web services designed to accept and publish data using established standards, such as the Atom Syndication Format and GeoRSS. The API also supports rapid development of customized third-party applications to meet specific needs of users."
"Hurst A., Hudson S.E., Mankoff J.";"Automatically identifying targets users interact with during real world tasks";"Information about the location and size of the targets that users interact with in real world settings can enable new innovations in human performance assessment and soft-ware usability analysis. Accessibility APIs provide some information about the size and location of targets. How-ever this information is incomplete because it does not sup-port all targets found in modern interfaces and the reported sizes can be inaccurate. These accessibility APIs access the size and location of targets through low-level hooks to the operating system or an application. We have developed an alternative solution for target identification that leverages visual affordances in the interface, and the visual cues produced as users interact with targets. We have used our novel target identification technique in a hybrid solution that combines machine learning, computer vision, and accessibility API data to find the size and location of targets users select with 89% accuracy. Our hybrid approach is superior to the performance of the accessibility API alone: in our dataset of 1355 targets covering 8 popular applications, only 74% of the targets were correctly identified by the API alone. Copyright 2010 ACM.";"Computer accessibility, Pointing input, Target identification, Usability analysis"
"Farooq U., Zirkler D.";"API peer reviews: A method for evaluating usability of application programming interfaces";"API usability tests in the lab are time and resource intensive, thus allowing a relatively small percentage of the API namespace to be evaluated. We describe a group-based usability inspection method - API Peer Reviews - to evaluate API usability. Based on an analysis of usability breakdowns from API Peer Reviews and API usability tests, results show that API Peer Reviews identified breakdowns across several cognitive dimensions, some of which were different than what was identified by API usability tests. We reflect on the adoption of API Peer Reviews as a collaborative practice in organizations for evaluating API usability. Copyright 2010 ACM.";"API usability, Cognitive dimensions, Usability inspection"
"Kim G., Suzuki Y., Nishida A., Takemiya H.";"Development of APIs for desktop supercomputing";"We developed the Script Generator API to support Grid users to develop their own Grid-enabled client application. The Script Generator API automatically generates a Grid-enabled workflow script needed to execute jobs on a Grid system. The Script Generator API enables users to develop their application with the complex job flow which cannot be generated using existing workflow tools. We implemented the Script Generator API in our Grid infrastructure and utilized it to the three-dimensional virtual plant vibration simulator. By developing Grid-enabled client application for the three-dimensional virtual plant vibration simulator, we confirmed the usability of the Script Generator API. © Springer-Verlag Berlin Heidelberg 2010."
"Myers B.A., Jeong S.Y., Xie Y., Beaton J., Stylos J., Ehret R., Karstens J., Efeoglu A., Busse D.K.";"Studying the Documentation of an API for Enterprise ServiceOriented Architecture";"All software today is written using application programming interfaces (APIs). We performed a user study of the online documentation of a large and complex API for Enterprise Service-Oriented Architecture (eSOA), which identified many issues and recommendations for making API documentation easier to use. eSOA is an appropriate testbed because the target users include high-level business experts who do not have significant programming expertise and thus can be classified as ""end-user developers."" Our study showed that the participants' background influenced how they navigated the documentation. Lack of familiarity with business terminology was a barrier for developers without business application experience. Both groups avoided areas of the documentation that had an inconsistent visual design. A new design for the documentation that supports flexible navigation strategies seems to be required to support the wide range of users for eSOA. This paper summarizes our study and provides recommendations for future documentation for APIs. Copyright © 2010, IGI Global.";"Api design, Business solution architects, Documentation, Natural programming, Service-oriented architecture, Usability, Web services"
"Teófilo M., Martini A., Cruz P.";"Ulmo: A system to enable mobile applications personalization by binary SMS";"Usability and user interfaces play a huge and important role in today's mobile application. Besides a good design, acceptable performance, scalability, and robustness, a mobile application needs to be easy to use and, to some extent, customizable. To create a system able to custom the mobile application's user interface and mirror it immediately to final users is the purpose of this article. Ulmo is such system, which is composed by a web site that enables user to comfortably executes change in mobile application user interface, a mobile application compliant (providing API that facilitates mobile application Ulmo compliance development) and the communication module to mirror web adjustments in mobile phone, which was made using SMS technology. Its availability and low cost are also considered and its high penetration in emergent markets. Some aspects as security, data compression and reliability are taken in account. © 2009 IEEE.";"Mobile human interaction, Mobile usability, SMS technology"
"Pradel M.";"Dynamically inferring, refining, and checking API usage protocols";"Using a set of API methods often requires compliance with a protocol, whose violation can lead to errors in the program. However, most APIs lack explicit and formal definitions of these protocols. We propose a dynamic program analysis for automatically inferring and refining specifications of correct method call sequences. Our experiments with several Java programs show that we can infer meaningful protocols, such as widely respected programming rules. Furthermore, our analysis finds violations of the inferred specifications that point out potential bugs to the programmer.";"Runtime verification, Specification mining"
"Pletcher D.M., Hou D.";"BCC: Enhancing code completion for better API usability";"Nowadays, programmers spend much of their workday dealing with code libraries and frameworks that are bloated with APIs. One common way of interacting with APIs is through Code Completion inside the code editor. By default, Code Completion presents in a scrollable list, in alphabetical order, all accessible members available in the apparent type and supertypes of a receiver expression. This default behavior for Code Completion should and can be further improved because (1) not all public methods are APIs and presenting non-API public members to a programmer is misleading, (2) certain APIs are meant to be accessible only in some limited contexts but not others, and (3) the alphabetical order separates otherwise logically related APIs, making it hard to see their connection. BCC (Better Code Completion) addresses these problems by enhancing Code Completion so that programmers can control how specific API elements should be sorted, filtered, and grouped."
"Mühlberg J.T., Lüttgen G.";"Verifying compiled file system code";"This paper presents a case study on retrospective verification of the Linux Virtual File System (VFS), which is aimed at checking for violations of API usage rules and memory properties. Since VFS maintains dynamic data structures and is written in a mixture of C and inlined assembly, modern software model checkers cannot be applied. Our case study centres around our novel verification tool, the SOCA Verifier, which symbolically executes and analyses compiled code. We describe how this verifier deals with complex program features such as memory access, pointer aliasing and computed jumps, while reducing manual modelling to the bare minimum. Our results show that the SOCA Verifier is capable of reliably analysing complex operating system components such as the Linux VFS, thereby going beyond traditional testing tools and into niches that current software model checkers do not reach. © 2009 Springer-Verlag Berlin Heidelberg."
"Kawrykow D., Robillard M.P.";"Improving API usage through automatic detection of redundant code";"Software projects often rely on third-party libraries made accessible through Application Programming Interfaces (APIs). We have observed many cases where APIs are used in ways that are not the most effective. We developed a technique and tool support to automatically detect such patterns of API usage in software projects. The main hypothesis underlying our technique is that client code imitating the behavior of an API method without calling it may not be using the API effectively because it could instead call the method it imitates. Our technique involves analyzing software systems to detect cases of API method imitations. In addition to warning developers of potentially reimplemented API methods, we also indicate how to improve the use of the API. Applying our approach on 10 Java systems revealed over 400 actual cases of potentially suboptimal API usage, leading to many improvements to the quality of the code we studied. © 2009 IEEE.";"API usage, Code analysis, Code quality, Recommendation system"
"Lo D., Ramalingam G., Ranganath V.P., Vaswani K.";"Mining quantified temporal rules: Formalism, algorithms, and evaluation";"Libraries usually impose constraints on how clients should use them. Often these constraints are not well-documented. In this paper, we address the problem of recovering such constraints automatically, a problem referred to as specification mining. Given some client programs that use a given library, we identify constraints on the library usage that are (almost) satisfied by the given set of clients. The class of rules we target for mining combines simple binary temporal operators with state predicates (involving equality constraints) and quantification. This is a simple yet expressive subclass of temporal properties that allows us to capture many common API usage rules.We focus on recovering rules from execution traces and apply classical data mining concepts to be robust against bugs (API usage rule violations) in clients. We present new algorithms for mining rules from execution traces. We show how a propositional rule mining algorithm can be generalized to treat quantification and state predicates in a unified way. Our approach enables the miner to be complete - mine all rules within the targeted class that are satisfied by the given traces - while avoiding an exponential blowup. We have implemented these algorithms and used them to mine API usage rules for several Windows APIs. Our experiments show the efficiency and effectiveness of our approach. © 2009 IEEE."
"Kim K., Lee H., Jo S., Ryu W.";"Implementation of open web portal service enabler based on service delivery platform";"This paper is to provide implementation supporting open web portal service enabler based on Service Delivery Platform(SDP). This technology is for adapter to provide the method for converging web portal Application Program Interface(API) using SDP. It united the specification of protocols and parameters per web site in order to support ""Open Method"". Also for adding the new web site and modifying the existed web site with ease, it utilized database dynamically. © 2009 IEEE.";"NGN, Open API, SDP"
"Focardi R., Luccio F.L., Steel G.";"Blunting differential attacks on PIN processing APIs";"We propose a countermeasure for a class of known attacks on the PIN processing API used in the ATM (cash machine) network. This API controls access to the tamper-resistant Hardware Security Modules where PIN encryption, decryption and verification takes place. The attacks are differential attacks, whereby an attacker gains information about the plaintext values of encrypted customer PINs by making changes to the non-confidential inputs to a command. Our proposed fix adds an integrity check to the parameters passed to the command. It is novel in that it involves very little change to the existing ATM network infrastructure. © Springer-Verlag 2009.";"Financial cryptography, PIN verification, Security APIs"
"Blum N., Dutkowski S., Magedanz T.";"InSeRt - An intent-based service request API for service exposure in Next Generation Networks";"Modern telecommunication networks and classical roles of operators are subject to fundamental change. Many network operators are currently seeking for new sources to generate revenue by exposing network capabilities to 3rd party service providers. At the same time we can observe that applications on the World Wide Web (WWW) are becoming more mature in terms of the definition of APIs that are offered towards other services. The combinations of those services are commonly referred to as Web 2.0 mash-ups. This report describes our approach to prototype a policy-based service broker function for Next Generation Networks (NGN)-based telecommunications service delivery platforms to provide flexible service exposure anchor points for service integration into so called mash-ups. The defined exposure API uses Intent-based request constructs to allow a description of services in business terms, i.e. intentions and strategies to achieve them and to organize their publication, search and composition on the basis of these descriptions. © 2009 IEEE."
"Stylos J., Faulring A., Yang Z., Myers B.A.";"Improving API documentation using API usage information";"Jadeite is a new Javadoc-like API documentation system that takes advantage of multiple users' aggregate experience to reduce difficulties that programmers have learning new APIs. Previous studies have shown that programmers often guessed that certain classes or methods should exist, and looked for these in the API. Jadeite's ""placeholders"" let users add new ""pretend"" classes or methods that are displayed in the actual API documentation, and can be annotated with the appropriate APIs to use instead. Since studies showed that programmers had difficulty finding the right classes from long lists in documentation, Jadeite takes advantage of usage statistics to display commonly used classes more prominently. Programmers had difficulty discovering how to instantiate objects, so Jadeite uses a large corpus of sample code to automatically the most common ways to construct an instance of any given class. An evaluation showed that programmers were about three times faster at performing common tasks with Jadeite than with standard Javadoc. ©2009 IEEE."
"Nguyen T.T., Nguyen H.A., Pham N.H., Al-Kofahi J.M., Nguyen T.N.";"Graph-based mining of multiple object usage patterns";"The interplay of multiple objects in object-oriented programming often follows specific protocols, for example certain orders of method calls and/or control structure constraints among them that are parts of the intended object usages. Unfortunately, the information is not always documented. That creates long learning curve, and importantly, leads to subtle problems due to the misuse of objects. In this paper, we propose GrouMiner, a novel graph-based approach for mining the usage patterns of one or multiple objects. GrouMiner approach includes a graph-based representation for multiple object usages, a pattern mining algorithm, and an anomaly detection technique that are efficient, accurate, and resilient to software changes. Our experiments on several real-world programs show that our prototype is able to find useful usage patterns with multiple objects and control structures, and to translate them into user-friendly code skeletons to assist developers in programming. It could also detect the usage anomalies that caused yet undiscovered defects and code smells in those programs. Copyright 2009 ACM.";"Anomaly, API usage, Clone, Graph mining, Groum, Object usage, Pattern"
"Pradel M., Gross T.R.";"Automatic generation of object usage specifications from large method traces";"Formal specifications are used to identify programming errors, verify the correctness of programs, and as documentation. Unfortunately, producing them is error-prone and time-consuming, so they are rarely used in practice. Inferring specifications from a running application is a promising solution. However, to be practical, such an approach requires special techniques to treat large amounts of runtime data. We present a scalable dynamic analysis that infers specifications of correct method call sequences on multiple related objects. It preprocesses method traces to identify small sets of related objects and method calls which can be analyzed separately. We implemented our approach and applied the analysis to eleven real-world applications and more than 240 million runtime events. The experiments show the scalability of our approach. Moreover, the generated specifications describe correct and typical behavior, and match existing API usage documentation. © 2009 IEEE.";"Dynamic analysis, Formal specifications, Specification inference, Temporal properties"
"Lefohn A., Houston M., Andersson J., Assarsson U., Everitt C., Fatahalian K., Foley T., Hensley J., Lalonde P., Luebke D.";"Beyond programmable shading (parts I and II)";"There are strong indications that the future of interactive graphics programming is a more flexible model than today's OpenGL/Direct3D pipelines. Graphics developers need a basic understanding of how to combine emerging parallel programming techniques and more flexible graphics processors with the traditional interactive rendering pipeline. As the first in a series, this course introduces the trends and directions in this emerging field. Topics include: parallel graphics architectures, parallel programming models for graphics, and game-developer investigations of the use of these new capabilities in future rendering engines. This second course in the series Beyond Programmable Shading presents the state of the art in combining traditional rendering API usage with advanced task- and data-parallel computation to increase the image quality of interactive graphics. Leaders from graphics hardware vendors, game development, and academic research present case studies that show how general parallel computation is being combined with the traditional graphics pipeline to boost image quality and spur new graphics algorithm innovation. Each case study discusses the mix of parallel programming constructs, details of the graphics algorithm, and how the rendering pipeline and computation interact to achieve the technical goals. Presenters also discuss integrating a combination of GPU and CPU techniques for more efficient and flexible algorithms. The focus is on what currently can be done, how it is done, and near-future trends. Topics include: interactive realistic lighting, advanced geometry-processing pipelines, in-frame data structure construction, complex image processing, and rasterization versus ray tracing."
"Parreiras F.S., Saathoff C., Walter T., Franz T., Staab S.";"APIs à gogo: Automatic generation of ontology APIs";"When developing application programming interfaces of ontologies that include many instances of ontology design patterns, developers of semantic web applications usually have to handle complex mappings between descriptions of information given by ontologies and object oriented representations of the same information. In current approaches, annotations on API source code handle these mappings, leading to problems with reuse and maintenance. We propose a domain-specific language to tackle these mappings in a platform independent way - agogo. Agogo provides improvements on software engineering quality attributes like usability, reusability, maintainability, and portability. © 2009 IEEE.";"Code generation, Model driven engineering, Ontology API, Ontology design pattern"
"Mentis A.S.";"A robotics API dialect for type-safe robots: Translating Myro to Ada";"In this paper, we present an Ada robotics API designed to be used in teaching undergraduate-level computer science. Our API is inspired by Myro, a Python-based API, but we improve upon Myro's usability, readability, modularity, and documentation by using features of the Ada programming language and the GNAT Programming Studio's documentation generation tool. The encapsulation, abstraction, and data hiding provided by Ada's packages make it easy for beginning programmers to use the API for advanced tasks, while Ada's syntax and readability allow educators to use the underlying code later in a course or curriculum to illustrate more advanced concepts to the same students as their knowledge and experience grow. Copyright 2009 Association for Computing Machinery.";"Myro, Scribbler, Undergraduate computer science education"
"Wurster G., Van Oorschot P.C.";"The developer is the enemy";"We argue that application developers, while often viewed as allies in the effort to create software with fewer security vulnerabilities, are not reliable allies. They have varying skill sets which often do not include security. Moreover, we argue that it is inefficient and unrealistic to expect to be able to successfully teach all of the world's population of software developers to be security experts. We suggest more efficient and effective alternatives, focusing on those developers who produce core functionality used by other developers (e.g. those who develop popular APIs - Application Programming Interfaces). We discuss the benefits of designing APIs which can be easily used in a secure fashion to encourage security. We also introduce two straw-man proposals which integrate security into the work- ow of an application developer. Data tagging and unsuppressible warnings provide the basis for further work where the most natural use (path of least resistance) results in secure code. We believe there are benefits to co-opting developers into programming securely. Copyright 2008 ACM.";"Development tools, Education, Human factors, Persuasion, Software developers, Software security, Usability"
"Ghoul O.E., Jemni M.";"A sign language screen reader for deaf";"Screen reader technology has appeared first to allow blind and people with reading difficulties to use computer and to access to the digital information. Until now, this technology is exploited mainly to help blind community. During our work with deaf people, we noticed that a screen reader can facilitate the manipulation of computers and the reading of textual information. In this paper, we propose a novel screen reader dedicated to deaf. The output of the reader is a visual translation of the text to sign language. The screen reader is composed by two essential modules: the first one is designed to capture the activities of users (mouse and keyboard events). For this purpose, we adopted Microsoft MSAA application programming interfaces. The second module, which is in classical screen readers a text to speech engine (TTS), is replaced by a novel text to sign (TTSign) engine. This module converts text into sign language animation based on avatar technology. © Springer-Verlag Berlin Heidelberg 2009.";"Avatar, Deaf, Screen reader, TTsing engine"
"Dekel U., Herbsleb J.D.";"Improving API documentation usability with knowledge pushing";"The documentation of API functions typically conveys detailed specifications for the benefit of interested readers. In some cases, however, it also contains usage directives, such as rules or caveats, of which authors of invoking code must be made aware to prevent errors and inefficiencies. There is a risk that these directives may be ""lost"" within the verbose text, or that the text would not be read because there are so many invoked functions. To address these concerns for Java, an Eclipse plug-in named eMoose decorates method invocations whose targets have associated directives. Our goal is to lead readers to investigate further, which we aid by highlighting the tagged directives in the JavaDoc hover. We present a lab study that demonstrates the directive awareness problem in traditional documentation use and the potential benefits of our approach. © 2009 IEEE."
"Dillon R., Bee N.K., Rozner S.";"The music and emotion driven game engine: Ideas and games";"In this paper we describe the ideas behind the Music and Emotion Driven Game Engine (M-EDGE), currently under development at the School of Interactive and Digital Media in Nanyang Polytechnic and fully supported by the Singapore National Research Foundation. The paper will explain a possible method for analyzing emotional content in music in real time and how it can successfully be applied to different game ideas to help defining a new interactive experience and music based gameplay in videogames.";"Cognitive musicology, Game API, Music based games, Real time human-computer interaction, usability"
"Donatelli M., Bellocchi G., Habyarimana E., Bregaglio S., Confalonieri R., Baruth B.";"CLIMA: A weather generator framework";"Weather generators (WG) can be defined as collections of models to estimate site specific weather data and derived variables. They are commonly used for providing inputs to a variety of biophysical models or for deriving weather indices. Also, using either global circulation models or local area models inputs, sets of parameters calculated from long term weather series specific to a site can be modified to reproduce via WG synthetic series representing climate change scenarios. Finally, models implemented in WG are used for estimating missing data and to perform quality control on data collected from sensors at weather stations. The scientific foundation of models implemented in WG varies from purely empirical to physically based. Several models exist allowing either the estimate or the generation of specific weather variables, with different input requirements. New models are continuously being proposed, and, although some models to estimate specific variables are commonly accepted as reference methods, the lack of some inputs requires at times using alternate approaches. Currently available WG are applications which implement a predefined set of modelling options, in software implementations which do not allow for independent extensions by third parties. The CLIMA weather generator is a component based application which consist of a set of reusable graphical user interface (GUI) components, and a set of extensible model components. The latter are subdivided into six namespaces to estimate variables related to air temperature, rainfall, solar radiation, evapotranspiration, wind, and leaf wetness. The temporal resolution of the estimated variables varies from a day to ten minutes. Another software library allows the estimation of climatic indices from one year of daily data at the time. The current implementation consists of more than 300 models. Components are usable either via the CLIMA GUI, or via custom developed applications in a client-server architecture. The architecture of components is based on the composite and strategy as keystone design patterns. Models are implemented as single approaches (simple strategies), and as composite models (composite strategies) which are associated to models of finer granularity. Another type of model unit is represented by context strategies, which implement a logic to select within associated models. Finally, the GUI allows building composite models which can be saved as libraries, to be reused both within CLIMA for weather series generation, or independently by other applications. The components are implemented as .NET libraries. They implement a test of pre- and post-conditions, and a scalable tracing via .NET listeners. All variables and parameters are documented by a description, a physical unit and default, maximum and minimum values. Components are extensible: i.e. new models can be added independently by third parties and detected by the CLIMA application, which can also use them for data generation via building new composite libraries. Each component is made available via a software development kit which includes the code of two sample projects, either to extend or to reuse the component. CLIMA and its model components are freely available for reuse in no-profit applications.";"Component-oriented programming, Extensibility, Re-usability, Weather generation"
"Lawall J.L., Brunel J., Palix N., Hansen R.R., Stuart H., Muller G.";"WYSIWIB: A declarative approach to finding API protocols and bugs in linux code";"Eliminating OS bugs is essential to ensuring the reliability of infrastructures ranging from embedded systems to servers. Several tools based on static analysis have been proposed for finding bugs in OS code. They have, however, emphasized scalability over usability, making it difficult to focus the tools on specific kinds of bugs and to relate the results to patterns in the source code. We propose a declarative approach to bug finding in Linux OS code using a control-flow based program search engine. Our approach is WYSIWIB (What You See Is Where It Bugs), since the programmer expresses specifications for bug finding using a syntax close to that of ordinary C code. The key advantage of our approach is that search specifications can be easily tailored, to eliminate false positives or catch more bugs. We present three case studies that have allowed us to find hundreds of potential bugs. © 2009 IEEE.";"Bug finding, Linux, Protocol finding"
"Harrison W., Lievens D., Simeoni F.";"Safer typing of complex API usage through java generics";"When several incompatible implementations of a single API are in use in a Java program, the danger exists that instances from different implementations may inadvertently be mixed, leading to errors. In this paper we show how to use generics to prevent such mixing. The core idea of the approach is to add a type parameter to the interfaces of the API, and tie the classes that make up an implementation to a unique choice of type parameter. In this way methods of the API can only be invoked with arguments that belong to the same implementation. We show that the presence of a type parameter in the interfaces does not violate the principle of interface-based programming: clients can still completely abstract over the choice of implementation. In addition, we demonstrate how code can be reused between different implementations, how implementations can be defined as extensions of other implementations, and how different implementations may be mixed in a controlled and safe manner. To explore the feasibility of the approach, gauge its usability, and identify any issues that may crop up in practical usage, we have refactored a fairly large existing API-based application suite, and we report on the experience gained in the process. Copyright 2009 ACM.";"Family polymorphism, Generics, Interface-based programming, Programming patterns"
"Kim M.S., Wellings A.";"Refactoring asynchronous event handling in the real-time specification for Java";"The primary goal for asynchronous event handling (AEH) in the Real-Time Specification for Java (RTSJ) is to have a lightweight concurrency mechanism. However the RTSJ neither provides a well-defined guideline on how to implement AEH nor requires the documentation of the AEH model used in the implementation. Also the AEH API in the RTSJ are criticised as lacking in configurability as they do not provide any means for programmers to have fine control over the AEH facilities, such as the mapping between real-time threads and handlers. For these reasons, it needs the refactoring of its application programming interface (API) to give programmers more configurability. This paper, therefore, proposes a set of AEH related classes and interfaces to enable flexible configurability over AEH components. We have implemented the refactored configurable AEH API using the new specifications on an existing RTSJ implementation and this paper shows that it allows more configurability for programmers than the current AEH API in the RTSJ does. Consequently programmers are able to specifically tailor the AEH subsystem to fit their applications' particular needs. © 2009 IEEE."
"Chen N.-S., Wei C.-W., Chen W.-S.";"Developing a GroupNet system to solve groupthink problem";"This study proposed the concepts, architecture, and kernel of a GroupNet system to construct a more flexible ubiquitous learning environment. GroupNet is aiming to support small-group face-to-face learning activities anywhere and anytime without sticking in traditional classroom settings and additional infrastructures. We have also implemented the application programming interface (API) for accessing the core functions supported by GroupNet Kernel such that developers can develop GroupNet applications with fewer efforts. A GroupNet application has been developed using the APIs for conducting an experiment on how to reduce groupthink phenomenon in collaborative learning setting using mobile devices to evaluate the usability of GroupNet Kernel and illustrate the effectiveness of GroupNet applications.© 2009 IEEE."
"Robillard M.P.";"What makes APIs hard to learn? answers from developers";"Most software projects reuse components exposed through APIs, which provide developers access to implemented functionality. APIs have grown large and diverse, which raises questions regarding their usability. This article reports on a study of the obstacles professional developers at Microsoft faced when learning how to use APIs. The study was grounded in developers' experience, collected through a survey and interviews. The resulting data showed that learning resources for APIs are critically important and shed light on three issues: the need to discover the design and rationale of the API when needed, the challenge of finding credible usage API examples at the right level of complexity, and the challenge of understanding inexplicable API behavior. The article describes each of these challenges in detail and discusses associated implications for API users and designers. © 2009 IEEE.";"API design, API usability, Application interfaces, Code examples, Context, Data mining, Documentation, Empirical study, Software documentation, Usability"
"Schoeberlein J.G., Wang Y.";"Evaluating groupware accessibility";"Accessibility has been one of the biggest problems that people with disabilities face in the work place, due to today's rapid change in computer technology. This paper presents the evaluation of several console-based and web-based groupware applications including Outlook, AIM, Google Blog, and Group System's ThinkTank in terms of their accessibility. These applications were evaluated for accessibility based on various characteristics of the applications such as accessible front-end, hierarchy or list structures, input support, output support, screen reader adaptability, and keyboard access. Additionally, web-based groupware applications were evaluated using Web Content Accessibility Guidelines (WCAG) and U.S. Government's Section 508 guidelines. Fujitsu's Web Accessibility Inspector tool was also utilized to help evaluate the web-based applications. It is found that groupware applications have very limited accessibility through the support of keyboard access. Additional audio support and flattened hierarchies should be considered, to enable some persons with disabilities easy access to groupware applications. Future research should include persons with disabilities in evaluating groupware applications, to determine preferences. Since many groupware applications provide Application Program Interfaces (API), custom front-ends should be developed to include audio content and to flatten hierarchies and lists. © 2009 Springer Berlin Heidelberg.";"Accessibility, And assistive technology, Blind, CSCW, Dyslexia, Groupware, User Interface, Visually impaired"
"Kawrykow D., Robillard M.P.";"Detecting inefficient API usage";"Large software projects often rely on third-party libraries, made accessible through Application Programming Interfaces (APIs). We have observed many cases where APIs are used in ways that are not efficient. We developed a technique to automatically detect inefficient API usage in software projects. The main hypothesis underlying the technique is that client code that imitates the behavior of a library method without calling it is likely not to use the library as efficiently as possible. In addition to warning developers of potentially inefficient API usage, our technique also indicates how to improve the use of the API. Application of the technique on Java open-source systems revealed many cases of inefficient API usage, and corresponding recommendations that led to code improvements. © 2009 IEEE."
"De Souza C.R.B., Bentolila D.L.M.";"Automatic evaluation of API usability using complexity metrics and visualizations";"APIs are one of the most important concepts in today's modern software engineering. They allow software developers to work independently and minimize the impact caused by changes in the implementation of software services. Despite their importance, currently there are only a few approaches that guide the design of an API. In this paper, we present an approach, and associated tool, that allows an API client (developer) to evaluate the usability of an API and decide whether to use it (release it). In this aspect, our approach goes beyond previous approaches by performing this complexity and usability API analysis automatically. © 2009 IEEE."
"Fröschle S., Steel G.";"Analysing PKCS#11 key management APIs with unbounded fresh data";"We extend Delaune, Kremer and Steel's framework for analysis of PKCS#11-based APIs from bounded to unbounded fresh data. We achieve this by: formally defining the notion of an attribute policy, showing that a well-designed API should have a certain class of policy we call complete, showing that APIs with complete policies may be safely abstracted to APIs where the attributes are fixed, and proving that these static APIs can be analysed in a small bounded model such that security properties will hold for the unbounded case. We automate analysis in our framework using the SAT-based security protocol model checker SATMC. We show that a symmetric key management subset of the Eracom PKCS#11 API, used in their ProtectServer product, preserves the secrecy of sensitive keys for unbounded numbers of fresh keys and handles, i.e. pointers to keys. We also show that this API is not robust: if an encryption key is lost to the intruder, SATMC finds an attack whereby all the keys may be compromised. © 2009 Springer Berlin Heidelberg."
"Daughtry J.M., Farooq U., Stylos J., Myers B.A.";"API usability: CHI'2009 special interest group meeting";"Programmers of all types from novice end-user developers to professional software engineers make use of application programming interfaces (API) within their various designs. And, while the use of these interfaces is ubiquitous, there is little research about their design. Recently, a number of researchers and practitioners have begun to treat API design as a first-order object of study and practice. The purpose of this special interest group meeting is to bring together the community of usability researchers and professionals interested in API usability. The time will be used to discuss attendees' ideas and opinions in order to stimulate this new and exciting emerging field that crosses the boundaries between human-computer interaction and software engineering.";"Empirical studies of programmers (ESP), Natural programming, Psychology of programming"
"Zhong H., Xie T., Zhang L., Pei J., Mei H.";"MAPO: mining and recommending api usage patterns";"To improve software productivity, when constructing new software systems, programmers often reuse existing libraries or frameworks by invoking methods provided in their APIs. Those API methods, however, are often complex and not well documented. To get familiar with how those API methods are used, programmers often exploit a source code search tool to search for code snippets that use the API methods of interest. However, the returned code snippets are often large in number, and the huge number of snippets places a barrier for programmers to locate useful ones. In order to help programmers overcome this barrier, we have developed an API usage mining framework and its supporting tool called MAPO (Mining API usage Pattern from Open source repositories) for mining API usage patterns automatically. A mined pattern describes that in a certain usage scenario, some API methods are frequently called together and their usages follow some sequential rules. MAPO further recommends the mined API usage patterns and their associated code snippets upon programmers' requests. Our experimental results show that with these patterns MAPO helps programmers locate useful code snippets more effectively than two state-of-the-art code search tools. To investigate whether MAPO can assist programmers in programming tasks, we further conducted an empirical study. The results show that using MAPO, programmers produce code with fewer bugs when facing relatively complex API usages, comparing with using the two state-of-the-art code search tools. © 2009 Springer Berlin Heidelberg."
"Burns A., Wettings A.J.";"Concurrency vulnerabilities";"Concurrency is a significant issue in the design and implementation of systems, though it brings with it a number of vulnerabilities. Many different concurrency models can be found in programming languages. Vulnerabilities from this simple model include not all tasks start their execution, premature silent termination of a task or tasks, and overflow of task-local data. Some other vulnerabilities include unintentional use of unprotected shared variables, mutual update problem, race conditions, livestocks, and memory caching. The decision not to use a concurrent programming language does not remove these vulnerabilities, many will be present in the operating system (OS) and the API used by the sequential program to gain access to the concurrency features of the OS. It is possible to take an extensive set of language features, such as those provided by Ada tasking, and define a subset so that a profile is defined that has adequate expressive power and a minimum of vulnerabilities."
"De F. O. Araújo T., De S. Falc̃ao M.A., Lima A.M.N., Loureiro C.F.C.L.";"MaeRobot: An open source test platform for prototyping robots";"MaeRobot is a platform for studying robotic systems that interact with wireless networks. MaeRobot's main goal is to provide a simple way to create and test different robotic configurations build using the Mindstorm NXT Robotics kit. A wireless mobile device running Embedded Linux OS is used as the robot controller. The architecture of the proposed platform whereas the API used to exploit its resources are described in the paper. Moreover, we provide some useful examples of applications implemented with MaeRobot. © 2008 IEEE.";"Embedded linux OS, Maemo, Mobile robots, Python, Robotics educational kit, Wireless communication"
"Jeong S.Y., Xie Y., Beaton J., Myers B.A., Stylos J., Ehret R., Karstens J., Efeoglu A., Busse D.K.";"Improving documentation for eSOA APIs through user studies";"All software today is written using libraries, toolkits, frameworks and other application programming interfaces (APIs). We performed a user study of the online documentation a large and complex API for Enterprise Service-Oriented Architecture (eSOA), which identified many issues and recommendations for making API documentation easier to use. eSOA is an appropriate testbed because the target user groups range from high-level business experts who do not have significant programming expertise (and thus are end-participant developers), to professional programmers. Our study showed that the participants' background influenced how they navigated the documentation. Lack of familiarity with business terminology was a barrier we observed for developers without business application experience. Participants with business software experience had difficulty differentiating similarly named services. Both groups avoided areas of the documentation that had an inconsistent visual design. A new design for the documentation that supports flexible navigation strategies seem to be required to support the wide range of users for eSOA. This paper summarizes our study and provides recommendations for future documentation for developers. © 2009 Springer Berlin Heidelberg.";"API Design, Business Solution Architects, Documentation, Service-Oriented Architecture, Usability, Web Services"
"Kim G., Suzuki Y., Teshima N., Nishida A., Yamada T., Araya F., Takemiya H., Nakajima N., Kondo M.";"A script generator API for the full-scale three-dimensional vibration simulation of an entire nuclear power plant within AEGIS";"We developed the Script Generator API to support users to develop Grid-enabled client application. The Script Generator API automatically generates a Grid-enabled workflow script needed to execute jobs on a Grid system. Using the Script Generator API enables users to use a Grid environment without consciousness of a Grid computing system. In this paper, we show the implementation of the Script Generator API in our Grid infrastructure and its utilization to the Full-scale 3D Vibration Simulator for an Entire Nuclear Power Plant. By developing a Gridenabled client application for the Full-scale 3D Vibration Simulator, we confirmed the usability of the Script Generator API. © Civil-Comp Press, 2009.";"Application, Client api, Grid-enabled, Script, Usability, Workflow"
"Sankaranarayanan S., Ivančić F., Gupta A.";"Mining library specifications using inductive logic programming";"Software libraries organize useful functionalities in order to promote modularity and code reuse. A typical library is used by client programs through an application programming interface (API) that hides its internals from the client. Typically, the rules governing the correct usage of the API are documented informally. In many cases, libraries may have complex API usage rules and unclear documentation. As a result, the behaviour of the library under some corner cases may not be well understood by the programmer. Formal specifications provide a precise understanding of the API behaviour. We propose a methodology for learning interface specifications using Inductive Logic Programming (ILP). Our technique runs several unit tests on the library in order to generate relations describing the operation of the library. The data collected from these tests are used by an inductive learner to obtain rich Datalog/Prolog specifications. Such specifications capture essential properties of interest to the user. They may be used for applications such as reverse engineering the library internals or constructing checks on the application code to enforce proper API usage along with other properties of interest. Copyright 2008 ACM.";"Datalog, Inductive logic programming, Machine learning, Software specification, Verification"
"Bierhoff K., Aldrich J.";"PLURAL: Checking protocol compliance under aliasing";"Enforcing compliance to API usage protocols is notoriously hard due to possible aliasing of objects through multiple references. In previous work we proposed a sound, modular approach to checking protocol compliance based on types-tates that offers a great deal of flexibility in aliasing [1]. In our approach, API protocols are defined based on type states. Every reference is associated with a permission, and reasoning about permissions is appropriately conservative for the ""degree"" of possible aliasing admitted by a permission. This paper describes Plural, a tool to automatically enforce type state-based protocols using permissions in Java. API developers can specify protocols with simple annotations on methods and method parameters. A static flow analysis tracks permissions in code that uses specified APIs and issues warnings for possible protocol violations.";"Design, Languages, Reliability, Verification"
"Bollacker K., Evans C., Paritosh P., Sturge T., Taylor J.";"Freebase: A collaboratively created graph database for structuring human knowledge";"Freebase is a practical, scalable tuple database used to structure general human knowledge. The data in Freebase is collaboratively created, structured, and maintained. Free-base currently contains more than 125,000,000 tuples, more than 4000 types, and more than 7000 properties. Public read/write access to Freebase is allowed through an HTTP-based graph-query API using the Metaweb Query Language (MQL) as a data query and manipulation language. MQL provides an easy-to-use object-oriented interface to the tuple data in Freebase and is designed to facilitate the creation of collaborative, Web-based data-oriented applications.";"Design, Human factors, Languages"
"Beaton J., Myers B.A., Stylos J., Jeong S.Y., Xie Y.";"Usability evaluation for Enterprise SOA APIs";"SAP recently began offering access to web services through its Enterprise Service-Oriented Architecture (E-SOA) platform. It is in the best interest of SAP that its E-SOA service operations are easier for developers to use and understand, which will contribute to higher E-SOA adoption, and a more effective means of innovation on the part of business customers. To facilitate such a change, Carnegie Mellon University's Human-Computer Interaction Institute is working with SAP's E-SOA and Business Process Renovation Teams to analyze the E-SOA interfaces using HCI techniques and determine means by which developers assigned to create SOA APIs in general, and Enterprise SOA APIs in particular, can design superior interfaces. The identification of usable design patterns, and methodologies to determine these patterns, can streamline SOA projects for API developers and programmers who use SOA APIs. Copyright 2008 ACM.";"Api design, Enterprise SOA, SAP, Service-Oriented Architecture, Usability, Web services"
"Bruch M., Schäfer T., Mezini M.";"On evaluating recommender systems for API usages";"To ease framework understanding, tools have been developed that analyze existing framework instantiations to extract API usage patterns and present them to the user. However, detailed quantitative evaluations of such recommender systems are lacking. In this paper we present an automated evaluation process which extracts queries and expected results from existing code bases. This enables the validation of recommendation systems with large test beds in an objective manner by means of precision and recall measures. We demonstrate the applicability of our approach by evaluating an improvement of an existing API recommender tool that takes into account the framework-method context for recommendations. Copyright 2008 ACM."
"Glek T., Mandelin D.";"Using GCC instead of grep and sed";"Large codebases benefit from automatic assistance when enforcing correct API usage and performing large-scale refactoring. To make large-scale refactoring of the Mozilla codebase successful, we developed a static analysis framework based on a time-tested GCC compiler infrastructure featuring the expressiveness and ease of prototyping of a general-purpose scripting language. The presentation will describe our GCC plugin system and two generic static analysis plugins, Dehydra and Treehydra. Dehydra exposes a simplified view of the GCC AST, suitable for novice users and semantic-grep-style analyses. Treehydra exposes the GCC GIMPLE API. We also describe our static analysis applications and experience with the system."
"Khoroshilov A.V., Rubanov V.V., Shatokhin E.A.";"Automated formal testing of C API using T2C framework";"A problem of automated test development for checking basic functionality of program interfaces (API) is discussed. Different technologies and corresponding tools are surveyed. And T2C technology developed in ISPRAS is presented. The technology and associated tools facilitate development of ""medium quality"" (and ""medium cost"") tests. An important feature of T2C technology is that it enforces that each check in a developed test is explicitly linked to the corresponding place in the standard. T2C tools provide convenient means to create such linkage. The results of using T2C are considered by example of a project for testing interfaces of Linux system libraries defined by the LSB standard. © 2008 Springer-Verlag.";"compliance testing, Formal testing, medium-quality tests, parameterized tests"
"[No author name available]";"RSSE '08 - Proc. 2008 International Workshop on Recommendation Systems for Software Engineering, Co-located with the 16th ACM SIGSOFT International Symposium on the Foundations of Software Engineering";"The proceedings contain 14 papers. The topics discussed include: recommending method invocation context changes, not all classes are created equal: toward a recommendation system for focusing testing, potentials and challenges of recommendation systems for software development, on evaluating recommender systems for API usages, dimensions of tools for detecting software conflicts, understanding interaction differences between newcomer and expert programmers, what is the long-term impact of changes?, evaluating recommended applications, seven habits of a highly effective smell detector, towards an agent-based framework for guiding design exploration, improving the readability of defect reports, and a recommendation system for security requirements."
"Yeh R.B., Paepcke A., Klemmer S.R.";"Iterative design and evaluation of an event architecture for pen-and-paper interfaces";"This paper explores architectural support for interfaces combining pen, paper, and PC. We show how the eventbased approach common to GUIs can apply to augmented paper, and describe additions to address paper's distinguishing characteristics. To understand the developer experience of this architecture, we deployed the toolkit to 17 student teams for six weeks. Analysis of the developers' code provided insight into the appropriateness of events for paper UIs. The usage patterns we distilled informed a second iteration of the toolkit, which introduces techniques for integrating interactive and batched input handling, coordinating interactions across devices, and debugging paper applications. The study also revealed that programmers created gesture handlers by composing simple ink measurements. This desire for informal interactions inspired us to include abstractions for recognition. This work has implications beyond paper - designers of graphical tools can examine API usage to inform iterative toolkit development.";"Augmented paper, Device ensembles., Evaluation, Toolkits"
"Clausse J.-M., Fizeau A.H.";"Software structure for Vega/Chara instrument";"VEGA (Visible spEctroGraph and polArimeter) is one of the focal instruments of the CHARA array at Mount Wilson near Los Angeles. Its control system is based on techniques developed on the GI2T interferometer (Grand Interféromètre à 2 Télescopes) and on the SIRIUS fibered hyper telescope testbed at OCA (Observatoire de la Côte d'Azur). This article describes the software and electronics architecture of the instrument. It is based on local network architecture and uses also Virtual Private Network connections. The server part is based on Windows XP (VC++). The control software is on Linux (C, GTK). For the control of the science detector and the fringe tracking systems, distributed API use real-time techniques. The control software gathers all the necessary informations of the instrument. It allows an automatic management of the instrument by using an original task scheduler. This architecture intends to drive the instrument from remote sites, such as our institute in Sou h of France.";"Instrument control, Intensified detector, Interferometer, Real time software, Scheduler"
"[No author name available]";"3rd International Symposium on Leveraging Applications of Formal Methods, Verification and Validation, ISoLA 2008";"The proceedings contain 61 papers. The special focus in this conference is on Leveraging Applications of Formal Methods, Verification and Validation. The topics include: Architecture based specification and verification of embedded software systems, information system engineering supporting observation, orientation, decision, and compliant action, modelling coordination and compensation, animating event B models by formal data models, automated formal testing of C API using T2C framework, tailoring and optimising software for automotive multicore system, timing validation of automotive software, towards using reo for compliance-aware business process modeling, a use-case driven approach to formal service-oriented modelling, safety and response-time analysis of an automotive accident assistance service, a framework for analyzing and testing the performance of software services, assuring the satisfiability of sequential extended regular expressions, computing must and may alias to detect null pointer dereference, program verification by reduction to semi-algebraic systems solving, debugging statecharts via model-code traceability, formal use of design patterns and refactoring, a component-based access control monitor, navigating the requirements jungle, non-functional avionics requirements, measurement-based timing analysis, weaving a formal methods education with problem-based learning, encouraging the uptake of formal methods training in an industrial context, computer-supported collaborative learning with mind-maps, thinking in user-centric models, specialization and instantiation aspects of a standard process for developing educational modules, contexts and context awareness in view of the diagram predicate framework, the use of adaptive semantic hypermedia for ubiquitous collaboration systems, the use of formal ontology to specify context in ubiquitous computing, high service availability in MaTRICS for the OCS, the ASK system and the challenge of distributed knowledge discovery, requirements for ontology based design project assessment, organizing the worlds machine learning information, workflow testing, directed generation of test data for static semantics checker, optimizing the system observability level for diagnosability, weaving authentication and authorization requirements into the functional model of a system using Z promotion, simple gedanken experiments in leveraging applications of formal methods and composition of web services using wrappers."
"Chew B.N., Chang C.W., Salinas S.V., Liew S.C.";"Remote sensing measurements of aerosol optical thickness and correlation with in-situ air quality parameters during a biomass burning episode in Southeast Asia";"Smoke haze related to biomass burning is a recurring environmental problem in Southeast Asia which has affected air quality not only in the source regions, but also in the surrounding areas. Air quality monitoring stations and meteorological stations in the region provide valuable information on the concentrations of criteria pollutants such as sulphur dioxide, nitrogen oxide, carbon monoxide, ozone and particulate mass (PM 10) during the haze episodes. Due to the limited coverage of the air quality monitoring stations, it is difficult to study and monitor the spatial and temporal variability of the smoke haze caused by biomass burning, especially in areas without ground-based instrumentation. As such, in this paper, we combine the standard in-situ measurements of PM 10 with remote sensing imagery obtained from the Moderate Resolution Imaging Spectroradiometer (MODIS) on board the Terra and Aqua satellites. The columnar AOT is first derived from MODIS images for regions where PM 10 measurements are available and a correlation between AOT and PM 10 measurements is then established. Based on this empirical correlation, it is also shown that MODIS AOT can be used to estimate air quality categories as defined in the Air Pollutant Index (API) used by Malaysia's Department of Environment (DOE) and the Pollutant Standards Index (PSI) used by Singapore's National Environment Agency (NEA). With this integrated approach, we hope to complement and enhance current capabilities in monitoring air quality during the haze episodes.";"Aerosol optical thickness, Air quality, MODIS, Particulate matter"
"Stylos J., Myers B.A.";"The implications of method placement on API learnability";"To better understand what makes Application Programming Interfaces (APIs) hard to use and how to improve them, recent research has begun studying programmers' strategies and use of APIs. It was found that method placement - - on which class or classes a method is placed - - can have large usability impact in object-oriented APIs. This was because programmers often start their exploration of an API from one ""main"" object, and were slower finding other objects that were not referenced in the methods of the main object. For example, while mailServer.send(mailMessage) might make sense, if programmers often begin their API explorations from the MailMessage class, then this makes it harder to find the MailServer class than the alternative mailMessage. send(mailServer). This is interesting because many real APIs place methods essential to common objects on other, helper objects. Alternate versions of three different APIs were compared, and it was found that programmers gravitated toward the same starting classes and were dramatically faster - - between 2 to 11 times - - combining multiple objects when a method on the starting class referred to the other class. © 2008 ACM.";"APIs, Documentation, Frameworks, Libraries, Usability, User studies"
"Wagner S., Nielsen C.C.";"Usability and implementation experiences with cots products used as a distributed client platform";"This paper conveys some of the experiences with using commercial of the-shel (COTS) products as clients to Bluetooth enabled devices, which have no user interface of their own, but relies on the COTS products for user interaction. The COTS devices used include several different vendors' models of the Microsoft Pocket PCplatform (also known as Windows Mobile Professional or Classic) running NET Compact Framework, as well as a number of different models of Java enabled cell phones from Nokia, Siemens and Sony-Ericsson. The specific case study is with the Taxmaster4 Windows Mobile product used with BMW automobiles as a driving log application. The paper concludes that many usability problems exist when using COTS products. These may to some extend be overcome by pragmatic design decisions, but it is necessary that the COTS products hardware platform and application programming interfaces should become better suited to support distributed user interfaces than is the case today. This includes better support for basic user interface elements as well as supporting Bluetooth and other wireless technologies more reliably. These issues should be addressed by the vendors and manufactures of these platforms, not the application programmers. © 2008 IEEE.";"Bluetooth, cell phone, COTS, HCI, Mobile computing, PDA, Pervasive computing, Pocket PC, Usability, Windows Mobile, Wireless, activeSync"
"Eggen R., Jones C., Eggen M.";"Ruby, PHP, Perl, Python: A web efficiency comparison";"In our modern world with so much emphasis being placed on the web and on web services it is fitting to evaluate the most popular web based API for speed, usability, reliability and general over all productivity. This paper seeks to analyze and demarcate Ruby, Perl, Python, and PHP. Several web services are simultaneously requested via the Apache web server. The server accesses scripts in each language to generate data served to the client. Attention is given to ease of use, programmer difficulty, and performance of the applications once completed. A client-server scenario is constructed, timings are taken, and appropriate conclusions drawn.";"Perl, PHP, Python, Ruby, Web services"
"Tan Y.K.A., Kwoh L.K., Ong S.H.";"Texture mapping of 3-D building models using pose estimation of digital photographs";"A virtual 3-D city is a sophisticated application of geo-informatics systems as it is a representation of layouts, activities and functionalities of a real-world community. It is an integrated effort in the fields of computer graphics, remote sensing and engineering to model the appearance and dynamics of the real world. The primary aim is to introduce a feasible, yet compelling representation of the city in the virtual world. It will be an attractive option to view and explore the building architecture of the past, present and future without being encumbered by the constraints of reality. Visualization of city models in a virtual environment is a combination of many challenging and laborious tasks, one of which is the texturing of building models façade. To improve the overall photo-realistic quality and usability of the visualization platform, we can texture the building façade with oblique-view terrestrial digital photographs taken using commercially available cameras. This paper will show that we can automatically extract the building façade textures after pose estimation of the acquired image is done. The OpenGL camera must be properly initialized with the intrinsic parameters of the actual camera before pose estimation. After which the actual camera's location and orientation can be estimated directly by matching the relative pose between the rendered 3-D scene geometry and the information from the acquired image. It is important to obtain a good estimate of the camera's pose as the recovered parameters would affect the accuracy of extracted façade textures. A test example will be used to demonstrate the system of performing texture mapping using series of close-range photographs after pose estimation was carried out.";"Building, Photo-realism, Texture, Virtual reality, Visualization"
"Beaton J., Jeong S.Y., Xie Y., Stylos J., Myers B.A.";"Usability challenges for enterprise service-oriented architecture APIs";"An important part of many programming tasks is the use of libraries and other forms of Application Programming Interfaces (APIs). Programming via web services using a Service-Oriented Architecture (SOA) is an emerging form of API usage. Web services in a business context (called enterprise SOA or E-SOA) add additional complexity in terms of the number of the services, the variety of internal data structures, and service interdependencies. After altering existing Human-Computer Interaction (HCI) methodologies to address the unique context of software development for SOA, we evaluated a large E-SOA API and identified many usability challenges. Prominent results include difficulties developers encountered while assembling data structures in web service parameters, cycles of errors due to unclear control parameters within data structures, and difficulties with understanding long identifier names. We recommend a tolerance for unspecified objects in automatically-generated web service proxy code, consistent data structures in parameters across services, and encoding optional namespace schemes into WSDL files. © 2008 IEEE."
"Stylos J., Graf B., Busse D.K., Ziegler C., Ehret R., Karstens J.";"A case study of API redesign for improved usability";"As software grows more complex, software developers' productivity is increasingly defined by their ability to effectively reuse code. Even APIs (application programming interfaces) and other code explicitly intended for reuse are often difficult and time consuming for developers to use. This paper describes the user-centered design and evaluation process we evolved in redesigning SAP's BRFplus - a business rules engine, whose API was created for platform development, but which is now also increasingly being used by application developers - even though it was not initially designed with their specific needs in mind. Our API redesign attempts to take both the initial as well as the new emergent user requirements into account. A usability evaluation of our proposed changes to the API suggests that our user-centered design process was successful in helping to create an API that significantly improved users' productivity and better matches the different users' needs. © 2008 IEEE."
"Lobato C., Garcia A., Romanovsky A., Lucena C.";"An aspect-oriented software architecture for code mobility";"Mobile agents have come forward as a technique for tackling the complexity of open distributed applications. However, the pervasive nature of code mobility implies that it cannot be modularized using only object-oriented (OO) concepts. In fact, developers frequently evidence the presence of mobility scattering in their system's modules. Despite these problems, they usually rely on OO application programming interfaces (APIs) offered by the mobility platforms. Such classical API-oriented designs suffer a number of architectural restrictions, and there is a pressing need for empowering developers with an architectural framework supporting a flexible incorporation of code mobility in the agent applications. This work presents an aspect-oriented software architecture, called ArchM, ensuring that code mobility has an enhanced modularization and variability in agent systems, and is straightforwardly introduced in otherwise stationary agents. It addresses OO APIs' restrictions and is independent of specific platforms and applications. An ArchM implementation also overcomes fine-grained problems related to mobility tangling and scattering at the implementation level. The usefulness and usability of ArchM are assessed within the context of two case studies and through its composition with two mobility platforms. Copyright © 2008 John Wiley & Sons, Ltd.";"Aspect-oriented software development, Mobile agents, Reuse"
"Ratiu D., Jürjens J.";"Evaluating the reference and representation of domain concepts in APIs";"As libraries are the most widespread form of software reuse, the usability of their APIs substantially influences the productivity of programmers in all software development phuses. In this paper we develop a framework to characterize domain-specific APIs along two directions: 1) how can the API users reference the domain concepts implemented by the API, 2) how are the domain concepts internally represented in the API. We define metrics that allow the API developer for example to assess the conceptual complexity of his API and the non-uniformity and ambiguities introduced by the API's internal representations of domain concepts, which makes developing and maintaining software that uses the library difficult and error-prone. The aim is to be able to predict these difficulties already during the development of the API, and based on this feedback be able to develop better APIs up front, which will reduce the risks of these difficulties later. © 2008 IEEE."
"Bellotti F., Berta R., Margarone M., De Gloria A.";"oDect: an RFID-based object detection API to support applications development on mobile devices";"The RFID technology is becoming ever more popular in the development of ubiquitous computing applications. A full exploitation of the RFID potential requires the study and implementation of human-computer interaction (HCI) modalities to be able to support wide usability by the target audience. This implies the need for programming methodologies specifically dedicated to support the easy and efficient prototyping of applications to have feedback from early tests with users. On the basis of our field-working experience, we have designed oDect, a high-level language and platform-independent application programming interface (API), ad hoc designed to meet the needs of typical applications for mobile devices (smart phones and PDAs). oDect aims at allowing application developers to create their prototypes focusing on the needs of the final users, without having to care about the low-level software that interacts with the RFID hardware. Further, in an end-user developing (EUD) approach, oDect provides specific support for the application end-user herself to cope with typical problems of RFID applications in detecting objects. We describe in detail the features of the API and discuss the findings of a test with four programmers, where we analyse and evaluate the use of the API in four sample applications. We also present results of an end-user test, which investigated strengths and weaknesses of the territorial agenda (TA) concept. The TA is an RFID-based citizen guide that aids-through time- and location-based reminders-users in their daily activities in a city. The TA directly exploits EUD features of oDect, in particular concerning the possibility of linking detected objects with custom actions. Copyright © 2008 John Wiley & Sons, Ltd.";"Context awareness, Development tools, HCI with mobile devices, Interaction styles, Mobile applications, Programming languages, RFID, User interfaces, Wireless sensor networks"
"González-Vélez H., Cole M.";"An adaptive parallel pipeline pattern for grids";"This paper introduces an adaptive parallel pipeline pattern which follows the GRASP (Grid-Adaptive Structured Parallelism) methodology. GRASP is a generic methodology to incorporate structural information at compile time into a parallel program that enables it to adapt automatically to dynamic variations in resource performance. GRASP instruments the pipeline with a series of pragmatic rules, which depend on particular performance thresholds based on the computation/communication patterns of the program and the availability of resources in the grid. Our parallel pipeline pattern is implemented as a parameterisable C/MPI API using a variable-size input data vector and a stage function array. We have evaluated its efficiency using a numerical benchmark stage function in a non-dedicated computational grid environment. ©2008 IEEE.";"Algorithmic skeletons, Grid computing, Grid resource management, Parallel patterns, Parallel programming, Structured parallelism"
"Hoefler T., Lumsdaine A.";"Optimizing non-blocking collective operations for InfiniBand";"Non-blocking collective operations have recently been shown to be a promising complementary approach for overlapping communication and computation in parallel applications. However, in order to maximize the performance and usability of these operations it is important that they progress concurrently with the application without introducing CPU overhead and without requiring explicit user intervention. While studying non-blocking collective operations in the context of our portable library (libNBC), we found that most MPI implementations do not sufficienctly support overlap over the InfiniBand network. To address this issue, we developed a low-level communication layer for libNBC based on the Open Fabrics InfiniBand verbs API. With this layer we are able to achieve high degrees of overlap without the need to explicitly progress the communication operations. We show that the communication overhead of parallel application kernels can be reduced up to 92% while not requiring user intervention to make progress. ©2008 IEEE."
"Ivanyukovich A., Marchese M., Giunchiglia F.";"ScienceTreks: An autonomous digital library system";"Purpose - The purpose of this paper is to provide support for automation of the annotation process of large corpora of digital content. Design/methodology/approach - The paper presents and discusses an information extraction pipeline from digital document acquisition to information extraction, processing and management. An overall architecture that supports such an extraction pipeline is detailed and discussed. Findings - The proposed pipeline is implemented in a working prototype of an autonomous digital library (A-DL) system called ScienceTreks that: supports a broad range of methods for document acquisition, does not rely on any external information sources and is solely based on the existing information in the document itself and in the overall set in a given digital archive, and provides application programming interfaces (API) to support easy integration of external systems and tools in the existing pipeline. Practical implications - The proposed A-DL system can be used in automating end-to-end information retrieval and processing, supporting the control and elimination of error-prone human intervention in the process. Originality/value - High quality automatic metadata extraction is a crucial step in the move from linguistic entities to logical entities, relation information and logical relations, and therefore to the semantic level of digital library usability. This in turn creates the opportunity for value-added services within existing and future semantic-enabled digital library systems. © Emerald Group Publishing Limited.";"Automation, Digital libraries, Information retrieval, Library systems"
"Krumsiek J., Friedel C.C., Zimmer R.";"ProCope - Protein complex prediction and evaluation";"Recent advances in high-throughput technology have increased the quantity of available data on protein complexes and stimulated the development of many new prediction methods. In this article, we present ProCope, a Java software suite for the prediction and evaluation of protein complexes from affinity purification experiments which integrates the major methods for calculating interaction scores and predicting protein complexes published over the last years. Methods can be accessed via a graphical user interface, command line tools and a Java API. Using ProCope, existing algorithms can be applied quickly and reproducibly on new experimental results, individual steps of the different algorithms can be combined in new and innovative ways and new methods can be implemented and integrated in the existing prediction framework. © The Author 2008. Published by Oxford University Press. All rights reserved."
"Homan M., Amor R., Tempero E.";"Indexing the Java API using source code";"The basic idea behind software reuse is that software developers use reusable components found in software repositories to reduce the amount of code that has to be written and so increase productivity. A problem arises, however, if the repository is too big - it becomes difficult to find relevant components. What is needed is an effective means to query repositories. Most approaches to developing such means involves creating a good index to which the queries can be applied. Developing a good index requires identifying the relevant information on which to base the index. In this paper, we present the results of a project that used source code as the basis for the index. © 2008 IEEE.";"Java standard API, Reuse, Software repositories, Source code analysis"
"Vaughan R.";"Massively multi-robot simulation in stage";"Stage is a C++ software library that simulates multiple mobile robots. Stage version 2, as the simulation backend for the Player/Stage system, may be the most commonly used robot simulator in research and university teaching today. Development of Stage version 3 has focused on improving scalability, usability, and portability. This paper examines Stage's scalability. We propose a simple benchmark for multi-robot simulator performance, and present results for Stage. Run time is shown to scale approximately linearly with population size up to 100,000 robots. For example, Stage simulates 1 simple robot at around 1,000 times faster than real time, and 1,000 simple robots at around real time. These results suggest that Stage may be useful for swarm robotics researchers who would otherwise use custom simulators, with their attendant disadvantages in terms of code reuse and transparency. © Springer Science + Business Media, LLC 2008.";"Multi-robot, Player/stage, Simulation, Stage, Swarm"
"Balakrishnan G., Reps T.";"Analyzing stripped device-driver executables";"This paper sketches the design and implementation of Device-Driver Analyzer for x86 (DDA/x86), a prototype analysis tool for finding bugs in stripped Windows device-driver executables (i.e., when neither source code nor symbol-table/debugging information is available), and presents a case study. DDA/x86 was able to find known bugs (previously discovered by source-code-based analysis tools) along with useful error traces, while having a reasonably low false-positive rate. This work represents the first known application of automatic program verification/analysis to stripped industrial executables, and allows one to check that an executable does not violate known API usage rules (rather than simply trusting that the implementation is correct). © 2008 Springer-Verlag Berlin Heidelberg."
"Kurzyniec D., Sunderam V., Sławińska M.";"REVENTS: Facilitating event-driven distributed HPC applications";"Modern scientific applications that need to share geographically scattered resources and dynamically adapt to changes in the environment pose challenges to traditional parallel and distributed programming paradigms. Distributed component frameworks attempt to address the demands of contemporary HPC applications by enabling coarse-grained decomposition and loose coupling. Nonetheless, components usually communicate via synchronous RPC, which is not suitable for interactive applications. This paper introduces a novel distributed event notification system, called REVENTS, which enables both synchronous and decentralized asynchronous component interactions. The REVENTS system is based on a topic-list publisher-subscriber model. It integrates and enhances common technologies for messaging, events, and group communication. The article introduces the REVENTS API, its reference implementation, and its application in the H2O metacomputing framework. Presented experimental results confirm REVENTS' usability in distributed HPC scenarios. © 2008 Springer-Verlag Berlin Heidelberg.";"Distributed event system, Loosely coupled system, Middleware"
"Fink S.J., Yahav E., Dor N., Ramalingam G., Geay E.";"Effective typestate verification in the presence of aliasing";"This article addresses the challenge of sound typestate verification, with acceptable precision, for real-world Java programs. We present a novel framework for verification of typestate properties, including several new techniques to precisely treat aliases without undue performance costs. In particular, we present a flow-sensitive, context-sensitive, integrated verifier that utilizes a parametric abstract domain combining typestate and aliasing information. To scale to real programs without compromising precision, we present a staged verification system in which faster verifiers run as early stages which reduce the workload for later, more precise, stages. We have evaluated our framework on a number of real Java programs, checking correct API usage for various Java standard libraries. The results show that our approach scales to hundreds of thousands of lines of code, and verifies correctness for 93% of the potential points of failure. © 2008 ACM.";"Alias analysis, Program verification, Typestate"
"Song Y., Tanaka Y., Nakada H., Sekiguchi S.";"Towards simplifying grid enablement for scientific applications";"It is very complex to implement and execute grid applications in a dynamic grid environment due to scale and heterogeneity. Consequently, we propose a solution to lower the barrier to implement and execute grid applications in this paper. In order to facilitate adapting scientific applications to a grid environment, GridRPC has been standardized by OGF (Open Grid Forum) for remote procedure calls over the grid. However, the GridRPC standard defines API in C only, while most scientific and engineering applications are implemented in Fortran. To avoid the cumbersome development of Fortran wrappers for such applications, we then have proposed GricRPC Fortran90 bindings and implemented the Fortran90 API based on Ninf-G which is one of the reference implementations of the GridRPC standard. As for the execution, we have developed a resource allocator called GRPLib. The GRPLib can provide applications with availability-guaranteed and reliability-evaluated resources, which frees users from dealing with faults to some extent during executions. A framework which combines the Ninf-G and GRPLib in Fortran90 has also been developed. This framework has been successfully used to gridify a Fortran application called MD/QM (molecular dynamics/quantum mechanical application) simulation program. This paper therefore presents the Fortran90 bindings of the GridRPC, describes the GRPLib, discusses the integrated framework, reports a case study, and concludes the simplicity and usability of this solution. © 2008 Global Information Publisher (H.K) Co., Limited. All rights reserved."
"Yang Y., Chen X., Gopalakrishnan G., Kirby R.M.";"Distributed dynamic partial order reduction based verification of threaded software";"Runtime (dynamic) model checking is a promising verification methodology for real-world threaded software because of its many features, the prominent ones being: (i) it avoids the need to extract a model and instead runs the actual code, and (ii) the precision of information available at run-time allows techniques such as dynamic partial order reduction (DPOR) [1] to dramatically cut down the number of interleavings examined. Unfortunately, DPOR does not have many implementations for real thread libraries such as POSIX Pthreads, and suffers from high computational overheads due to a stateless search that requires re-executions. In our previous work [2], we designed a runtime model checker, inspect, that overcomes the first of these drawbacks. Inspect has been shown capable of detecting data races, deadlocks and other incorrect API usages in real-world PThreads C programs. In this paper, we describe a distributed version of inspect, which implements an extended DPOR algorithm. Our two key contributions are: (i) a practical algorithm for distributed dynamic partial order reduction, (ii) the innovations that helped distributed inspect attain nearly linear (with respect to the number of CPUs) speedup on realistic examples. © Springer-Verlag Berlin Heidelberg 2007."
"Jian S., Wei G.";"Development of routing application of SCA-based software defined radio";"Software Communications Architecture (SCA) has become the standard framework followed by the current developing software defined radios (SDR) all over the world. So it is significant for us to develop some essential applications in such an SCA-based SDR. In this paper, we propose an implementation scheme of routing application based on SCA. First, the framework and functions of SCA are introduced briefly. In the following, routing technology is discussed in such a software radio network with multi-layer dynamic topology. Based on SCA, the system architecture on which the routing application depends is presented. We put emphasis on the design of routing components and application program interface (API). Using a sequence diagram, the interaction among Routing Selection Component, Adaptive Channel Selection Component and MAC Components, is shown clearly. ©2006 IEEE."
"Lee S.-Y., Choi B.-U.";"Certification tools of ubiquitous mobile platform";"The Wireless Internet Platform for Interoperability (WIPI) is a wireless Internet standard platform in Korea. The WIPI is composed of four main parts including the hardware abstraction layer (HAL), a runtime engine, and two standard application programming interfaces (APIs, WIPI-C and WIPIJava). A certification process is required to ensure the interoperability of the developed WIPI platform. In this paper, we propose the platform certification toolkit (PCT) and HAL certification toolkit (HCT) as WIPI specification certification tools. The PCT certifies the functions of the platform and standard APIs, whereas The HCT certifies the HAL API. Users can find precisely where an error occurred by using the tools, which facilitate the debugging processes and reduce development time. We describe the architecture of the PCT and the HCT and show the implementations. And, we introduce the case study applying them to the real WIPI reference implementations. © Springer-Verlag Berlin Heidelberg 2007.";"Certification tool, HAL, HCT, PCT, Platform, WIPI"
"Acharya M., Xie T., Pei J., Xu J.";"Mining API patterns as partial orders from source code: From usage scenarios to specifications";"A software system interacts with third-party libraries through various APIs. Using these library APIs often needs tofollow certain usage patterns. Furthermore, ordering rules (specifications) exist between APIs, and these rules govern the secure and robust operation of the system using these APIs. But these patterns and rules may not be well documented by the API developers. Previous approaches mine frequent association rules, itemsets, or subsequences that capture API call patterns shared by API client code. However, these frequent API patterns cannot completely capture some useful orderings shared by APIs, especially when multiple APIs are involved across different procedures. In this paper, we present a framework to automatically extract usage scenarios among user-specified APIs as partial orders, directly from the source code (API client code). We adapt a model checker to generate interprocedural control-flow-sensitive static traces related to the APIs of interest. Different API usage scenarios are extracted from the static traces by our scenario extraction algorithm and fed to a miner. The miner summarizes different usage scenarios as compact partial orders. Specifications are extracted from the frequent partial orders using our specification extraction algorithm. Our experience of applying the framework on 72 X11 clients with 200K LOC in total has shown that theextracted API partial orders are useful in assisting effective API reuse and checking. Copyright 2007 ACM.";"API patterns, Mining, Partial orders, Specification, Usage scenarios"
"Kitagawa H., Watanabe Y.";"Stream data management based on integration of a stream processing engine and databases";"Recent developments in network and sensor device technologies enable us to easily obtain real-world information, such as locations of moving objects, weather information, news, and stock prices. These data are continuously supplied, and they are regarded as data streams. Because of the dramatical increase of streaming data, their management and utilization has become more and more important. This paper describes a data stream management system named Harmonica. Harmonica employs an architecture combining our stream processing engine named Stream-Spinner and relational DBMSs. Based on the architecture, the system processes both continuous queries and traditional one-shot queries. Moreover, Harmonica supports continuous persistence requirements for streaming data as well as queries including selection, join, projection, and user-defined functions over data streams. Users can also specify continuous queries that integrate streaming data and persistent data stored in databases. Using the Harmonica API, users can develop a variety of applications coping with different continuous steaming data and data stored in databases. Our system can be deployed in network environments to achieve efficient and dependable distributed stream processing. © 2007 IEEE."
"Stylos J., Myers B.";"Mapping the space of API design decisions";"When creating new application programming interfaces (APIs), designers must make many decisions. These decisions affect the quality of the resulting APIs in terms of performance (such as speed and memory usage), power (expressiveness, extensibility and evolvability) and usability (learnability, productivity and error prevention). Experienced API designers have written recommendations on how to design APIs, offering their opinions on various API design decisions. Additionally, empirical research has begun to measure the usability tradeoffs of specific design decisions. While previous work has offered specific suggestions, there has not been a clear description of the design space of all possible API design decisions, or the quality attributes that these decisions affect. This paper puts existing API design recommendations into context by mapping out the space of API design decisions and API quality attributes. © 2007 IEEE."
"Xu G., Lu F., Yu H., Xu Z.";"A distributed parallel computing environment for bioinformatics problems";"Certain bioinformatics research, such as sequence alignment, alternative splicing, protein function/structure prediction, gene identify, bio-chip data analysis, and so on, requires massive computing power, which is hardly available in a single computing node. In order to facilitate bioinformatics research, we have designed and implemented a distributed and parallel computing environment with grid technology, in which, biologists can solve bioinformatics problems using distributed computing resources in parallel and reduce execution time. In this environment, the computing power and program information of computing nodes are described with XML documents. A web service named Local Resource Management Service is deployed on each computing node so that the distributed resources can be accessed in a uniform manner. With an API suite, biologists can use distributed computing resources in parallel easily in their applications. Further more, users can monitor the status of distributed resources dynamically on the portal. A real use case of alternative splicing is also presented, through which we have analyzed the usability, efficiency, and stability of the environment. ©2007 IEEE."
"Woemdl W., Yousef H.";"An adaptation manager for personalized mobile web searches";"Context-aware and personalized information access becomes more and more important, especially in a mobile scenario. In this paper, we present an Adaptation Manager which customizes Web searches to a user's context and profile attributes. The approach allows for reuse of personal information for different services such as the Google Web Service API. We identify personalization components as parts of our Adaptation Manager and explain the design of the system. We have also implemented the most important parts of the system and thereby show the usability of the approach. Our solution is extensible, for example to incorporate a rule system to (semi-)automatically switch between services.";"Context, Context-aware applications, Mobile web, Personalization, User profile, Web searches"
"Lim S.C., Lowe S., Koempel J.";"Application of visual programming to Web mash up development";"The ongoing adoption of the latest Web development patterns such as AJAX is helping to enhance the user experience on the Web. Moreover, there is now API-based support from various vendors that allow seamless fusion of disparate data sources into a single application. However, the barrier for Web designers to integrate such features into their Web applications remains high. This hampers a wider proliferation of such novel Web applications. In this paper, we conduct an experiment to see whether visual programming is appropriate for allowing Web designers integrate the aforementioned features. For the experiment, we have developed a prototype, tentatively named WIPER that allows Web designers to incorporate pre-built JavaScript components into live Web pages using drag-and-drop. We combined rapid revision with usability testing to iteratively advance our prototype. Working with users, we have learned that with some targeted refinements, visual programming paradigm can be very effective in achieving our goal. © Springer-Verlag Berlin Heidelberg 2007.";"Dataflow architecture, End-user programming, JavaScript, Rapid prototyping, Visual programming"
"Juanjuan J., Koskinen J., Ruokonen A., Systä T.";"Constructing usage scenarios for API redocumentation";"Software development relies heavily on reusable libraries and software components. For correct use of the provided API, proper documentation is needed. API usage is often demonstrated by giving example applications and code samples. In this paper we propose an approach for mining such usage scenarios from run-time communication between sample applications and the API. This is done automatically by first monitoring the API usage of sample applications, then filtering the generated traces, and finally synthesizing the sequence diagrams and illustrating them in a well-formed way as UML2 sequence diagrams. Such usage scenarios support the software engineer in comprehending the usage of the API. With proper tool support they can also be used for validating other applications ' API usage and for generating code for a new application using the same API. ©2007 IEEE."
"Ellis B., Stylos J., Myers B.";"The factory pattern in API design: A usability evaluation";"The usability of software APIs is an important and infrequently researched topic. A user study comparing the usability of the factory pattern and constructors in API designs found highly significant results indicating that factories are detrimental to API usability in several varied situations. The results showed that users require significantly more time (p = 0.005) to construct an object with a factory than with a constructor while performing both context-sensitive and contextfree tasks. These results suggest that the use of factories can and should be avoided in many cases where other techniques, such as constructors or class clusters, can be used instead. ©2007 IEEE."
"Stylos J., Clarke S.";"Usability implications of requiring parameters in objects' constructors";"The usability of APIs is increasingly important to programmer productivity. Based on experience with usability studies of specific APIs, techniques were explored for studying the usability of design choices common to many APIs. A comparative study was performed to assess how professional programmers use APIs with required parameters in objects' constructors as opposed to parameterless ""default"" constructors. It was hypothesized that required parameters would create more usable and self-documenting APIs by guiding programmers toward the correct use of objects and preventing errors. However, in the study, it was found that, contrary to expectations, programmers strongly preferred and were more effective with APIs that did not require constructor parameters. Participants' behavior was analyzed using the cognitive dimensions framework, and revealing that required constructor parameters interfere with common learning strategies, causing undesirable premature commitment. © 2007 IEEE."
"Nirnimesh, Harish P., Narayanan P.J.";"Garuda: A scalable tiled display wall using commodity PCs";"Cluster-based tiled display walls can provide cost-effective and scalable displays with high resolution and a large display area. The software to drive them needs to scale too if arbitrarily large displays are to be built. Chromium is a popular software API used to construct such displays. Chromium transparently renders any OpenGL application to a tiled display by partitioning and sending individual OpenGL primitives to each client per frame. Visualization applications often deal with massive geometric data with millions of primitives. Transmitting them every frame results in huge network requirements that adversely affect the scalability of the system. In this paper, we present Garuda, a client-server-based display wall framework that uses off-the-shelf hardware and a standard network. Garuda Is scalable to large tile configurations and massive environments. It can transparently render any application built using the Open Scene Graph (OSG) API to a tiled display without any modification by the user. The Garuda server uses an object-based scene structure represented using a scene graph. The server determines the objects visible to each display tile using a novel adaptive algorithm that culls the scene graph to a hierarchy of frustums. Required parts of the scene graph are transmitted to the clients, which cache them to exploit the interframe redundancy. A multicast-based protocol is used to transmit the geometry to exploit the spatial redundancy present in tiled display systems. A geometry push philosophy from the server helps keep the clients in sync with one another. Neither the server nor a client needs to render the entire scene, making the system suitable for interactive rendering of massive models. Transparent rendering is achieved by intercepting the cull, draw, and swap functions of OSG and replacing them with our own. We demonstrate the performance and scalability of the Garuda system for different configurations of display wall. We also show that the server and network loads grow sublinearly with the increase in the number of tiles, which makes our scheme suitable to construct very large displays. © 2007 IEEE.";"Large-scale displays, Parallel visualization and graphics clusters, Visualization over networks"
"Rich C., Sidner C.L.";"DiamondHelp: A generic collaborative task guidance system";"DiamondHelp is a generic collaborative task guidance system motivated by the current usability crisis in high-tech home products. It combines an application-independent conversational interface (adapted from online chat programs) with an application-specific direct-manipulation interface. DiamondHelp is implemented in Java and uses Collagen for representing and using task models. Copyright © 2007, Association for the Advancement of Artificial Intelligence. All rights reserved."
"Mitter F., Stopper M.";"Advantages of using language integrated queries technology";"Current object oriented programming languages require additional application programming interfaces (API's) to access the stored data in relational databases. Therefore an investment of learning-overhead is necessary. Additionally missing compiler support and IntelliSense feature do not simplify the situation as well as the case for doubling-up possible error sources regarding to be on the way in two worlds. A combination of features in upcoming Microsoft C# 3.0 (generics, anonymous delegates, lambda expressions, query expressions - LINQ) can achieve the desired goals without facing these disadvantages. While in beta phase this solution lacks usability, but Microsoft company announced to implement LINQ in Visual Studio 2008 (Codename Orcas) with many more upgrades like a control element for an appropriate data source. Substitutional there are different object relational mappers available that image database tables in objects, but if the company's development progress will be as expected, after all LINQ technology would be the most effective solution for the creation of data driven applications.";".net framework technology, Compile time syntax checking, Generic query syntax, Language integrated query"
"Xie T., Pei J.";"MAPO: Mining API usages from open source repositories";"To improve software productivity, when constructing new software systems, developers often reuse existing class libraries or frameworks by invoking their APIs. Those APIs, however, are often complex and not well documented, posing barriers for developers to use them in new client code. To get familiar with how those APIs are used, developers may search the Web using a general search engine to find relevant documents or code examples. Developers can also use a source code search engine to search open source repositories for source files that use the same APIs. Nevertheless, the number of returned source files is often large. It is difficult for developers to learn API usages from a large number of returned results. In order to help developers understand API usages and write API client code more effectively, we have developed an API usage mining framework and its supporting tool called MAPO (for Mining API usages from Open source repositories). Given a query that describes a method, class, or package for an API, MAPO leverages the existing source code search engines to gather relevant source files and conducts data mining. The mining leads to a short list of frequent API usages for developers to inspect. MAPO currently consists of five components: a code search engine, a source code analyzer, a sequence preprocessor, a frequent sequence miner, and a frequent sequence post processor. We have examined the effectiveness of MAPO using a set of various queries. The preliminary results show that the framework is practical for providing informative and succinct API usage patterns. Copyright 2006 ACM.";"application programming interfaces, mining software repositories, program comprehension"
"Ball T., Bounimova E., Cook B., Levin V., Lichtenberg J., McGarvey C., Ondrusek B., Rajamani S.K., Ustuner A.";"Thorough static analysis of device drivers";"Bugs in kernel-level device drivers cause 85% of the system crashes in the Windows XP operating system [44]. One of the sources of these errors is the complexity of the Windows driver API itself: programmers must master a complex set of rules about how to use the driver API in order to create drivers that are good clients of the kernel. We have built a static analysis engine that finds API usage errors in C programs. The Static Driver Verifier tool (SDV) uses this engine to find kernel API usage errors in a driver. SDV includes models of the OS and the environment of the device driver, and over sixty API usage rules. SDV is intended to be used by driver developers ""out of the box."" Thus, it has stringent requirements: (1) complete automation with no input from the user, (2) a low rate of false errors. We discuss the techniques used in SDV to meet these requirements, and empirical results from running SDV on over one hundred Windows device drivers.";"Formal verification, Software model checking"
"[No author name available]";"Proceedings of the 2006 International Workshop on Mining Software Repositories, MSR '06, Co-located with the 28th International Conference on Software Engineering, ICSE 2006";"The proceedings contain 41 papers. The topics discussed include: mining large software compilations over time: another perspective of software evolution, scenarios for mining the software architecture evolution, productivity analysis of Japanese enterprise software development projects, coupling and cohesion measures for evaluation of component reusability, the evolution radar: visualizing integrated logical coupling information, an open framework for CVS repository querying, analysis and visualization, mining sequences of changed-files from version histories, MAPO: mining API usages from open sourch repositories, detecting similar java classes using tree algorithms, mining version archives for co-changed lines, concern based mining of heterogeneous software repositories, mining eclipse for cross-cutting concerns, predicting defect densities in source code files with decision tree learners, and mining email social networks."
"Sormaz D.N., Pisipati D.V., Borse P.A.";"Virtual manufacturing of milling operations with multiple tool paths";"Virtual manufacturing (visualisation and animation of a manufacturing process) provide the user with visual feed back in order to understand relations between the data in the process plan. The paper presents a framework, a procedure and an object-oriented prototype for virtual manufacturing of milling processes. Visualisation model is generated through three steps: geometric model, kinematic model and animation model. In the first step, geometric model, the feature geometry is analysed and corresponding tool path patterns are generated, and initial and final work piece geometry computed using stock and feature geometric models. Kinematic model is generated by segmentation of end milling processing time into intervals for each tool path segment and identification of part/tool engagement and disengagement relations. The third step, animation model, creates objects necessary for virtual manufacturing of the process in virtual 3D world. The user-friendly prototype has been implemented in java using java3d API. User is able to experiment with different values of the tool path parameters and visually inspect results in order to select the most suitable ones. Copyright © 2006 Inderscience Enterprises Ltd.";"Computer-Aided Manufacturing (CAM), Java3d, NC verification, Process planning, Process visualisation, Virtual reality"
"Holmes R., Walker R.J., Murphy G.C.";"Approximate structural context matching: An approach to recommend relevant examples";"When coding to an application programming interface (API), developers often encounter difficulties, unsure of which class to subclass, which objects to instantiate, and which methods to call. Example source code that demonstrates the use of the API can help developers make progress on their task. This paper describes an approach to provide such examples in which the structure of the source code that the developer is writing is matched heuristically to a repository of source code that uses the API. The structural context needed to query the repository is extracted automatically from the code, freeing the developer from learning a query language or from writing their code in a particular style. The repository is generated automatically from existing applications, avoiding the need for handcrafted examples. We demonstrate that the approach is effective, efficient, and more reliable than traditional alternatives through four empirical studies. © 2006 IEEE.";"API usage, Example recommendation, Heuristic search, Strathcona, Structural context"
"Stylos J.";"Informing API design through usability studies of API design choices: A research abstract";"Using APIs is a common and often difficult task for developers. Successful API designs can guide users of an API and reduce their dependence on documentation, however API design is far from a science. Usability lab studies have been shown to be successful at improving the usability of specific APIs, however these are expensive and not always possible to run for every API. This paper describes an approach to generalize from studies of specific APIs to investigate the usability impact of design choices that commonly arise in the creation of APIs. Based on these results we will inform the design of many new APIs. A preliminary usability study of whether or not to require constructor parameters confirms our belief that the answer to common design decisions is not always obvious, and making the wrong choice can have a strong negative impact on usability for large groups of API users. © 2006 IEEE."
"Fink S., Yahav E., Dor N., Ramalingam G., Geav E.";"Effective typestate verification in the presence of aliasing";"This paper addresses the challenge of sound typestate verification, with acceptable precision, for real-world Java programs. We present a novel framework for verification of typestate properties, including several new techniques to precisely treat aliases without undue performance costs. In particular, we present a flow-sensitive, context-sensitive, integrated verifier that utilizes a parametric abstract domain combining typestate and aliasing information. To scale to real programs without compromising precision, we present a staged verification system in which faster verifiers run as early stages which reduce the workload for later, more precise, stages. We have evaluated our framework on a number of real Java programs, checking correct API usage for various Java standard libraries. The results show that our approach scales to hundreds of thousands of lines of code, and verifies correctness for 93% of the potential points of failure. Copyright 2006 ACM.";"Alias analysis, Program verification, Typestate"
"Gokhale P.S.";"Innovative approach for emission monitoring and control";"This paper will describe the implementation of Membrane-based vapor recovery system and unconventional CEMS applied in Methyl Tertiary Butyl ether (MTBE) and Methanol plants which was commissioned and in operation at Jubail, Saudi Arabia. MTBE is highly volatile and hazardous fuel additive used as oxygenate to boost the octane number of gasoline. A project was commissioned for loading MTBE tankers to comply with API using bottom-loading methodology. Local environmental regulations mandated that HC loading with a rate equal or more than should have Vapor control to avoid release of hydrocarbon to atmosphere during loading operation. This paper will describe how the environmental control was achieved and the system functionality. CEMS was required to be installed on four auxiliary Boilers to comply with the local environmental regulations for MTBE & Methanol plant Boilers for monitoring Carbon monoxide (CO) emission thru flue gas stack. CO emission monitoring was necessary since the code dictated that any fired furnace burning hazardous hydrocarbon waste as fuel shall monitor and maintain CO emission below 100 PPM. Paper will describe how an unconventional CEMS. System was installed and in operation for last two years and benefits realized. Copyright 2006 by ISA."
"Lobato C., Garcia A., Lucena C., Romanovsky A.";"A modular implementation framework for code mobility";"With the growing popularity of open distributed applications, mobile agents have naturally emerged as the fundamental technique for tackling the complexity of the emerging applications. However, the pervasive nature of code mobility issues implies that their implementation cannot be modularized based only on object-oriented (OO) abstractions and mechanisms. In fact, programmers of complex mobile agent systems frequently evidence the presence of mobility tangling and scattering in the modules of their systems. Despite these modularity breakdowns caused by code mobility, the developers have mostly relied on OO application programming interfaces (APIs) from mobility platforms and on the Java programming language. As a consequence, there is a pressing need for empowering developers with a modular implementation framework that supports a transparent, flexible incorporation of code mobility-specific capabilities into their applications. This paper presents an aspect-oriented software framework, called AspectM, that ensures: (1) improved modularization of the code mobility issues, (2) a seamless introduction of code mobility into stationary agents, and (3) overall enhanced variability of the mobile agent systems, such as flexible integration of these systems with distinct mobility platforms. The usefulness and usability of the AspectM framework has been assessed in the context of two medium-sized case studies from different application domains, and through its composition with two mobility platforms. Copyright 2006 ACM.";"Aspect-oriented programming, Mobile agent, Mobility platform"
"Lobato C., Garcia A., Lucena C., Romanovsky A.";"A modular implementation framework for code mobility";"With the growing popularity of open distributed applications, mobile agents have naturally emerged as the fundamental technique for tackling the complexity of the emerging applications. However, the pervasive nature of code mobility issues implies that their implementation cannot be modularized based only on object-oriented (OO) abstractions and mechanisms. In fact, programmers of complex mobile agent systems frequently evidence the presence of mobility tangling and scattering in the modules of their systems. Despite these modularity breakdowns caused by code mobility, the developers have mostly relied on OO application programming interfaces (APIs) from mobility platforms and on the Java programming language. As a consequence, there is a pressing need for empowering developers with a modular implementation framework that supports a transparent, flexible incorporation of code mobility-specific capabilities into their applications. This paper presents an aspectoriented software framework, called AspectM, that ensures: (1) improved modularization of the code mobility issues, (2) a seamless introduction of code mobility into stationary agents, and (3) overall enhanced variability of the mobile agent systems, such as flexible integration of these systems with distinct mobility platforms. The usefulness and usability of the AspectM framework has been assessed in the context of two medium-sized case studies from different application domains, and through its composition with two mobility platforms. Copyright 2006 ACM.";"Aspect-oriented programming, Mobile agent, Mobility platform"
"Pietsch M., Schlaefke A., Vogl T.J., Bergh B.";"Development and evaluation of different methods to assess download and display time of image web systems";"Objectives: The aim of this study was to develop and verify different methods of measuring time-to-display (TTD) for radiological images with image web systems (IWS). The process should be automatable in order to repeatedly perform a large number of measurements without human interaction. Materials and Methods: Three methods were defined and compared with respect to usability, stability, and quality of results. Method 1 was based on Windows 2000 Performance Monitor, whereas method 2 employed phototransistors taped to the screen and connected to a separate PC. A software tool developed for method 3, which used Windows application programming interface (API) function, calls to read the color code assigned to specific pixels on the screen. Results: Method 3 proved to be the most reliable and easy to automate. The accuracy is practically equivalent to method 2, but it proved to be far more automatable. Method 1 produced the largest mean error, was easily disturbed, but was also easy to set up and provided additional insights into the system's architecture especially if combined with method 3. Conclusions: To measure the performance of image distribution systems, any of these methods can be used, but method 3 proved to be superior. © 2006 SCAR (Society for Computer Applications in Radiology).";"Image compression, Image distribution, Internet technology, PACS (picture archiving and communication systems), Performance measurement, Web-based, WWW (world wide web)"
"Sun C., Xia S., Sun D., Chen D., Shen H., Cai W.";"Transparent adaptation of single-user applications for multi-user real-time collaboration";"Single-user interactive computer applications are pervasive in our daily lives and work. Leveraging single-user applications for supporting multi-user collaboration has the potential to significantly increase the availability and improve the usability of collaborative applications. In this article, we report an innovative Transparent Adaptation (TA) approach and associated supporting techniques that can be used to convert existing and new single-user applications into collaborative ones, without changing the source code of the original application. The cornerstone of the TA approach is the operational transformation (OT) technique and the method of adapting the single-user application programming interface to the data and operation models of OT. This approach and supporting techniques were developed and tested in the process of transparently converting two commercial off-the-shelf single-user applications (Microsoft Word and PowerPoint) into real-time collaborative applications, called CoWord and CoPowerPoint, respectively. CoWord and CoPowerPoint not only retain the functionalities and look-and-feel of their single-user counterparts, but also provide advanced multi-user collaboration capabilities for supporting multiple interaction paradigms, ranging from concurrent and free interaction to sequential and synchronized interaction, and for supporting detailed workspace awareness, including multi-user telepointers and radar views. The TA approach and generic collaboration engine software component developed from this work are potentially applicable and reusable in adapting a wide range of single-user applications. © 2006 ACM.";"Application sharing, Computer-supported cooperative work, CoPowerPoint, CoWord, Operational transformation, Transparent adaptation"
"[No author name available]";"Proceedings of the 3rd International Conference on Mobile Technology, Applications and Systems";"The proceedings contain 70 papers. The topics discussed include: conception and simulation of energy-efficient AODV protocol in ad hoc networks, enabling seamless vertical handovers using unified link-layer API, context handling in a pervasive computing system framework, backbone-based location-aided routing algorithm to reduce control packets of AODV protocol, performance of a multiband impulse radio UWB architecture, design and applications of wireless SET protocol, challenges in multi-mode transmitter design, towards implicit interaction by using wearable interaction device sensors for more than one task, mobile phones as tool to increase communication and location awareness of users, cyberanthropology of mobility, developing design guidelines for context-aware mobile applications, usability guidelines for designing mobile learning portals, network centric photorealistic mixed reality on mobile devices, and signwriting on mobile phones for the deaf.";
"Storz O., Friday A., Davies N.";"Supporting content scheduling on situated public displays";"There is increasing interest in creating networks of situated public displays that offer novel forms of interaction and rich media content-often as work towards a vision of ubiquitous computing or ambient multimedia. In this paper, we present an infrastructure developed as part of the e-Campus project that is designed to support the coordinated scheduling of rich media content on networks of situated public displays. The design of the system was informed by an iterative process of developing, deploying and evaluating a set of three technology probes. The resulting system provides flexible support for the construction of domain-specific scheduling approaches on top of a common, domain-independent API. Using this approach, we are able to support a combination of both statically scheduled content and interactive content across multiple displays. The API provides support for transactional semantics, allowing developers of schedulers to reliably schedule content across displays in the presence of conflicts and failures without negative impact on running applications. © 2006 Elsevier Ltd. All rights reserved.";"Coordination, Digital signage, Distributed systems infrastructure, Public displays, Ubiquitous computing"
"Kim H.-J., Chu W.-S., Ahn S.-H., Kim D.-S., Jun C.-S.";"Web-based design and manufacturing systems for micromachining: Comparison of architecture and usability";"In this paper, web-based micromachining systems are compared with a commercial CAD/CAM system from the point of educational usability. The web-based systems included in this study were Micromachining System (MIMS) and SmartFab. In the MIMS architecture, a 3D model in STL format was read using the web browser, the file was sent to the web server where toolpath planner was located, and the NC code was reviewed by the designer through the web connection. In the SmartFab system, SolidWorks was used as the design interface with modified menus that support input parameters for micromachining. This additional function was available by SolidWorks API that provided links to the same toolpath planner as MIMS. In the commercial CAD/CAM case, without using any web connection, SolidWorks and CATIA were used for design, and PowerMill was used as a CAM tool. For each system, accessibility, user-friendliness, toolpath-reliability, and processing time were compared. Total of 91 students tested these systems In an undergraduate CAD class, and the user's feedback showed better performance of the web-based system in accessibility, user-friendliness, and processing time. However, reliability of the web-based system should be improved to be more useful design and manufacturing system. © 2006 Wiley Periodicals, Inc.";"Design for manufacturing, Micromachining, Usability, Web-based"
"Wang C., Lin Y., Sohraby K., Li B.";"An adaptive algorithm for active queue management";"This paper proposes an adaptive proportional integral (API) algorithm for active queue management. API uses mean packet loss ratio and mean queue length as control error to adaptively adjust packet drop probability in order to expedite congestion control. The extensive simulations validate that API achieves faster control response and improved performance in terms of goodput, average queue length, and packet loss ratio.";"Active queue management, Congestion control, Quality of service"
"Worringen J.";"Self-adaptive hints for collective I/O";"The processing of MPI-IO operations can be controlled via the MPI API using file hints, which are passed to the MPI library as MPI info objects. A file hint can affect how the MPI library accesses the file on the file system level, it can set buffer sizes, turn special optimizations on and off or whatever parameters the MPI implementation provides. However, experience shows that file hints are rarely used for reasons that will be discussed in the paper. We present a new approach which dynamically determines the optimal setting for file hints related to collective MPI-IO operations. The chosen settings adapt to the actual file access pattern, the topology of the MPI processes and the available memory resources and consider the characteristics of the underlying file system. We evaluate our approach which has been implemented in MPI/SX, NEC's MPI implementation for the SX series of vector supercomputers. © Springer-Verlag Berlin Heidelberg 2006.";"Collective operations, File hints, MPI-IO, Self-adaptation"
"Kimpe D., Vandewalle S., Poedts S.";"On the usability of high-level parallel IO in unstructured grid simulations";"For this poster, the usability of the two most common IO libraries for parallel IO was evaluated, and compared against a pure MPI-IO implementation. Instead of solely focusing on the raw transfer bandwidth achieved, API issues such as data preparation and call overhead were also taken into consideration. The access pattern resulting from parallel IO in unstructured grid applications, which is also one of the hardest patterns to optimize, was examined. © Springer-Verlag Berlin Heidelberg 2006.";"HDF5, MPI, Parallel IO, Parallel netcdf"
"Ghosh A., Olsson M., Persson P.";"Open application environments in mobile devices: Focus on JME and Ericsson Mobile Platforms";"Advances in hardware in mobile handsets are rapidly overcoming computational constraints. Similarly, handset interfaces are improving in terms of quality and usability. At the same time, wireless operators are offering increasingly faster transmission rates for data communication. The table is thus being set, as it were, to provide a feast of innovative and interesting end-user services. Not all these services are installed in end-user handsets at the time of purchase, but thanks to the adoption of open application environments, more and more handsets can download and upgrade services. Handsets with Java application environments, for example, can download games and other applications over the air. The authors provide an overview of available open application environments. In particular, they focus on the Java for Micro Edition (JME) standard, a highly popular environment being developed through the Java Community Process (JCP). They also introduce Ericsson Mobile Platform's (EMP) middleware architecture and Open Platform API (OPA), putting emphasis on how OPA and JME provide a complete product offering to Ericsson's customers, including a compelling open application environment that meets wireless operator requirements."
"Mathieu P., Verrons M.-H.";"GeNGA, a generic contract negotiation model [GeNGA, un modèle général de négociation de contrats]";"Modelisation of group phenomena is the core of the multi-agent problematic. Among them are automatic negotiation systems which have been largely studied in the electronic commerce field in order to modelise especially auctions. In this paper, we present a generic negotiation model for multi-agent systems, called GeNCA, built on three levels: a communication level, a negotiation level and a strategic level, which is the only level specific to a particular application. The negotiation model presented here aims to be general and parameterable for different kinds of negotiations. It has been implemented by a Java API used to build our applications. GeNCA is the only platform which enables the use of different communication systems and of negotiation strategies specific to the applications achieved.";"Artificial intelligence, Multi-agent, Negotiation, Software engineering"
"Sunderraman R., Dogdu E., Madiraju P., Malladi L.";"A java API for global querying and updates for a system of databases";"In this paper, we present the design of system of databases (SyDb). We also give the design and implementation of a Java API for global querying and updates on the SyDb. The databases may be heterogeneous. The API allows for queries and updates that have global references to schema elements of multiple databases to be executed in a seamless manner. The API can be used to develop collaborative applications that need access to several independent databases on the network. One such collaborative application, called the Calendar application, is illustrated in the paper. In this application each individual keeps their schedule information in their personal database. The users can schedule meetings with others, view others schedules, cancel meetings, etc. We implement the API using direct JDBC connections to databases. Copyright 2005 ACM.";"Distributed information retrieval, Global queries/Updates, Multidatabases, System of databases"
"Compton M.";"Stenning's protocol implemented in UDP and verified in Isabelle";"This paper is about the mechanical verification of UDP based network programs. It uses the UDP portion of a formal model of the Internet protocols TCP (Transmission Control Protocol) and UDP (User Datagram Protocol). The model includes asynchronous message passing, message loss and host failure. The model is based around the sockets library, the primary API used for writing UDP and TCP based applications. This paper demonstrates that formal, machine-checked, proof is possible in the UDP model by presenting the proof of a safety property for an implementation of Stenning's Protocol. The protocol is implemented in a fragment of the OCaml language, using the sockets library for UDP network communication. The entire development including the safety proof is carried out in the proof assistant Isabelle, this assures soundness. Thus this paper demonstrates that it is possible to machine verify very concrete representations of distributed programs in a detailed semantics that accurately reflects the programs execution environment. Previously only abstract representations of this protocol have been machine verified. The proof, based on an implementation, provides a contrast to other verifications. © 2005, Australian Computer Society, Inc.";"Distributed systems, Formal verification, Theorem proving"
"Czarnul P., Fra̧czak M.";"New user-guided and ckpt-based checkpointing libraries for parallel MPI applications";"We present design and implementation details as well as performance results for two new parallel checkpointing libraries developed by us for parallel MPI applications. The first one, a user-guided library requires from the programmer to support packing and unpacking code with an easy-to-use API using MPI constants. It uses MPI-2 collective I/O calls or a dedicated master process for checkpointing. The other version is a technically advanced parallel implementation of checkpointing based on the user-level ckpt library. It uses wrappers for MPI calls in the user program which enables to run a shadow MPI application just for communication purposes. Communication between original processes and the shadow MPI code is done via shared memory segments to which communication buffers are mapped. We present checkpoint/restart times for the two approaches and subversions proposed by us compared to an available LAMMPI/BLCR checkpointing solution for MPI applications. The performance of all the versions and I/O optimizations are discussed for a 4-node, 16-processor cluster with NFS and specifically for single SMP nodes with a local file system. © Springer-Verlag Berlin Heidelberg 2005."
"Kennedy C.";"Development of a new interchangeable virtual instrument class specification";"In today's world, rapidly changing technology and high costs associated with developing and maintaining ATE software push the need for reusability and ease of upgrading or replacing components in test systems intended to be used over a long period of time. The Interchangeable Virtual Instrument (IVI) Foundation is tackling these issues by: ""Promoting specifications for programming test instruments that simplify interchangeability, provide better performance, and reduce program development and maintenance cost."" An Interchangeable Virtual Instrument (IVI) class specification defines the base capabilities and extensions for an instrument type (such as a Function Generator or Oscilloscope). This specification defines the Application Programming Interface (API) used to develop an IVI Class-compliant driver. Systems & Electronics Inc. and Boeing are jointly chairing an IVI Foundation working group to define an IVI class specification for a Counter/Timer. Based on the experiences of characterizing the Counter/Timer specification, this paper explores the process of creating a new class specification for an instrument type that does not already have a specification defined. Topics such as steps to effective specification development, obstacles encountered, and how to keep the specification moving forward are discussed. © 2005 IEEE."
"Bruni R., Ferrari G., Melgratti H., Montanari U., Strollo D., Tuosto E.";"From theory to practice in transactional composition of Web Services";"We address the problem of composing Web Services in long-running transactional business processes, where compensations must be dealt with appropriately. The framework presented in this paper is a Java API called Java Transactional Web Services (JTWS), which provides suitable primitives for wrapping and invoking Web Services as activities in long-running transactions. JTWS adheres to a process calculi formalisation of long-running transactions, called Naïve Sagas, which fixes unambiguously the implemented compensation policy. In particular, the primitives provided by JTWS are in one-to-one correspondence with the primitives of Sagas, and they are abstract enough to hide the complex details of their realization, thus favouring usability. Moreover, JTWS orchestrates business processes in a distributed way. © Springer-Verlag Berlin Heidelberg 2005."
"Chanda A., Elmeleegy K., Cox A.L., Zwaenepoel W.";"Causeway: Support for controlling and analyzing the execution of multi-tier applications";"Causeway provides runtime support for the development of distributed meta-applications. These meta-applications control or analyze the behavior of multi-tier distributed applications such as multi-tier web sites or web services. Examples of meta-applications include multi-tier debugging, fault diagnosis, resource tracking, prioritization, and security enforcement. Efficient online implementation of these meta-applications requires meta-data to be passed between the different program components. Examples of metadata corresponding to the above meta-applications are request identifiers, priorities or security principal identifiers. Causeway provides the infrastructure for injecting, destroying, reading, and writing such metadata. The key functionality in Causeway is forwarding the metadata associated with a request at so-called transfer points, where the execution of that request gets passed from one component to another. This is done automatically for system-visible channels, such as pipes or sockets. An API is provided to implement the forwarding of metadata at system-opaque channels such as shared memory. We describe the design and implementation of Causeway, and we evaluate its usability and performance. Causeway's low overhead allows it to be present permanently in production systems. We demonstrate its usability by showing how to implement, in 150 lines of code and without modification to the application, global priority enforcement in a multi-tier dynamic web server. © IFIP International Federation for Information Processing 2005."
"Kraj P., McIndoe R.A.";"caBIONet - A .NET wrapper to access and process genomic data stored at the National Cancer Institute's Center for Bioinformatics databases";"Motivation: The National Cancer Institute's Center for Bioinformatics (NCICB) has developed a Java based data management and information system called caCORE. One component of this software suite is the object oriented API (caBIO) used to access the rich biological datasets collected at the NCI. This API can access the data using native Java classes, SOAP requests or HTTP calls. Non-Java based clients wanting to use this API have to use the SOAP or HTTP interfaces with the data being returned from the NCI servers as an XML data stream. Although the XML can be read and manipulated using DOM or SAX parsers, one loses the convenience and usability of an object oriented programming paradigm. caBIONet is a set of .NET wrapper classes (managers, genes, chromosomes, sequences, etc.) capable of serializing the XML data stream into local .NET objects. The software is able to search NCICB databases and provide local objects representing the data that can be manipulated and used by other .NET programs. The software was written in C# and compiled as a .NET DLL. © The Author 2005. Published by Oxford University Press. All rights reserved."
"Guthe M., Balázs Á., Klein R.";"GPU-based trimming and tessellation of NURBS and T-Spline surfaces";"As there is no hardware support neither for rendering trimmed NURBS - the standard surface representation in CAD - nor for T-Spline surfaces the usability of existing rendering APIs like OpenGL, where a run-time tessellation is performed on the CPU, is limited to simple scenes. Due to the irregular mesh data structures required for trimming no algorithms exists that exploit the GPU for tessellation. Therefore, recent approaches perform a pretessellation and use level-of-detail techniques. In contrast to a simple API these methods require tedious preparation of the models before rendering and hinder interactive editing. Furthermore, due to the tremendous amount of triangle data smooth zoom-ins from long shot to close-up are not possible. In this paper we show how the trimming region can be defined by a trim-texture that is dynamically adapted to the required resolution and allows for an efficient trimming of surfaces on the GPU. Combining this new method with GPU-based tessellation of cubic rational surfaces allows a new rendering algorithm for arbitrary trimmed NURBS and T-Spline surfaces with prescribed error in screen space on the GPU. The performance exceeds current CPU-based techniques by a factor of up to 1000 and makes real-time visualization of real-world trimmed NURBS and T-Spline models possible on consumer-level graphics cards. © 2005 ACM 0730-0301/05/0700-1016 $5.00.";"GPU-based algorithms, NURBS nd T-Spline surfaces, Trimming"
"Marchesini J., Smith S.W., Zhao M.";"Keyjacking: The surprising insecurity of client-side SSL";"In theory, PKI can provide a flexible and strong way to authenticate users in distributed information systems. In practice, much is being invested in realizing this vision via client-side SSL and various client keystores. However, whether this works depends on whether what the machines do with the private keys matches what the humans think they do: whether a server operator can conclude from an SSL request authenticated with a user's private key that the user was aware of and approved that request. Exploring this vision, we demonstrate via a series of experiments that this assumption does not hold with standard desktop tools, even if the browser user does all the right things. A fundamental rethinking of the trust, usage, and storage model might result in more effective tools for achieving the PKI vision. © 2004 Elsevier Ltd. All rights reserved.";"API hijacking, Application security, Authentication, PKI, Spoofing, SSL, Usability, USB tokens"
"Greenberg J.P., Mock S., Bhatia K., Katz M., Bruno G., Sacerdoti F., Papadopoulos P., Baldridge K.K.";"Incorporation of middleware and grid technologies to enhance usability in computational chemistry applications";"High performance computing, storage, visualization, and database infrastructures are increasing in complexity as scientists move towards grid-based computing. This evolution of computing infrastructure has the effect of pushing breakthrough computational capabilities beyond the reach of domain scientists. In this work, we discuss a workflow management system that allows portal construction that is fully integrated with emerging grid standards but can be dynamically reconfigured. By defining an XML schema to describe both resources, application codes and interfaces, we will enable a ""pluggable"" event-driven model where grid-enabled services can be composed to form elaborate pipelines of simulation, and visual analysis. © 2004 Elsevier B.V. All rights reserved."
"Pastel R., Skalsky N.";"Demonstrating information in simple gestures";"We introduce the simple gesturing user interface (SGUI), an application programming interface (API) for designing user interfaces utilizing simple gesturing on the personal digital assistant (PDA). SGUI is particularly appropriate for PDA interfaces because the simple gestures are recognized using minimum processing power and reserve all of the small display for user-task specific information. A graphing-software implemented on a PDA using SGUI illustrates the usability of gesturing interfaces and the information conveyed in a single gesture stroke.";"Gestures, Gesturing interface, PDA, PDA interface, Personal digital assistant"
"McGuinness D.L., Da Silva P.P.";"Explaining answers from the semantic web: The inference web approach";"The Semantic Web lacks support for explaining answers from web applications. When applications return answers, many users do not know what information sources were used, when they were updated, how reliable the source was, or what information was looked up versus derived. Many users also do not know how implicit answers were derived. The Inference Web (IW) aims to take opaque query answers and make the answers more transparent by providing infrastructure for presenting and managing explanations. The explanations include information concerning where answers came from (knowledge provenance) and how they were derived (or retrieved). In this article we describe an infrastructure for IW explanations. The infrastructure includes: IWBase - an extensible web-based registry containing details about information sources, reasoners, languages, and rewrite rules, PML - the Proof Markup Language specification and API used for encoding portable proofs, IW browser - a tool supporting navigation and presentations of proofs and their explanations, and a new explanation dialogue component. Source information in the IWBase is used to convey knowledge provenance. Representation and reasoning language axioms and rewrite rules in the IWBase are used to support proofs, proof combination, and Semantic Web agent interoperability. The Inference Web is in use by four Semantic Web agents, three of them using embedded reasoning engines fully registered in the IW. Inference Web also provides explanation infrastructure for a number of DARPA and ARDA projects. © 2004 Elsevier B.V. All rights reserved.";"Inference Web, Knowledge provenance, PML, Web explanations"
"Clarke S.";"Measuring API Usability";"The techniques used to design the usability of APIs that move with .NET are described. The best way to design usable graphical user interfaces (GUI) or APIs is to follow a user-centered design approach. APIs are reviewed periodically by examining the code samples and determining whether or not developers would be comfortable writing the code in each of the samples. The cognitive dimensions framework can also be used to describe the usability of APIs and to gather feedback from customers."
"Zheng Z., Sepehri N.";"A CORBA-based distributed real-time crane simulator with 3D visualization";"The development of a simulator for a crane equipped with a claming device is reported in this paper. The real-time simulation is built upon a complete mathematical model of the claming machine with 3D graphics and interactive features. Common Object Request Broker Architecture (CORBA) technology is employed to distribute the calculation of the complex dynamic equations on a more powerful server, while relieving the -client computer to concentrate on graphics rendering, collision detection and control signal collection. The communication methods and concurrency model of both the client and the server are carefully selected to ensure reliability without compromising the speed. The server supports multiple users. Thus, more than one user can share the resource of a single server when they are connected to a network that supports Transmission Control Protocol (TCP) or Internet Protocol (IP). OpenGL is used as the graphics Application Programming Interface (API), Users can select different visual angle to watch the scene while operating the virtual machine.";"Distributed algorithms, Object-oriented programming, Real-time simulations"
"Lee H.-C., Kim H.-J., Park K.-S.";"A flexible transition scheme within a dual stack host in IPv4/IPv6 coexistence phase";"In an early transition period, the Internet consists of IPv4-only, IPv6-only or IPv4/IPv6 dual networks. Users want to connect to the Internet without any restriction and also still use their existing applications even after migration from IPv4 to IPv6 networks. Thus, we propose a new flexible transition scheme called GHADH (Coexistence of Heterogeneous Applications within a Dual stack Host). At this scheme, DSTM (Dual Stack Transition Mechanism) is tightly coupled with BIA (Bump In the API). With these coupling, Users can use their existing IPv4 applications to communicate with IPv6 host within IPv6 networks. Furthermore, seamless interworking with IPv4 networks can be also assured. Additionally, it can provide the users with adaptive environments to easily use their terminals in various networks environments. DNSv6 resolving can be also available to the users with the help of CHADH. We have implemented the prototype of CHADH on the Microsoft Windows 2000 and XP platforms. We have verified its usability through various experiments with existing applications and evaluated the performance in each network environments. © Springer-Verlag Berlin Heidelberg 2003."
"Simonds C.";"Software for the Next-Generation Automobile";"The features of Ford devised intelligent transportation system (ITS) are discussed. Ford's prototype software provides aid in rapid tailoring of automobile features and handles diverse communication modes. The flexible XML-based software architecture, Vehicle User-Interface Mark-up Language (VUML), offers customers a high degree of personalization including real-time information, facilitated by off-board services. In this regard, the specifications of application programming interface (API) used in the designing of Vehicle Consumer Services Interface (VCSI) are also discussed."
"Jones H., Snyder M.";"Robotic control & 3D GUIs";"A graphical user interface (GUI) based on the open GL 3D API used to operate global-positioning system (GPS)-enabled robots, is discussed. This basic technique is used to operate helicopters, submarines and space systems. The position sensing of the robot is accomplished with four GPS antennae that provide both position and altitude using differential carrier phase (DCPGPS) techniques."
"Sicilia M.-A., García E., Díaz P., Aedo I.";"Extending relational data access programming libraries for fuzziness: The fJDBC framework";"Fuzzy relational databases have been extensively studied in recent years, resulting in several models and representation techniques, some of which have been implemented as software layers on top of diverse existing database systems. Fuzzy extensions to query languages and end-user query interfaces have also been developed, but the design of programming interfaces has not been properly addressed yet. In this paper, we describe a software framework called fJDBC that extends the Java Database Connectivity API by enabling fuzzy queries on existing relational databases, using externally-stored metadata. Since the main design objective of this extension is usability for existing database programmers, only a restricted subset of extensions (supported also by an extended object modelling notation) has been included. The overall design of the framework and some empirical results are also described. © Springer-Verlag Berlin Heidelberg 2002."
"Ball T., Rajamani S.K.";"The SLAM project: Debugging system software via static analysis";"The goal of the SLAM project is to check whether or not a program obeys ""API usage rules"" that specify what it means to be a good client of an API. The SLAM toolkit statically analyzes a C program to determine whether or not it violates given usage rules. The toolkit has two unique aspects: It does not require the programmer to annotate the source program (invariants are inferred), it minimizes noise (false error messages) through a process known as ""counterexample-driven refinement"". SLAM exploits and extends results from program analysis, model checking and automated deduction. We have successfully applied the SLAM toolkit to Windows XP device drivers, to both validate behavior and find defects in their usage of kernel APIs."
"Umlauf E.J., Piringer H., Reitmayr G., Schmalstieg D.";"ARLib: The augmented library";"ARLib is a location-based application for a mobile Augmented Reality system based on a notebook computer, a head-mounted display fitted with a FireWire camera, and powered by Sludierstube 2.0 software. The application aims to aid the user in typical tasks that are done in a library by augmenting a book's position on a shelf. The system utilizes an optical tracking approach, relying on ARToolKit for recognising markers. Markers are attached to bookshelves and walls to determine the viewer's position, as well as to books themselves. A powerful multi-criteria search engine combined with an interface that supports grafitti text input grants a maximum of usability and speed. © 2002 IEEE.";"Application software, Augmented reality, Books, Cameras, Computer displays, Firewire, Mobile computing, Search engines, Software libraries, Usability"
"Bubak M., Kurzyniec D., Luszczek P., Sunderam V.";"Creating Java to native code interfaces with Janet";"Java is growing in appropriateness and usability for high performance computing. With this increasing adoption, issues relating to combining Java with existing codes in other languages become more important. The Java Native Interface (JNI) API is portable but too inconvenient to be used directly owing to its low-level API. This paper presents Janet - a highly expressive Java language extension and preprocessing tool that enables convenient integration of native code with Java programs. The Janet methodology overcomes some of the limitations of JNI and generates Java programs that execute with little or no degradation despite the flexibility and generality of the interface."
"Aizman A.";"Easy concurrency";"Advances in technology raise expectations. As far as software engineering is concerned, the common expectation is that coding and deploying applications is going to be simple. It seems, though, that software engineering is not getting easier, and the complexity moves to an application domain. One of the sources of complexity is an application concurrency. It is not an uncommon development practice that concurrency and transaction management in multi-user, multi-threaded, event-driven applications are postponed until after most of the required functionality is implemented. This situation has various explanations. On the one hand, business logic may require access and modification of large sets of interconnected application objects. On the other, testing and stress-testing of this logic becomes possible only at advanced stages of product development. At these stages, increasing lock granularities may appear to be less ""ex-pensive"" than debugging race conditions and deadlocks. Coarse-grained locking has, of course, an adverse effect on application scalability. Declaring rules of concurrency outside of the application may solve part of the problem. This paper presents an approach allowing developers to define concurrency in application-specific terms, design it in the early stages of development, and implement it using a documented API of the concurrency engine (CE). Simple notation makes it possible to record concurrency specifications in terms of application operations, relationships between application resources, and synchronization conflicts between operations. These concepts are demonstrated on examples. The final sections include the CE UML diagram, notes on API usage, and performance benchmarks. © Springer-Verlag 2001.";"Application, Conflict, Operation, Relationship, Resource, Rules of concurrency"
"John B.E., Bass L.";"Usability and software architecture";"The role of software architecture with respect to usability has evolved over the past 20 years. The architectures of the 1980s and early 1990s assumed that usability was primarily a property of the presentation of information. Therefore, simply separating the presentation from the dialogue and application make it easy to modify that presentation after user testing. A more popular belief in the 1990s was that usability concerns greatly affected system functionality as well as the presentation. This emphasis took attention away from architectural support (beyond separation). Achieving the correct functionality for a given system became paramount. It is our observation that even if presentation and functionality of a system are well designed, the usability of a system can be greatly compromised if the underlying architecture does not support human concerns beyond modifiability. This paper will present a new role for software architecture in usability, preliminary research and practice stemming from this role and a research agenda for the future."
"Bunn J.J., Holtman K., Newman H.B., Wilkinson R.P.";"The GIOD project - Globally interconnected object databases";"The GIOD (Globally Interconnected Object Databases) Project, a joint effort between Caltech and CERN, funded by Hewlett Packard Corporation, has investigated the use of WAN-distributed Object Databases and Mass Storage systems for LHC data. A prototype small-scale LHC data analysis center has been constructed using computing resources at Caltechs Centre for Advanced Computing Research (CACR). These resources include a 256 CPU HP Exemplar of ∼4600 SPECfp95, a 600 TByte High Performance Storage System (HPSS), and local/wide area links based on OC3 ATM. Using the Exemplar, a large number of fully simulated CMS events were produced, and used to populate an object database with a complete schema for raw, reconstructed and analysis objects. The reconstruction software used for this task was based on early codes developed in preparation for the current CMS reconstruction program, ORCA. Simple analysis software was then developed in Java, and integrated with SLACs Java Analysis Studio tool. An event viewer was constructed with the Java 3D API. Using this suite of software, tests were made in collaboration with researchers at FNAL and SDSC, that focused on distributed access to the database by numerous clients, and measurements of peak bandwidths were made and interpreted. In this paper, some significant findings from the GIOD Project are presented, such as the achievement of the CMS experiment's 100 MB/s database I/O milestone. © 2001 Elsevier Science B.V. All rights reserved.";"CMS, GIOD, LHC, ODBMS, WAN"
"Whittaker J.A.";"Software's invisible users";"The challenges of dealing with different types of users are discussed, which provide software systems with input. These include human users, operating systems (OS) users, API users, and file system users. When designing software, programmers must decide on the inputs to verify. Testers must also simulate anomalous inputs that create problems for the system."
"Meijer H., Poll E.";"Towards a full formal specification of the javacard API";"This paper reports on ongoing work to develop a formal specification of the JavaCard API using the specification language JML. It discusses the specification of the JCSystem class, which deals with the JavaCard firewall, (atomic) transactions and transient objects. The JCSystem class seems to be the hardest class in the API to specify, and it is closely connected with some of the peculiarities of JavaCard as opposed to Java. © Springer-Verlag Berlin Heidelberg 2001."
"Braun P., Lötzbeyer H., Schätz B., Slotosch O.";"Consistent integration of formal methods";"The usability of formal concepts for system design depends essentially on their integration in the design process. We discuss several possible levels of integration: technical integration of tools considering APIs and tool interfaces, conceptual integration of metamodels of description formalisms combined with hard and soft constraints, semantical integration of semantics of description techniques using a common semantic model, and finally methodical integration by an embedding in the development process. We show the feasibility of such an integrated approach and its advantages presenting AutoFocus/Quest, a formal method CASE-Tool with its levels of integration. Parts of a banking system model are used as example. © Springer-Verlag Berlin Heidelberg 2000."
"North C., Shneiderman B.";"Snap-together visualization: Can users construct and operate coordinated visualizations?";"Multiple coordinated visualizations enable users to rapidly explore complex information. However, users often need unforeseen combinations of coordinated visualizations. Snap-together visualization (Snap) enables users to rapidly and dynamically construct coordinated-visualization interfaces, customized for their data, without programming. Users load data into desired visualizations, then construct coordinations between them for brushing and linking, overview and detail view, drill down, etc. Snap formalizes a conceptual model of visualization coordination based on the relational data model. Visualization developers can easily Snap-enable their independent visualizations using a simple API. Empirical evaluation reveals benefits, cognitive issues and usability concerns with coordination concepts and Snap. Two user studies explore coordination construction and operation. Data-savvy users successfully, enthusiastically and rapidly constructed powerful coordinated-visualization interfaces of their own. Operating an overview-and-detail coordination reliably improved user performance by 30-80% over detail-only and uncoordinated interfaces for most tasks."
"Hale M.A., Mavris D.N.";"Lean-server foundation for collaborative design";"The design framework research community utilizes the Internet as a facilitator for collaborative activities. The ability to support coordination and high-level communication is imperative in any collaboratory. A novel approach using lean-servers is an alternative method for providing a functional server-side computing model that meets the implementation requirements for a collaboratory. The server brokers Internet requests directly within a design application by providing a gateway to the application's programming interface using a HyperText Transfer Protocol compliant layer. This allows requests to be managed directly by the application rather than requiring auxiliary services. Macros are used to provide content and context sensitive responses. A prototype system, called the Systems Programming Architecture for Collaborative Engineering, is described as one scenario for implementing the lean-server technology. Usability of the approach is demonstrated through a Design of Experiments example that is representative of modern design methods. This example also demonstrates coordination because it executes asynchronously with multi-user intervention at any time during the process. In hindsight, the lean-server approach is an enabling technology for collaborative design and focuses future research on methods for communicating reasoning, experience, and other information during design decision-making processes."
"Hoffman D., Strooper P.";"Prose + test cases = specifications";"The rise of component-based software development has created a need for API documentation. Experience has shown that it is hard to create and maintain precise and readable documentation. Prose documentation can provide a good overview but lacks precision. Formal methods offer precision but the resulting documentation is expensive to write and modify. Worse, few developers have the skill or inclination to read formal documentation. We present a pragmatic solution to the problem of API documentation. We augment the current prose documentation with test cases, including expected outputs, and use the prose plus the test cases as the documentation. Typically there are one or two simple test cases for each likely question about API behavior. With this approach, the documentation is precise, albeit partial. Consistency between code and documentation is guaranteed by running the test cases. The readability of the test cases is of paramount importance because communication with API users is their primary purpose. We present a test script language that supports compact, readable test cases and generation of test drivers, and illustrate the approach with a detailed case study."
"Klein K., Sequeira V.";"The view-cube: An efficient method of view planning for 3D modelling from range data";"When aiming at the automated reconstruction of real world scenes from range images, one has to address the problem of planning the image acquisition. Although solutions for small objects in well defined environments are already available, the insufficient scalability of these approaches to large scenes and to a high number of degrees of freedom limits their applicability. In this paper we present a new planning algorithm with emphasis on practical usability in initially unknown, large indoor environments. Using a surface representation of seen and unseen parts of the environment, we propose an objective function based on the analysis of occlusions. In addition to previous approaches, we take into account both a quality criterion and the cost of the next acquisition. By optimising this objective function, the parameters of the next view are computed efficiently for a large search space with eight degrees of freedom (3D position, viewing direction, field of view, and resolution). Our technique exploits hardware-accelerated rendering (OpenGL) in order to perform the expensive visibility computation, which reduces the computation time of one planning step to a couple of minutes. Results are shown for two large indoor scenes-an artificial scene and a real world room-with numerous self occlusions. © 2000 IEEE.";"Computer graphics, Contracts, Costs, Humans, Image reconstruction, Indoor environments, Large-scale systems, Layout, Robotics and automation, Scalability"
"North Chris, Shneiderman Ben";"Snap-Together Visualization: A user interface for coordinating visualizations via relational schemata";"Multiple coordinated visualizations enable users to rapidly explore complex information. However, users often need unforeseen combinations of coordinated visualizations that are appropriate for their data. Snap-Together Visualization enables data users to rapidly and dynamically mix and match visualizations and coordinations to construct custom exploration interfaces without programming. Snap's conceptual model is based on the relational database model. Users load relations into visualizations then coordinate them based on the relational joins between them. Users can create different types of coordinations such as: brushing, drill down, overview and detail view, and synchronized scrolling. Visualization developers can make their independent visualizations snap-able with a simple API. Evaluation of Snap revealed benefits, cognitive issues, and usability concerns. Data savvy users were very capable and thrilled to rapidly construct powerful coordinated visualizations. A snapped overview and detail-view coordination improved user performance by 30-80%, depending on task."
"Succi G., Eberlein A., Yip J., Luc K., Nguy M., Tan Y.";"Design of Holmes: a tool for domain analysis and engineering";"Holmes is a collection of tools that support the Sherlock domain analysis & engineering (DA&E) methodology. Holmes plans to improve on existing DA&E tools by providing a more usable interface and making better use of existing technologies and standards. Usability is achieved through automation and the use of a critiquing system. The tool is developed in Java to allow easier upgrading to new technologies and standards by updating a server to deploy new versions. Internal data exchange is achieved using the JavaSpaces API while external data exchange uses the Extensible Markup Language (XML)."
"Martin David H., Martin Johnny";"Java and digital images";"Interfacing Java applications to a video-capture device poses a special challenge because there is currently no easy way to access the camera from Java. The Java virtual machine presents a barrier between applications and C/C++ application programming interfaces (API) used to access the video camera. To access these APIs from Java, one must not only write JNI methods, but must also address image conversion problems, performance issues, and thread synchronization. The three approaches, no integration, loose integration, and full integration, to incorporate video or image capture into a Java application and their abilities/complexity tradeoffs are discussed."
"McLellan S.G., Roesler A.W., Tempest J.T., Spinuzzi C.I.";"Building more usable APIs";"Imagine hypothetically, just for a moment, that programmers are humans,"" writes Steven Pemberton in a July 1997 magazine devoted to human-computer interaction design and development. ""Now suppose for a moment, also for the sake of the argument, that their chief method of communicating and interacting with computers was with programming languages. What would we, as HCI people, then do? Run screaming in the other direction...."" 1 It is a good question and, unfortunately, an all too common response. It's hard enough for us to ensure that product interfaces, like those for Excel or Word, are easy to use and learn. But programmers are users, too. They need application and system libraries that are just as easy to learn and use as the products they build from these libraries. Listen to this customer: ""I think it would be worthwhile if all developers would spend maybe a couple of hours a year seeing how the[ir] product is used by...customers. Just watching them. And while they're watching ...the customer would say, 'I don't like the way this works....'You need to see how they use it."" 2 Now ask yourself: why is it easier to visualize the customer who's purchased a financial accounting package from a neighborhood computer outlet, rather than a programmer whose company has just purchased a new Java class library? Wouldn't the developer of this library find it worthwhile to watch programmers work with it?"
"[No author name available]";"Proceedings of the 1998 International Conference on Intelligent User Interfaces, IUI";"The proceedings contains 24 papers from the 1998 International Conference on Intelligent User Interfaces. Topics discussed include: intelligent user interfaces, life-like pedagogical agents, dynamically generated hypermedia presentations, multi-model interactive improvisational agent, speech research, integrating user interface agents, self-integrating context-aware services, multimodal tools, standardized task models, intelligent agents, user task models, task-sensitive cinematography interfaces, text editing task automation, context-sensitive filtering, knowledge-rich interface, construction planning information, software architectures critics, intelligent educational systems, adaptive forms, and agent-assisted interfaces."
"McCartney T.P.";"A usability study of end-user construction of distributed multimedia applications";"This paper describes an empirical study of end-users that tested the usability of The Programmers' Playground graphical environment. The Programmers' Playground is a software library and run-time system for constructing distributed multimedia applications. Playground's graphical environment enables end-users to create direct-manipulation graphical user interfaces (GUIs) and to dynamically configure communication among distributed application components. In this study, 28 end-users with no prior experience in distributed computing or user interface construction were timed and evaluated on several tasks using our graphical environment. Tasks included the use of direct and indirect constraint relationships, visual configuration of distributed applications, and graphical user interface construction. The results show that a wide variety of end-users (i.e., not just programmers) can learn and apply these concepts, utilizing our graphical environment to construct distributed multimedia applications. © Springer-Verlag 1997.";"Distributed application, Graphical environment, Graphical user interface, GUI, I/0 abstraction, Multimedia, Programmers' Playground"
"Ketchpel S.P., Garcia-Molina H., Paepcke A.";"Shopping models: a flexible architecture for information commerce";"In a digital library, there are many different interaction models between customers and information providers or merchants. Subscriptions, sessions, pay-per-view, shareware, and pro-paid vouchers are different models that each have different properties. A single merchant may use several of them. Yet if a merchant wants to support multiple models, there is a substantial amount of work to implement each one. In this paper, we formalize the shopping models which represent these different modes of consumer to merchant interaction. In addition to developing the overall architecture, we define the application program interfaces (API) to interact with the models. We show how a small number of primitives can be used to construct a wide range of shopping models that a digital library can support, and provide examples of the shopping models in operation, demonstrating their flexibility. Two models have been implemented as part of the Stanford Digital Library Project, to begin validating re-usability of key architectural components."
"Watson Richard W., Coyne Robert A.";"Parallel I/O architecture of the High-Performance Storage System (HPSS)";"Datasets up to terabyte size and petabyte total capacities have created a serious imbalance between I/O and storage-system performance and system functionality. One promising approach is the use of parallel data-transfer techniques for client access to storage, peripheral-to-peripheral transfers, and remote file transfers. This paper describes the parallel I/O architecture and mechanisms, Parallel Transport Protocol (PTP), parallel FTP, and parallel client Application Programming Interface (API) used by the High-Performance Storage System (HPSS). Parallel storage integration issues with a local parallel file system are also discussed."
"Castelli G.";"Software development environments for massively parallel systems";"The commercial offer of massively parallel systems has now reached a wide variety, with well engineered products offered by European and American manufacturers. Furthermore, both the American government and the Commission of the European Communities have clearly identified the important role that High Performance Computing may play in science and industry in the near future. To be successful, HPC needs to improve greatly the quality attributes of its software. This paper investigates the status of the software environments for massively parallel systems. In fact, whilst the hardware technology improvements in the past few years have been very rapid, the technology has suffered because of a substantial misalignment between the potential user's expectations and the actual usability of software for massively parallel computer systems. Actions and serious industrialisation efforts are needed to bring the system software and the basic programming environments to a level of real usability, because it is time for these systems to get rid of the ancestral equation: massive parallel systems = number crunching. Many potential markets could be addressed by massively parallel systems if they were able to offer to the users the same ease of use, quality, completeness, and portability of conventional sequential systems. © 1994.";"Application Programming Interface (API), Architecture Neutral Distribution Format (ANDF), Compiler, Debugger, Operating system"
"Oliveira J.L., Martins J.A.";"A management architecture based on network topology information";"This paper describes the development of a formalism to represent Network Topology Information that provides hierarchical views of the network elements distribution, usable with advantage by management applications. It reviews some topology discovery tools and emphasizes the lack of a common methodology to represent the network cabling and organize the agent distribution information. The formalism, consisting on a descriptive language and on an object-oriented topology base, is described and some application areas, where this information can be used, are pointed. Finally it presents a Management API, as part of the overall architecture, that helps to show the usability of the Topology Information Base. © 1994, Plenum Publishing Corporation. All rights reserved.";"management application programming interface, management domains, topology discovery, Topology modeling"
"Hilgert L.D.";"Software Reviews: Test plus";"TEST PLUS is a software package based on the Adult Personality Inventory (API). It allows the API user to make decisions based on a systematic comparison of 25 personality factors to a database of up to 100 other examinees or to a “referenced model” constructed by the evaluator. This makes TEST PLUS extremely useful in a variety of settings. © 1987, Sage Publications. All rights reserved."
